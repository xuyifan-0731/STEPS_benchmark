{"question_id": 1, "text": " Design a feature for a social media website to recommend articles to users based on how similar the articles are to their previously liked articles.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'csebuetnlp/mT5_multilingual_XLSum\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'csebuetnlp/mT5_multilingual_XLSum\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers==4.11.0.dev0\\'], \\'example_code\\': \"import re\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nWHITESPACE_HANDLER = lambda k: re.sub(\\'\\\\\\\\s+\\', \\' \\', re.sub(\\'\\\\\\\n+\\', \\' \\', k.strip()))\\\narticle_text = Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people\\'s scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We\\'re expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\\\nmodel_name = csebuetnlp/mT5_multilingual_XLSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\\\ninput_ids = tokenizer(\\\n [WHITESPACE_HANDLER(article_text)],\\\n return_tensors=pt,\\\n padding=max_length,\\\n truncation=True,\\\n max_length=512\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n max_length=84,\\\n no_repeat_ngram_size=2,\\\n num_beams=4\\\n)[0]\\\nsummary = tokenizer.decode(\\\n output_ids,\\\n skip_special_tokens=True,\\\n clean_up_tokenization_spaces=False\\\n)\\\nprint(summary)\", \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.5, \\'ROUGE-2\\': 13.934, \\'ROUGE-L\\': 28.988, \\'ROUGE-LSUM\\': 28.996, \\'loss\\': 2.067, \\'gen_len\\': 26.973}}, \\'description\\': \\'This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 2, "text": " The user is interested in a tool to find relationships between medical terms.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Image-to-Text\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'promptcap-coco-vqa\\', \\'api_call\\': \"PromptCap(\\'vqascore/promptcap-coco-vqa\\')\", \\'api_arguments\\': {\\'prompt\\': \\'string\\', \\'image\\': \\'string\\'}, \\'python_environment_requirements\\': \\'pip install promptcap\\', \\'example_code\\': [\\'import torch\\', \\'from promptcap import PromptCap\\', \\'model = PromptCap(vqascore/promptcap-coco-vqa)\\', \\'if torch.cuda.is_available():\\', \\'  model.cuda()\\', \\'prompt = please describe this image according to the given question: what piece of clothing is this boy putting on?\\', \\'image = glove_boy.jpeg\\', \\'print(model.caption(prompt, image))\\'], \\'performance\\': {\\'dataset\\': {\\'coco\\': {\\'accuracy\\': \\'150 CIDEr\\'}, \\'OK-VQA\\': {\\'accuracy\\': \\'60.4%\\'}, \\'A-OKVQA\\': {\\'accuracy\\': \\'59.6%\\'}}}, \\'description\\': \\'PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 3, "text": " As a journalist, I am curious about speech sentiment analysis in a group of people in a crowd. I want to extract features from the audio to run sentiment analysis.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentiment Analysis\\', \\'api_name\\': \\'michellejieli/NSFW_text_classifier\\', \\'api_call\\': \"pipeline(\\'sentiment-analysis\\', model=\\'michellejieli/NSFW_text_classification\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'classifier(I see youâ€™ve set aside this special time to humiliate yourself in public.)\\', \\'performance\\': {\\'dataset\\': \\'Reddit posts\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 4, "text": " A chat service needs a way to compare and cluster similar sentences from users in different languages. Find a suitable feature extraction method to achieve this.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Classification\\', \\'api_name\\': \\'microsoft/swinv2-tiny-patch4-window8-256\\', \\'api_call\\': \"AutoModelForImageClassification.from_pretrained(\\'microsoft/swinv2-tiny-patch4-window8-256\\')\", \\'api_arguments\\': {\\'image\\': \\'http://images.cocodataset.org/val2017/000000039769.jpg\\'}, \\'python_environment_requirements\\': [\\'transformers\\', \\'PIL\\', \\'requests\\'], \\'example_code\\': \\'from transformers import AutoImageProcessor, AutoModelForImageClassification\\\nfrom PIL import Image\\\nimport requests\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\nprocessor = AutoImageProcessor.from_pretrained(microsoft/swinv2-tiny-patch4-window8-256)\\\nmodel = AutoModelForImageClassification.from_pretrained(microsoft/swinv2-tiny-patch4-window8-256)\\\ninputs = processor(images=image, return_tensors=pt)\\\noutputs = model(**inputs)\\\nlogits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'imagenet-1k\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 5, "text": " I am an interior designer and want to showcase a modern living room with a fireplace and a large window overlooking a forest. Create an image according to this description.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Denoising Diffusion Probabilistic Models (DDPM)\\', \\'api_name\\': \\'google/ddpm-bedroom-256\\', \\'api_call\\': \"DDPMPipeline.from_pretrained(\\'google/ddpm-bedroom-256\\')\", \\'api_arguments\\': \\'None\\', \\'python_environment_requirements\\': \\'diffusers\\', \\'example_code\\': \\'!pip install diffusers\\\nfrom diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline\\\nmodel_id = google/ddpm-bedroom-256\\\nddpm = DDPMPipeline.from_pretrained(model_id)\\\nimage = ddpm().images[0]\\\nimage.save(ddpm_generated_image.png)\\', \\'performance\\': {\\'dataset\\': \\'CIFAR10\\', \\'accuracy\\': {\\'Inception score\\': 9.46, \\'FID score\\': 3.17}}, \\'description\\': \\'We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 6, "text": " We need a product description for an image-based online store platform that will help customers understand the specifics of the product.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 7, "text": " Create a program to generate a description for an image provided as input.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image Generation\\', \\'api_name\\': \\'stabilityai/stable-diffusion-2\\', \\'api_call\\': \"StableDiffusionPipeline.from_pretrained(\\'stabilityai/stable-diffusion-2\\', scheduler=EulerDiscreteScheduler.from_pretrained(\\'stabilityai/stable-diffusion-2\\', subfolder=scheduler), torch_dtype=torch.float16)\", \\'api_arguments\\': {\\'prompt\\': \\'a photo of an astronaut riding a horse on mars\\'}, \\'python_environment_requirements\\': [\\'diffusers\\', \\'transformers\\', \\'accelerate\\', \\'scipy\\', \\'safetensors\\'], \\'example_code\\': \\'from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\\\nmodel_id = stabilityai/stable-diffusion-2\\\nscheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=scheduler)\\\npipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\\\npipe = pipe.to(cuda)\\\nprompt = a photo of an astronaut riding a horse on mars\\\nimage = pipe(prompt).images[0]\\\nimage.save(astronaut_rides_horse.png)\\', \\'performance\\': {\\'dataset\\': \\'COCO2017 validation set\\', \\'accuracy\\': \\'Not optimized for FID scores\\'}, \\'description\\': \\'Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 8, "text": " I am a financial analyst, and I receive report after report filled with charts helping to explain trends and data in my field. However, I also need to have this information in tabular format. Please help me extract a linearized table from this chart.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 9, "text": " We are building an automatic video generation platform based on user-provided text. We need a reliable model to convert text instructions into appropriate videos.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 10, "text": " How can I extract video content from a text file? Provide a code sample to generate the video based on the text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'camenduru/text2-video-zero\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'camenduru/text2-video-zero\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 11, "text": " We are developing a mobile app to demonstrate the AI's ability to generate a short video from text. The app focuses on processing written stories into video.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 12, "text": " Hey, I want to analyze images in my phone gallery and answer questions about them.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Visual Question Answering\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Visual Question Answering\\', \\'api_name\\': \\'JosephusCheung/GuanacoVQAOnConsumerHardware\\', \\'api_call\\': \"pipeline(\\'visual-question-answering\\', model=\\'JosephusCheung/GuanacoVQAOnConsumerHardware\\')\", \\'api_arguments\\': {\\'model\\': \\'JosephusCheung/GuanacoVQAOnConsumerHardware\\', \\'tokenizer\\': \\'JosephusCheung/GuanacoVQAOnConsumerHardware\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'latest\\', \\'torch\\': \\'latest\\'}, \\'example_code\\': \\'vqa(image_path, question)\\', \\'performance\\': {\\'dataset\\': \\'JosephusCheung/GuanacoVQADataset\\', \\'accuracy\\': \\'unknown\\'}, \\'description\\': \\'A Visual Question Answering model trained on the GuanacoVQADataset, designed to work on consumer hardware like Colab Free T4 GPU. The model can be used to answer questions about images.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 13, "text": " My company wants to develop an application that will analyze images in relation to food and answer questions about them. We want it to handle questions like \\\"what is in the dish\\\" and \\\"how many calories does it have\\\".\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'csebuetnlp/mT5_multilingual_XLSum\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'csebuetnlp/mT5_multilingual_XLSum\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers==4.11.0.dev0\\'], \\'example_code\\': \"import re\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nWHITESPACE_HANDLER = lambda k: re.sub(\\'\\\\\\\\s+\\', \\' \\', re.sub(\\'\\\\\\\n+\\', \\' \\', k.strip()))\\\narticle_text = Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people\\'s scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We\\'re expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\\\nmodel_name = csebuetnlp/mT5_multilingual_XLSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\\\ninput_ids = tokenizer(\\\n [WHITESPACE_HANDLER(article_text)],\\\n return_tensors=pt,\\\n padding=max_length,\\\n truncation=True,\\\n max_length=512\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n max_length=84,\\\n no_repeat_ngram_size=2,\\\n num_beams=4\\\n)[0]\\\nsummary = tokenizer.decode(\\\n output_ids,\\\n skip_special_tokens=True,\\\n clean_up_tokenization_spaces=False\\\n)\\\nprint(summary)\", \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.5, \\'ROUGE-2\\': 13.934, \\'ROUGE-L\\': 28.988, \\'ROUGE-LSUM\\': 28.996, \\'loss\\': 2.067, \\'gen_len\\': 26.973}}, \\'description\\': \\'This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 14, "text": " We have received an invoice document, and would like to extract the total amount from it.\n###Input: {'question': 'What is the total amount?', 'context': 'Invoice information for order ABC_123\\\nProduct: Widget A, Quantity: 10, Price: $5 each\\\nProduct: Widget B, Quantity: 5, Price: $3 each\\\nProduct: Widget C, Quantity: 15, Price: $2 each\\\nSubtotal: $75, Tax: $6.38, Total Amount Due: $81.38'}\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Document Question Answering\\', \\'api_name\\': \\'CQI_Visual_Question_Awnser_PT_v0\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=LayoutLMForQuestionAnswering.from_pretrained(\\'microsoft/layoutlm-base-uncased\\'))\", \\'api_arguments\\': [\\'url\\', \\'question\\'], \\'python_environment_requirements\\': [\\'PIL\\', \\'pytesseract\\', \\'PyTorch\\', \\'transformers\\'], \\'example_code\\': [\"nlp(\\'https://templates.invoicehome.com/invoice-template-us-neat-750px.png\\', \\'What is the invoice number?\\')\", \"nlp(\\'https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\\', \\'What is the purchase amount?\\')\", \"nlp(\\'https://www.accountingcoach.com/wp-content/uploads/2013/10/income-statement-example@2x.png\\', \\'What are the 2020 net sales?\\')\"], \\'performance\\': {\\'dataset\\': [{\\'accuracy\\': 0.9943977}, {\\'accuracy\\': 0.9912159}, {\\'accuracy\\': 0.59147286}]}, \\'description\\': \\'A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 15, "text": " As a clerk in a school, you want to extract information from some student enrollment forms. These forms contain students' details such as Name, age, and address.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Generation\\', \\'api_name\\': \\'pygmalion-6b\\', \\'api_call\\': \"AutoModelForCausalLM.from_pretrained(\\'waifu-workshop/pygmalion-6b\\')\", \\'api_arguments\\': [\\'input_ids\\', \\'max_length\\', \\'num_return_sequences\\'], \\'python_environment_requirements\\': [\\'transformers\\', \\'torch\\'], \\'example_code\\': \"from transformers import AutoTokenizer, AutoModelForCausalLM\\\n\\\ntokenizer = AutoTokenizer.from_pretrained(\\'waifu-workshop/pygmalion-6b\\')\\\nmodel = AutoModelForCausalLM.from_pretrained(\\'waifu-workshop/pygmalion-6b\\')\\\n\\\ninput_text = [CHARACTER]\\'s Persona: [A few sentences about the character you want the model to play]\\\\\\\n<START>\\\\\\\n[DIALOGUE HISTORY]\\\\\\\nYou: [Your input message here]\\\\\\\n[CHARACTER]:\\\ninput_ids = tokenizer.encode(input_text, return_tensors=\\'pt\\')\\\n\\\noutput = model.generate(input_ids, max_length=100, num_return_sequences=1)\\\n\\\noutput_text = tokenizer.decode(output[0], skip_special_tokens=True)\", \\'performance\\': {\\'dataset\\': \\'56MB of dialogue data gathered from multiple sources\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \"Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI\\'s GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 16, "text": " Find a model that can be used to predict the properties of molecules based on their graph representations.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Graph Machine Learning\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'graphormer-base-pcqm4mv1\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'graphormer-base-pcqm4mv1\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'See the Graph Classification with Transformers tutorial\\', \\'performance\\': {\\'dataset\\': \\'PCQM4M-LSC\\', \\'accuracy\\': \\'1st place on the KDD CUP 2021 (quantum prediction track)\\'}, \\'description\\': \\'The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 17, "text": " Estimate the depth of a pool using computational depth estimation, given an underwater photo.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Zero-Shot Image Classification\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Zero-Shot Image Classification\\', \\'api_name\\': \\'laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\\', \\'api_call\\': \"pipeline(\\'image-classification\\', model=\\'laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\\')\", \\'api_arguments\\': \\'image_path, class_names\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"results = model(image_path, class_names=\\'cat, dog, bird\\')\", \\'performance\\': {\\'dataset\\': \\'ImageNet-1k\\', \\'accuracy\\': \\'76.9\\'}, \\'description\\': \\'A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 18, "text": " I need technology that can analyze images and estimate their depth in a single camera.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Conversational\\', \\'api_name\\': \\'facebook/blenderbot_small-90M\\', \\'api_call\\': \"BlenderbotForConditionalGeneration.from_pretrained(\\'facebook/blenderbot_small-90M\\')\", \\'api_arguments\\': [\\'message\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'Input a message to start chatting with facebook/blenderbot_small-90M.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 19, "text": " The client is a real estate company working on virtual tours. We need to help them estimate depth in images of houses.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'csebuetnlp/mT5_multilingual_XLSum\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'csebuetnlp/mT5_multilingual_XLSum\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers==4.11.0.dev0\\'], \\'example_code\\': \"import re\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nWHITESPACE_HANDLER = lambda k: re.sub(\\'\\\\\\\\s+\\', \\' \\', re.sub(\\'\\\\\\\n+\\', \\' \\', k.strip()))\\\narticle_text = Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people\\'s scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We\\'re expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\\\nmodel_name = csebuetnlp/mT5_multilingual_XLSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\\\ninput_ids = tokenizer(\\\n [WHITESPACE_HANDLER(article_text)],\\\n return_tensors=pt,\\\n padding=max_length,\\\n truncation=True,\\\n max_length=512\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n max_length=84,\\\n no_repeat_ngram_size=2,\\\n num_beams=4\\\n)[0]\\\nsummary = tokenizer.decode(\\\n output_ids,\\\n skip_special_tokens=True,\\\n clean_up_tokenization_spaces=False\\\n)\\\nprint(summary)\", \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.5, \\'ROUGE-2\\': 13.934, \\'ROUGE-L\\': 28.988, \\'ROUGE-LSUM\\': 28.996, \\'loss\\': 2.067, \\'gen_len\\': 26.973}}, \\'description\\': \\'This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 20, "text": " Assist me in setting up an image classifier that can recognize objects within an image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'videomae-small-finetuned-ssv2\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-small-finetuned-ssv2\\')\", \\'api_arguments\\': {\\'model_name\\': \\'MCG-NJU/videomae-small-finetuned-ssv2\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\\', \\'numpy\\': \\'import numpy as np\\', \\'torch\\': \\'import torch\\'}, \\'example_code\\': \\'video = list(np.random.randn(16, 3, 224, 224))\\\nfeature_extractor = VideoMAEFeatureExtractor.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\nmodel = VideoMAEForVideoClassification.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\ninputs = feature_extractor(video, return_tensors=pt)\\\nwith torch.no_grad():\\\n  outputs = model(**inputs)\\\n  logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'Something-Something V2\\', \\'accuracy\\': {\\'top-1\\': 66.8, \\'top-5\\': 90.3}}, \\'description\\': \\'VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 21, "text": " Identify an object within an image based on textual description. For example, find a dog in the image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Text Classification\\', \\'api_name\\': \\'distilbert-base-uncased-finetuned-sst-2-english\\', \\'api_call\\': \"DistilBertForSequenceClassification.from_pretrained(\\'distilbert-base-uncased-finetuned-sst-2-english\\')\", \\'api_arguments\\': [\\'inputs\\'], \\'python_environment_requirements\\': [\\'torch\\', \\'transformers\\'], \\'example_code\\': \"import torch\\\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\\\ntokenizer = DistilBertTokenizer.from_pretrained(\\'distilbert-base-uncased\\')\\\nmodel = DistilBertForSequenceClassification.from_pretrained(\\'distilbert-base-uncased-finetuned-sst-2-english\\')\\\ninputs = tokenizer(\\'Hello, my dog is cute\\', return_tensors=\\'pt\\')\\\nwith torch.no_grad():\\\n    logits = model(**inputs).logits\\\npredicted_class_id = logits.argmax().item()\\\nmodel.config.id2label[predicted_class_id]\", \\'performance\\': {\\'dataset\\': \\'glue\\', \\'accuracy\\': 0.911}, \\'description\\': \\'This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 22, "text": " Our client is an AI gaming company and we need to develop a bot for the game Valorant. The bot should detect objects like dropped spike, enemy, planted spike, and teammate within the game.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Object Detection\\', \\'api_name\\': \\'keremberke/yolov8m-valorant-detection\\', \\'api_call\\': \"YOLO(\\'keremberke/yolov8m-valorant-detection\\')\", \\'api_arguments\\': {\\'conf\\': 0.25, \\'iou\\': 0.45, \\'agnostic_nms\\': False, \\'max_det\\': 1000}, \\'python_environment_requirements\\': \\'pip install ultralyticsplus==0.0.23 ultralytics==8.0.21\\', \\'example_code\\': \"from ultralyticsplus import YOLO, render_result\\\nmodel = YOLO(\\'keremberke/yolov8m-valorant-detection\\')\\\nmodel.overrides[\\'conf\\'] = 0.25\\\nmodel.overrides[\\'iou\\'] = 0.45\\\nmodel.overrides[\\'agnostic_nms\\'] = False\\\nmodel.overrides[\\'max_det\\'] = 1000\\\nimage = \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'\\\nresults = model.predict(image)\\\nprint(results[0].boxes)\\\nrender = render_result(model=model, image=image, result=results[0])\\\nrender.show()\", \\'performance\\': {\\'dataset\\': \\'valorant-object-detection\\', \\'accuracy\\': 0.965}, \\'description\\': \\'A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 23, "text": " A client from real estate agency needs to get a list of objects present in a series of pictures to prepare their property listings.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'zero-shot-object-detection\\', \\'api_name\\': \\'google/owlvit-base-patch32\\', \\'api_call\\': \"OwlViTForObjectDetection.from_pretrained(\\'google/owlvit-base-patch32\\')\", \\'api_arguments\\': {\\'texts\\': \\'List of text queries\\', \\'images\\': \\'Image to be processed\\'}, \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'import requests\\\nfrom PIL import Image\\\nimport torch\\\nfrom transformers import OwlViTProcessor, OwlViTForObjectDetection\\\nprocessor = OwlViTProcessor.from_pretrained(google/owlvit-base-patch32)\\\nmodel = OwlViTForObjectDetection.from_pretrained(google/owlvit-base-patch32)\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\ntexts = [[a photo of a cat, a photo of a dog]]\\\ninputs = processor(text=texts, images=image, return_tensors=pt)\\\noutputs = model(**inputs)\\\ntarget_sizes = torch.Tensor([image.size[::-1]])\\\nresults = processor.post_process(outputs=outputs, target_sizes=target_sizes)\\', \\'performance\\': {\\'dataset\\': \\'COCO and OpenImages\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'OWL-ViT is a zero-shot text-conditioned object detection model that uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. The model can be used to query an image with one or multiple text queries.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 24, "text": " We are developing an application for smartphones which automatically separates elements in a user's photo, and we need to implement this feature.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 25, "text": " I have a picture of a room demonstrating a mixture of objects. The model needs to seperate the objects and label them accordingly.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Translation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Text-to-Text Generation\\', \\'api_name\\': \\'optimum/t5-small\\', \\'api_call\\': \"ORTModelForSeq2SeqLM.from_pretrained(\\'optimum/t5-small\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\', \\'optimum.onnxruntime\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, pipeline\\\nfrom optimum.onnxruntime import ORTModelForSeq2SeqLM\\\ntokenizer = AutoTokenizer.from_pretrained(optimum/t5-small)\\\nmodel = ORTModelForSeq2SeqLM.from_pretrained(optimum/t5-small)\\\ntranslator = pipeline(translation_en_to_fr, model=model, tokenizer=tokenizer)\\\nresults = translator(My name is Eustache and I have a pet raccoon)\\\nprint(results)\\', \\'performance\\': {\\'dataset\\': \\'c4\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. It can be used for translation, text-to-text generation, and summarization.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 26, "text": " We want to randomly generate high-quality images of celebrity faces.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Unconditional Image Generation\\', \\'api_name\\': \\'google/ddpm-cat-256\\', \\'api_call\\': \"DDPMPipeline.from_pretrained(\\'google/ddpm-cat-256\\')\", \\'api_arguments\\': [\\'model_id\\'], \\'python_environment_requirements\\': [\\'diffusers\\'], \\'example_code\\': \\'!pip install diffusers\\\nfrom diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline\\\nmodel_id = google/ddpm-cat-256\\\nddpm = DDPMPipeline.from_pretrained(model_id)\\\nimage = ddpm().images[0]\\\nimage.save(ddpm_generated_image.png)\\', \\'performance\\': {\\'dataset\\': \\'CIFAR10\\', \\'accuracy\\': {\\'Inception_score\\': 9.46, \\'FID_score\\': 3.17}}, \\'description\\': \\'Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 27, "text": " Generate a new image based on the online database of bedroom art.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'ToddGoldfarb/Cadet-Tiny\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'ToddGoldfarb/Cadet-Tiny\\', low_cpu_mem_usage=True)\", \\'api_arguments\\': {\\'pretrained_model\\': \\'t5-small\\', \\'model_max_length\\': 512}, \\'python_environment_requirements\\': {\\'torch\\': \\'\\', \\'transformers\\': \\'\\', \\'colorful\\': \\'\\'}, \\'example_code\\': \"import torch\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nimport colorful as cf\\\ncf.use_true_colors()\\\ncf.use_style(\\'monokai\\')\\\nclass CadetTinyAgent:\\\n def <strong>init</strong>(self):\\\n  print(cf.bold | cf.purple(Waking up Cadet-Tiny...))\\\n  self.device = torch.device(cuda if torch.cuda.is_available() else cpu)\\\n  self.tokenizer = AutoTokenizer.from_pretrained(t5-small, model_max_length=512)\\\n  self.model = AutoModelForSeq2SeqLM.from_pretrained(ToddGoldfarb/Cadet-Tiny, low_cpu_mem_usage=True).to(self.device)\\\n  self.conversation_history = \\\ndef observe(self, observation):\\\n self.conversation_history = self.conversation_history + observation\\\n # The number 400 below is just a truncation safety net. It leaves room for 112 input tokens.\\\n if len(self.conversation_history) &gt; 400:\\\n self.conversation_history = self.conversation_history[112:]\\\ndef set_input(self, situation_narrative=, role_instruction=):\\\n input_text = dialogue: \\\n if situation_narrative != :\\\n input_text = input_text + situation_narrative\\\n if role_instruction != :\\\n input_text = input_text +  &lt;SEP&gt;  + role_instruction\\\n input_text = input_text +  &lt;TURN&gt;  + self.conversation_history\\\n # Uncomment the line below to see what is fed to the model.\\\n # print(input_text)\\\n return input_text\\\ndef generate(self, situation_narrative, role_instruction, user_response):\\\n user_response = user_response +  &lt;TURN&gt; \\\n self.observe(user_response)\\\n input_text = self.set_input(situation_narrative, role_instruction)\\\n inputs = self.tokenizer([input_text], return_tensors=pt).to(self.device)\\\n # I encourage you to change the hyperparameters of the model! Start by trying to modify the temperature.\\\n outputs = self.model.generate(inputs[input_ids], max_new_tokens=512, temperature=1, top_p=.95,\\\n do_sample=True)\\\n cadet_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\\\n added_turn = cadet_response +  &lt;TURN&gt; \\\n self.observe(added_turn)\\\n return cadet_response\\\ndef reset_history(self):\\\n self.conversation_history = []\\\ndef run(self):\\\n def get_valid_input(prompt, default):\\\n  while True:\\\n   user_input = input(prompt)\\\n   if user_input in [Y, N, y, n]:\\\n    return user_input\\\n   if user_input == :\\\n    return default\\\n  while True:\\\n   continue_chat = \\\n   # MODIFY THESE STRINGS TO YOUR LIKING :)\\\n   situation_narrative = Imagine you are Cadet-Tiny talking to ???.\\\n   role_instruction = You are Cadet-Tiny, and you are talking to ???.\\\n   self.chat(situation_narrative, role_instruction)\\\n   continue_chat = get_valid_input(cf.purple(Start a new conversation with new setup? [Y/N]:), Y)\\\n   if continue_chat in [N, n]:\\\n    break\\\n   print(cf.blue(CT: See you!))\\\ndef chat(self, situation_narrative, role_instruction):\\\n print(cf.green(\\\n  Cadet-Tiny is running! Input [RESET] to reset the conversation history and [END] to end the conversation.))\\\n while True:\\\n  user_input = input(You: )\\\n  if user_input == [RESET]:\\\n   self.reset_history()\\\n   print(cf.green([Conversation history cleared. Chat with Cadet-Tiny!]))\\\n   continue\\\n  if user_input == [END]:\\\n   break\\\n  response = self.generate(situation_narrative, role_instruction, user_input)\\\n  print(cf.blue(CT:  + response))\\\ndef main():\\\n print(cf.bold | cf.blue(LOADING MODEL))\\\nCadetTiny = CadetTinyAgent()\\\nCadetTiny.run()\\\nif <strong>name</strong> == \\'<strong>main</strong>\\':\\\n main()\", \\'performance\\': {\\'dataset\\': \\'allenai/soda\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 28, "text": " I run an online store that sells butterfly-themed products. Please generate an image of a cute butterfly for our social media page.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 29, "text": " We need a video-based AI model for security purposes. We want the AI to check and categorize footage based on existing security guidelines.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 30, "text": " A new project demands to classify videos for a social media platform. Let us create a video classification pipeline.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'csebuetnlp/mT5_multilingual_XLSum\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'csebuetnlp/mT5_multilingual_XLSum\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers==4.11.0.dev0\\'], \\'example_code\\': \"import re\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nWHITESPACE_HANDLER = lambda k: re.sub(\\'\\\\\\\\s+\\', \\' \\', re.sub(\\'\\\\\\\n+\\', \\' \\', k.strip()))\\\narticle_text = Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people\\'s scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We\\'re expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\\\nmodel_name = csebuetnlp/mT5_multilingual_XLSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\\\ninput_ids = tokenizer(\\\n [WHITESPACE_HANDLER(article_text)],\\\n return_tensors=pt,\\\n padding=max_length,\\\n truncation=True,\\\n max_length=512\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n max_length=84,\\\n no_repeat_ngram_size=2,\\\n num_beams=4\\\n)[0]\\\nsummary = tokenizer.decode(\\\n output_ids,\\\n skip_special_tokens=True,\\\n clean_up_tokenization_spaces=False\\\n)\\\nprint(summary)\", \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.5, \\'ROUGE-2\\': 13.934, \\'ROUGE-L\\': 28.988, \\'ROUGE-LSUM\\': 28.996, \\'loss\\': 2.067, \\'gen_len\\': 26.973}}, \\'description\\': \\'This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 31, "text": " I am an insurance adjustor. I need a zero-shot image classifier that will tell me whether a car has been involved in a major accident or had minor damages.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 32, "text": " I want to analyze a medical image to find out if it's an X-ray, an MRI scan, or a CT scan.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 33, "text": " We are building a quiz application where the image will be shown, and we have to choose a dressings matching that image. Please help in classifying the image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 34, "text": " We're developing a chatbot that can quickly identify and describe images for our Chinese-speaking users.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 35, "text": " We would like to understand the sentiment of user's messages in a customer support chat system.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'Kirili4ik/mbart_ruDialogSum\\', \\'api_call\\': \"MBartForConditionalGeneration.from_pretrained(\\'Kirili4ik/mbart_ruDialogSum\\')\", \\'api_arguments\\': {\\'model_name\\': \\'Kirili4ik/mbart_ruDialogSum\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import MBartTokenizer, MBartForConditionalGeneration\\\nmodel_name = Kirili4ik/mbart_ruDialogSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)\\\nmodel.eval()\\\narticle_text = ...\\\ninput_ids = tokenizer(\\\n [article_text],\\\n max_length=600,\\\n padding=max_length,\\\n truncation=True,\\\n return_tensors=pt,\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n top_k=0,\\\n num_beams=3,\\\n no_repeat_ngram_size=3\\\n)[0]\\\nsummary = tokenizer.decode(output_ids, skip_special_tokens=True)\\\nprint(summary)\\', \\'performance\\': {\\'dataset\\': [{\\'name\\': \\'SAMSum Corpus (translated to Russian)\\', \\'accuracy\\': {\\'Validation ROGUE-1\\': 34.5, \\'Validation ROGUE-L\\': 33, \\'Test ROGUE-1\\': 31, \\'Test ROGUE-L\\': 28}}]}, \\'description\\': \\'MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 36, "text": " As a book store owner, I want to classify customer reviews into positive and negative sentiments.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'results-yelp\\', \\'api_call\\': \"AutoTokenizer.from_pretrained(\\'bert-base-uncased\\')\", \\'api_arguments\\': {\\'tokenizer\\': \"AutoTokenizer.from_pretrained(\\'bert-base-uncased\\')\", \\'config\\': \"AutoConfig.from_pretrained(\\'potatobunny/results-yelp\\')\"}, \\'python_environment_requirements\\': {\\'Transformers\\': \\'4.18.0\\', \\'Pytorch\\': \\'1.10.0+cu111\\', \\'Datasets\\': \\'2.0.0\\', \\'Tokenizers\\': \\'0.12.1\\'}, \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'Yelp\\', \\'accuracy\\': 0.9302}, \\'description\\': \\'This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 37, "text": " I am the owner of a news website. I have several consumers' comments about our publishing news. I want to analyze the sentiments of these comments.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 38, "text": " Our business is expanding to international markets. Analyze the sentiment of the following customer review to better understand their satisfaction with our product: \\\"\\u00a1Esto es maravilloso! Me encanta.\\\"\n###Input: \\\"\\u00a1Esto es maravilloso! Me encanta.\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Zero-Shot Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Zero-Shot Classification\\', \\'api_name\\': \\'Recognai/bert-base-spanish-wwm-cased-xnli\\', \\'api_call\\': \"AutoModelForSequenceClassification.from_pretrained(\\'Recognai/bert-base-spanish-wwm-cased-xnli\\')\", \\'api_arguments\\': [\\'sequence\\', \\'candidate_labels\\', \\'hypothesis_template\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import pipeline\\\nclassifier = pipeline(zero-shot-classification, model=Recognai/bert-base-spanish-wwm-cased-xnli)\\\nclassifier(\\\nEl autor se perfila, a los 50 aÃ±os de su muerte, como uno de los grandes de su siglo,\\\ncandidate_labels=[cultura, sociedad, economia, salud, deportes],\\\nhypothesis_template=Este ejemplo es {}. \\\n)\\', \\'performance\\': {\\'dataset\\': \\'XNLI-es\\', \\'accuracy\\': \\'79.9%\\'}, \\'description\\': \\'This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 39, "text": " We are a forum moderator team looking for a solution to classify comments into toxic or non-toxic categories.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'martin-ha/toxic-comment-model\\', \\'api_call\\': \"pipeline(model=\\'martin-ha/toxic-comment-model\\')\", \\'api_arguments\\': {\\'model_path\\': \\'martin-ha/toxic-comment-model\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import AutoModelForSequenceClassification, AutoTokenizer, TextClassificationPipeline\\\nmodel_path = martin-ha/toxic-comment-model\\\ntokenizer = AutoTokenizer.from_pretrained(model_path)\\\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\\\npipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\\\nprint(pipeline(\\'This is a test text.\\'))\", \\'performance\\': {\\'dataset\\': \\'held-out test set\\', \\'accuracy\\': 0.94, \\'f1-score\\': 0.59}, \\'description\\': \\'This model is a fine-tuned version of the DistilBERT model to classify toxic comments.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 40, "text": " My company is launching a social media campaign. We need an AI-based system that would automatically analyze the sentiment of any user-generated reviews or tweets concerning our product.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'csebuetnlp/mT5_multilingual_XLSum\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'csebuetnlp/mT5_multilingual_XLSum\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers==4.11.0.dev0\\'], \\'example_code\\': \"import re\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nWHITESPACE_HANDLER = lambda k: re.sub(\\'\\\\\\\\s+\\', \\' \\', re.sub(\\'\\\\\\\n+\\', \\' \\', k.strip()))\\\narticle_text = Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people\\'s scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We\\'re expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\\\nmodel_name = csebuetnlp/mT5_multilingual_XLSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\\\ninput_ids = tokenizer(\\\n [WHITESPACE_HANDLER(article_text)],\\\n return_tensors=pt,\\\n padding=max_length,\\\n truncation=True,\\\n max_length=512\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n max_length=84,\\\n no_repeat_ngram_size=2,\\\n num_beams=4\\\n)[0]\\\nsummary = tokenizer.decode(\\\n output_ids,\\\n skip_special_tokens=True,\\\n clean_up_tokenization_spaces=False\\\n)\\\nprint(summary)\", \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.5, \\'ROUGE-2\\': 13.934, \\'ROUGE-L\\': 28.988, \\'ROUGE-LSUM\\': 28.996, \\'loss\\': 2.067, \\'gen_len\\': 26.973}}, \\'description\\': \\'This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 41, "text": " I have jobs descriptions in French for sales manager, please highlight names of organizations or cities within the text.\n###Input: \\\"La soci\\u00e9t\\u00e9 de Paris est sp\\u00e9cialis\\u00e9e dans la vente de v\\u00e9hicules \\u00e9lectriques. Responsable des ventes, vous travaillerez au sein d'une \\u00e9quipe dynamique dans l'agence de Lyon. Vous \\u00eates charg\\u00e9(e) de d\\u00e9velopper le portefeuille client et d'assurer la satisfaction des clients existants. Dans ce contexte, vous devrez travailler en lien \\u00e9troit avec le directeur commercial et les autres \\u00e9quipes de l'entreprise. Une exp\\u00e9rience pr\\u00e9alable chez Renault est un atout.\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Token Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Named Entity Recognition\\', \\'api_name\\': \\'Jean-Baptiste/camembert-ner\\', \\'api_call\\': \"AutoModelForTokenClassification.from_pretrained(\\'Jean-Baptiste/camembert-ner\\')\", \\'api_arguments\\': {\\'model\\': \\'model\\', \\'tokenizer\\': \\'tokenizer\\', \\'aggregation_strategy\\': \\'simple\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'AutoTokenizer, AutoModelForTokenClassification, pipeline\\'}, \\'example_code\\': \"from transformers import AutoTokenizer, AutoModelForTokenClassification\\\ntokenizer = AutoTokenizer.from_pretrained(Jean-Baptiste/camembert-ner)\\\nmodel = AutoModelForTokenClassification.from_pretrained(Jean-Baptiste/camembert-ner)\\\n\\\nfrom transformers import pipeline\\\nnlp = pipeline(\\'ner\\', model=model, tokenizer=tokenizer, aggregation_strategy=simple)\\\nnlp(Apple est cre le 1er avril 1976 dans le garage de la maison d\\'enfance de Steve Jobs  Los Altos en Californie par Steve Jobs, Steve Wozniak et Ronald Wayne14, puis constitue sous forme de socit le 3 janvier 1977  l\\'origine sous le nom d\\'Apple Computer, mais pour ses 30 ans et pour reflter la diversification de ses produits, le mot Â« computer  est retir le 9 janvier 2015.)\", \\'performance\\': {\\'dataset\\': \\'wikiner-fr\\', \\'accuracy\\': {\\'overall_f1\\': 0.8914, \\'PER_f1\\': 0.9483, \\'ORG_f1\\': 0.8181, \\'LOC_f1\\': 0.8955, \\'MISC_f1\\': 0.8146}}, \\'description\\': \\'camembert-ner is a Named Entity Recognition (NER) model fine-tuned from camemBERT on the wikiner-fr dataset. It can recognize entities such as persons, organizations, locations, and miscellaneous entities.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 42, "text": " In order to have a better understanding of our clients, I'd like to identify the names of people and organizations mentioned in the following customer review.\n###Input: \\\"I recently purchased a MacBook Pro from Apple Inc. and had a fantastic customer support experience. John from their tech support team was incredibly helpful and professional.\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 43, "text": " I am building a social media app that requires people to write fascinating stories rather than boring sentences. Detect named entities in a sentence by using an NER model.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 44, "text": " We have a large dataset of customer orders in the form of a table. Help us answer questions about this data.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'PyTorch Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'table-question-answering-tapas\\', \\'api_call\\': \"pipeline(\\'table-question-answering\\', model=\\'Meena/table-question-answering-tapas\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'This model can be loaded on the Inference API on-demand.\\', \\'performance\\': {\\'dataset\\': [{\\'name\\': \\'SQA (Sequential Question Answering by Microsoft)\\', \\'accuracy\\': None}, {\\'name\\': \\'WTQ (Wiki Table Questions by Stanford University)\\', \\'accuracy\\': None}, {\\'name\\': \\'WikiSQL (by Salesforce)\\', \\'accuracy\\': None}]}, \\'description\\': \\'TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 45, "text": " Gather information about annual income and age demographics of employees to predict retirement patterns. Make sure to identify top employees for potential promotions.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Speech Recognition\\', \\'api_name\\': \\'jonatasgrosman/wav2vec2-large-xlsr-53-japanese\\', \\'api_call\\': \"SpeechRecognitionModel(\\'jonatasgrosman/wav2vec2-large-xlsr-53-japanese\\')\", \\'api_arguments\\': [\\'audio_paths\\'], \\'python_environment_requirements\\': [\\'huggingsound\\', \\'torch\\', \\'librosa\\', \\'datasets\\', \\'transformers\\'], \\'example_code\\': \\'from huggingsound import SpeechRecognitionModel\\\nmodel = SpeechRecognitionModel(jonatasgrosman/wav2vec2-large-xlsr-53-japanese)\\\naudio_paths = [/path/to/file.mp3, /path/to/another_file.wav]\\\ntranscriptions = model.transcribe(audio_paths)\\', \\'performance\\': {\\'dataset\\': \\'common_voice\\', \\'accuracy\\': {\\'WER\\': 81.8, \\'CER\\': 20.16}}, \\'description\\': \\'Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 46, "text": " To track our sales data, we need to find total sales of a specific product based on a table containing sales information per week.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'financial-sentiment-analysis\\', \\'api_name\\': \\'yiyanghkust/finbert-tone\\', \\'api_call\\': \"BertForSequenceClassification.from_pretrained(\\'yiyanghkust/finbert-tone\\',num_labels=3)\", \\'api_arguments\\': [\\'sentences\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import BertTokenizer, BertForSequenceClassification\\\nfrom transformers import pipeline\\\nfinbert = BertForSequenceClassification.from_pretrained(\\'yiyanghkust/finbert-tone\\',num_labels=3)\\\ntokenizer = BertTokenizer.from_pretrained(\\'yiyanghkust/finbert-tone\\')\\\nnlp = pipeline(sentiment-analysis, model=finbert, tokenizer=tokenizer)\\\nsentences = [there is a shortage of capital, and we need extra financing,\\\n growth is strong and we have plenty of liquidity,\\\n there are doubts about our finances,\\\n profits are flat]\\\nresults = nlp(sentences)\\\nprint(results)\", \\'performance\\': {\\'dataset\\': \\'10,000 manually annotated sentences from analyst reports\\', \\'accuracy\\': \\'superior performance on financial tone analysis task\\'}, \\'description\\': \\'FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 47, "text": " I have a table containing information about various animals and their important characteristics. I need the system to answer a query to provide information about the tallest animal in the table.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 48, "text": " You are building an app that allows users to find quick answers to textbook questions. Users will send a message with the question, and the answer should be detected directly from the textbook content.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'valhalla/t5-base-e2e-qg\\', \\'api_call\\': \"pipeline(\\'e2e-qg\\', model=\\'valhalla/t5-base-e2e-qg\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'Hugging Face Transformers\\'], \\'example_code\\': \"from pipelines import pipeline\\\n\\\ntext = Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python\\'s design philosophy emphasizes code readability with its notable use of significant whitespace.\\\n\\\nnlp = pipeline(e2e-qg, model=valhalla/t5-base-e2e-qg)\\\n\\\nnlp(text)\", \\'performance\\': {\\'dataset\\': \\'squad\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 49, "text": " We want to make sure clarify some questions about the legal implications of a new partnership contract for a real estate development project.\n###Input: We hereby grant the Licensee the exclusive right to develop, construct, operate and promote the Project, as well as to manage the daily operations of the Licensed Facilities during the Term. In consideration for the grant of the License, the Licensee shall pay to the Licensor the full amount of Ten Million (10,000,000) Dollars within thirty (30) days after the execution hereof.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 50, "text": " Help me setup a tinyroberta model from deepset for Question and Answer. Provide a sample input and output.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'google/tapas-medium-finetuned-sqa\\', \\'api_call\\': \"pipeline(\\'table-question-answering\\', model=\\'google/tapas-medium-finetuned-sqa\\')\", \\'api_arguments\\': \\'table, query\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"from transformers import pipeline\\\n\\\n# Initialize the pipeline\\\ntable_qa_pipeline = pipeline(\\'table-question-answering\\', model=\\'google/tapas-medium-finetuned-sqa\\')\\\n\\\n# Provide the table and query\\\nresult = table_qa_pipeline(table=table, query=\\'What is the total revenue?\\')\", \\'performance\\': {\\'dataset\\': \\'msr_sqa\\', \\'accuracy\\': 0.6561}, \\'description\\': \\'TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 51, "text": " I want to build a tool to answer questions automatically from a given document. Which model do you recommend for this task?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'distilbert-base-uncased-distilled-squad\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'distilbert-base-uncased-distilled-squad\\')\", \\'api_arguments\\': [\\'question\\', \\'context\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\nquestion_answerer = pipeline(question-answering, model=\\'distilbert-base-uncased-distilled-squad\\')\\\ncontext = r\\\n... Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\\\n... question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\\\n... a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\\\n... \\\nresult = question_answerer(question=What is a good example of a question answering dataset?, context=context)\\\nprint(\\\n... fAnswer: \\'{result[\\'answer\\']}\\', score: {round(result[\\'score\\'], 4)}, start: {result[\\'start\\']}, end: {result[\\'end\\']}\\\n...)\", \\'performance\\': {\\'dataset\\': \\'SQuAD v1.1\\', \\'accuracy\\': \\'86.9 F1 score\\'}, \\'description\\': \"DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT\\'s performances as measured on the GLUE language understanding benchmark.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 52, "text": " We have a French news agency and we want to categorize the news articles based on sports, politics, and science.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Feature Extraction\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Feature Extraction\\', \\'api_name\\': \\'DeepPavlov/rubert-base-cased\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'DeepPavlov/rubert-base-cased\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'Russian part of Wikipedia and news data\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'RuBERT (Russian, cased, 12â€‘layer, 768â€‘hidden, 12â€‘heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERTâ€‘base as an initialization for RuBERT[1].\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 53, "text": " I need a solution to detect whether a piece of news is talking about technology, sports, or politics.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'ToddGoldfarb/Cadet-Tiny\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'ToddGoldfarb/Cadet-Tiny\\', low_cpu_mem_usage=True)\", \\'api_arguments\\': {\\'pretrained_model\\': \\'t5-small\\', \\'model_max_length\\': 512}, \\'python_environment_requirements\\': {\\'torch\\': \\'\\', \\'transformers\\': \\'\\', \\'colorful\\': \\'\\'}, \\'example_code\\': \"import torch\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nimport colorful as cf\\\ncf.use_true_colors()\\\ncf.use_style(\\'monokai\\')\\\nclass CadetTinyAgent:\\\n def <strong>init</strong>(self):\\\n  print(cf.bold | cf.purple(Waking up Cadet-Tiny...))\\\n  self.device = torch.device(cuda if torch.cuda.is_available() else cpu)\\\n  self.tokenizer = AutoTokenizer.from_pretrained(t5-small, model_max_length=512)\\\n  self.model = AutoModelForSeq2SeqLM.from_pretrained(ToddGoldfarb/Cadet-Tiny, low_cpu_mem_usage=True).to(self.device)\\\n  self.conversation_history = \\\ndef observe(self, observation):\\\n self.conversation_history = self.conversation_history + observation\\\n # The number 400 below is just a truncation safety net. It leaves room for 112 input tokens.\\\n if len(self.conversation_history) &gt; 400:\\\n self.conversation_history = self.conversation_history[112:]\\\ndef set_input(self, situation_narrative=, role_instruction=):\\\n input_text = dialogue: \\\n if situation_narrative != :\\\n input_text = input_text + situation_narrative\\\n if role_instruction != :\\\n input_text = input_text +  &lt;SEP&gt;  + role_instruction\\\n input_text = input_text +  &lt;TURN&gt;  + self.conversation_history\\\n # Uncomment the line below to see what is fed to the model.\\\n # print(input_text)\\\n return input_text\\\ndef generate(self, situation_narrative, role_instruction, user_response):\\\n user_response = user_response +  &lt;TURN&gt; \\\n self.observe(user_response)\\\n input_text = self.set_input(situation_narrative, role_instruction)\\\n inputs = self.tokenizer([input_text], return_tensors=pt).to(self.device)\\\n # I encourage you to change the hyperparameters of the model! Start by trying to modify the temperature.\\\n outputs = self.model.generate(inputs[input_ids], max_new_tokens=512, temperature=1, top_p=.95,\\\n do_sample=True)\\\n cadet_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\\\n added_turn = cadet_response +  &lt;TURN&gt; \\\n self.observe(added_turn)\\\n return cadet_response\\\ndef reset_history(self):\\\n self.conversation_history = []\\\ndef run(self):\\\n def get_valid_input(prompt, default):\\\n  while True:\\\n   user_input = input(prompt)\\\n   if user_input in [Y, N, y, n]:\\\n    return user_input\\\n   if user_input == :\\\n    return default\\\n  while True:\\\n   continue_chat = \\\n   # MODIFY THESE STRINGS TO YOUR LIKING :)\\\n   situation_narrative = Imagine you are Cadet-Tiny talking to ???.\\\n   role_instruction = You are Cadet-Tiny, and you are talking to ???.\\\n   self.chat(situation_narrative, role_instruction)\\\n   continue_chat = get_valid_input(cf.purple(Start a new conversation with new setup? [Y/N]:), Y)\\\n   if continue_chat in [N, n]:\\\n    break\\\n   print(cf.blue(CT: See you!))\\\ndef chat(self, situation_narrative, role_instruction):\\\n print(cf.green(\\\n  Cadet-Tiny is running! Input [RESET] to reset the conversation history and [END] to end the conversation.))\\\n while True:\\\n  user_input = input(You: )\\\n  if user_input == [RESET]:\\\n   self.reset_history()\\\n   print(cf.green([Conversation history cleared. Chat with Cadet-Tiny!]))\\\n   continue\\\n  if user_input == [END]:\\\n   break\\\n  response = self.generate(situation_narrative, role_instruction, user_input)\\\n  print(cf.blue(CT:  + response))\\\ndef main():\\\n print(cf.bold | cf.blue(LOADING MODEL))\\\nCadetTiny = CadetTinyAgent()\\\nCadetTiny.run()\\\nif <strong>name</strong> == \\'<strong>main</strong>\\':\\\n main()\", \\'performance\\': {\\'dataset\\': \\'allenai/soda\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 54, "text": " I want to build a chatbot that is used by language learners who want to communicate in French while they only know English. Generate a response for an English message.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 55, "text": " Translate the following text from French to English: \\u201cLe syst\\u00e8me \\u00e9ducatif fran\\u00e7ais est compos\\u00e9 d'\\u00e9coles maternelles, d'\\u00e9coles \\u00e9l\\u00e9mentaires, de coll\\u00e8ges et de lyc\\u00e9es.\\u201d\n###Input: Le syst\\u00e8me \\u00e9ducatif fran\\u00e7ais est compos\\u00e9 d'\\u00e9coles maternelles, d'\\u00e9coles \\u00e9l\\u00e9mentaires, de coll\\u00e8ges et de lyc\\u00e9es.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Token Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Named Entity Recognition\\', \\'api_name\\': \\'Jean-Baptiste/camembert-ner\\', \\'api_call\\': \"AutoModelForTokenClassification.from_pretrained(\\'Jean-Baptiste/camembert-ner\\')\", \\'api_arguments\\': {\\'model\\': \\'model\\', \\'tokenizer\\': \\'tokenizer\\', \\'aggregation_strategy\\': \\'simple\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'AutoTokenizer, AutoModelForTokenClassification, pipeline\\'}, \\'example_code\\': \"from transformers import AutoTokenizer, AutoModelForTokenClassification\\\ntokenizer = AutoTokenizer.from_pretrained(Jean-Baptiste/camembert-ner)\\\nmodel = AutoModelForTokenClassification.from_pretrained(Jean-Baptiste/camembert-ner)\\\n\\\nfrom transformers import pipeline\\\nnlp = pipeline(\\'ner\\', model=model, tokenizer=tokenizer, aggregation_strategy=simple)\\\nnlp(Apple est cre le 1er avril 1976 dans le garage de la maison d\\'enfance de Steve Jobs  Los Altos en Californie par Steve Jobs, Steve Wozniak et Ronald Wayne14, puis constitue sous forme de socit le 3 janvier 1977  l\\'origine sous le nom d\\'Apple Computer, mais pour ses 30 ans et pour reflter la diversification de ses produits, le mot Â« computer  est retir le 9 janvier 2015.)\", \\'performance\\': {\\'dataset\\': \\'wikiner-fr\\', \\'accuracy\\': {\\'overall_f1\\': 0.8914, \\'PER_f1\\': 0.9483, \\'ORG_f1\\': 0.8181, \\'LOC_f1\\': 0.8955, \\'MISC_f1\\': 0.8146}}, \\'description\\': \\'camembert-ner is a Named Entity Recognition (NER) model fine-tuned from camemBERT on the wikiner-fr dataset. It can recognize entities such as persons, organizations, locations, and miscellaneous entities.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 56, "text": " I want to translate a text from one language to another.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Summarization\\', \\'api_name\\': \\'pszemraj/long-t5-tglobal-base-16384-book-summary\\', \\'api_call\\': \"T5ForConditionalGeneration.from_pretrained(\\'pszemraj/long-t5-tglobal-base-16384-book-summary\\')\", \\'api_arguments\\': [\\'long_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\nimport torch\\\nsummarizer = pipeline(\\\n summarization,\\\n pszemraj/long-t5-tglobal-base-16384-book-summary,\\\n device=0 if torch.cuda.is_available() else -1,\\\n)\\\nlong_text = Here is a lot of text I don\\'t want to read. Replace me\\\nresult = summarizer(long_text)\\\nprint(result[0][summary_text])\", \\'performance\\': {\\'dataset\\': \\'kmfoda/booksum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.408, \\'ROUGE-2\\': 6.065, \\'ROUGE-L\\': 16.721, \\'ROUGE-LSUM\\': 33.34}}, \\'description\\': \\'A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 57, "text": " Our team member has written a long article that needs to be published on a company blog. Can you provide a shorter summary to be used as a snippet on the landing page?\n###Input: \\\"Apple Inc. reported its quarterly earnings results yesterday. The company posted a record-breaking revenue of $123.9 billion for the first quarter of 2022, up by 11% from the same period last year. The increase was fueled by stronger demand for iPhones, iPads, and Macs, as well as continued growth in its services segment. Apple's operating profit for the quarter came in at $38.3 billion, up 17% from a year earlier. The results surpassed analysts' expectations, who had anticipated revenue of around $118 billion. This strong performance is largely attributed to the successful launch of the iPhone 13, which has enjoyed robust sales since its debut in September. Apple CEO Tim Cook said in a statement, \\\"Our record-breaking quarter reflects the strength of our entire ecosystem, from our innovative products and services to the unmatched dedication of our teams around the world.\\\" Despite the ongoing global supply chain disruptions, Apple has managed to maintain its growth trajectory, thanks in part to its vertically integrated operations and nimble supply chain management. The company is expected to face stiffer competition going forward, particularly in the smartphone market, as rivals introduce new devices and increased pricing pressures.\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'csebuetnlp/mT5_multilingual_XLSum\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'csebuetnlp/mT5_multilingual_XLSum\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers==4.11.0.dev0\\'], \\'example_code\\': \"import re\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nWHITESPACE_HANDLER = lambda k: re.sub(\\'\\\\\\\\s+\\', \\' \\', re.sub(\\'\\\\\\\n+\\', \\' \\', k.strip()))\\\narticle_text = Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people\\'s scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We\\'re expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\\\nmodel_name = csebuetnlp/mT5_multilingual_XLSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\\\ninput_ids = tokenizer(\\\n [WHITESPACE_HANDLER(article_text)],\\\n return_tensors=pt,\\\n padding=max_length,\\\n truncation=True,\\\n max_length=512\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n max_length=84,\\\n no_repeat_ngram_size=2,\\\n num_beams=4\\\n)[0]\\\nsummary = tokenizer.decode(\\\n output_ids,\\\n skip_special_tokens=True,\\\n clean_up_tokenization_spaces=False\\\n)\\\nprint(summary)\", \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.5, \\'ROUGE-2\\': 13.934, \\'ROUGE-L\\': 28.988, \\'ROUGE-LSUM\\': 28.996, \\'loss\\': 2.067, \\'gen_len\\': 26.973}}, \\'description\\': \\'This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 58, "text": " Write a summary of a conference held by the World Health Organization discussing the impacts of climate change on human health.\n###Input: Over the past week, the World Health Organization held a conference discussing the impacts of climate change on human health. The conference brought together leading experts from around the world to examine the current problems affecting people's health due to changing environmental conditions. The topics of discussion included increased occurrence of heat-related illnesses, heightened rates of vector-borne diseases, and the growing problem of air pollution. The conference concluded with a call to action for governments and organizations to invest in mitigating and adapting to the negative consequences of climate change for the sake of public health.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 59, "text": " Please provide a brief overview of a news article.\n###Input: A new study suggests that eating chocolate at least once a week can lead to better cognition. The study, published in the journal Appetite, analyzed data from over 900 adults and found that individuals who consumed chocolate at least once a week performed better on cognitive tests than those who consumed chocolate less frequently. Researchers believe that the beneficial effects of chocolate on cognition may be due to the presence of flavonoids, which have been shown to be antioxidant-rich and to improve brain blood flow.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 60, "text": " I developed a document generation app, I need to create a summary of a long article given as input to provide to my users before they read the full article.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 61, "text": " We need a quick summary of a news article we found online. Can you help us with that?\n###Input: Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people's scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We're expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'csebuetnlp/mT5_multilingual_XLSum\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'csebuetnlp/mT5_multilingual_XLSum\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers==4.11.0.dev0\\'], \\'example_code\\': \"import re\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nWHITESPACE_HANDLER = lambda k: re.sub(\\'\\\\\\\\s+\\', \\' \\', re.sub(\\'\\\\\\\n+\\', \\' \\', k.strip()))\\\narticle_text = Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people\\'s scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We\\'re expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\\\nmodel_name = csebuetnlp/mT5_multilingual_XLSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\\\ninput_ids = tokenizer(\\\n [WHITESPACE_HANDLER(article_text)],\\\n return_tensors=pt,\\\n padding=max_length,\\\n truncation=True,\\\n max_length=512\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n max_length=84,\\\n no_repeat_ngram_size=2,\\\n num_beams=4\\\n)[0]\\\nsummary = tokenizer.decode(\\\n output_ids,\\\n skip_special_tokens=True,\\\n clean_up_tokenization_spaces=False\\\n)\\\nprint(summary)\", \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.5, \\'ROUGE-2\\': 13.934, \\'ROUGE-L\\': 28.988, \\'ROUGE-LSUM\\': 28.996, \\'loss\\': 2.067, \\'gen_len\\': 26.973}}, \\'description\\': \\'This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 62, "text": " We'd like our chatbot to act as a fictional character for engaging with our users.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 63, "text": " Write a story about a spaceship journey to a distant planet in search of a new home for humanity.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'ToddGoldfarb/Cadet-Tiny\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'ToddGoldfarb/Cadet-Tiny\\', low_cpu_mem_usage=True)\", \\'api_arguments\\': {\\'pretrained_model\\': \\'t5-small\\', \\'model_max_length\\': 512}, \\'python_environment_requirements\\': {\\'torch\\': \\'\\', \\'transformers\\': \\'\\', \\'colorful\\': \\'\\'}, \\'example_code\\': \"import torch\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nimport colorful as cf\\\ncf.use_true_colors()\\\ncf.use_style(\\'monokai\\')\\\nclass CadetTinyAgent:\\\n def <strong>init</strong>(self):\\\n  print(cf.bold | cf.purple(Waking up Cadet-Tiny...))\\\n  self.device = torch.device(cuda if torch.cuda.is_available() else cpu)\\\n  self.tokenizer = AutoTokenizer.from_pretrained(t5-small, model_max_length=512)\\\n  self.model = AutoModelForSeq2SeqLM.from_pretrained(ToddGoldfarb/Cadet-Tiny, low_cpu_mem_usage=True).to(self.device)\\\n  self.conversation_history = \\\ndef observe(self, observation):\\\n self.conversation_history = self.conversation_history + observation\\\n # The number 400 below is just a truncation safety net. It leaves room for 112 input tokens.\\\n if len(self.conversation_history) &gt; 400:\\\n self.conversation_history = self.conversation_history[112:]\\\ndef set_input(self, situation_narrative=, role_instruction=):\\\n input_text = dialogue: \\\n if situation_narrative != :\\\n input_text = input_text + situation_narrative\\\n if role_instruction != :\\\n input_text = input_text +  &lt;SEP&gt;  + role_instruction\\\n input_text = input_text +  &lt;TURN&gt;  + self.conversation_history\\\n # Uncomment the line below to see what is fed to the model.\\\n # print(input_text)\\\n return input_text\\\ndef generate(self, situation_narrative, role_instruction, user_response):\\\n user_response = user_response +  &lt;TURN&gt; \\\n self.observe(user_response)\\\n input_text = self.set_input(situation_narrative, role_instruction)\\\n inputs = self.tokenizer([input_text], return_tensors=pt).to(self.device)\\\n # I encourage you to change the hyperparameters of the model! Start by trying to modify the temperature.\\\n outputs = self.model.generate(inputs[input_ids], max_new_tokens=512, temperature=1, top_p=.95,\\\n do_sample=True)\\\n cadet_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\\\n added_turn = cadet_response +  &lt;TURN&gt; \\\n self.observe(added_turn)\\\n return cadet_response\\\ndef reset_history(self):\\\n self.conversation_history = []\\\ndef run(self):\\\n def get_valid_input(prompt, default):\\\n  while True:\\\n   user_input = input(prompt)\\\n   if user_input in [Y, N, y, n]:\\\n    return user_input\\\n   if user_input == :\\\n    return default\\\n  while True:\\\n   continue_chat = \\\n   # MODIFY THESE STRINGS TO YOUR LIKING :)\\\n   situation_narrative = Imagine you are Cadet-Tiny talking to ???.\\\n   role_instruction = You are Cadet-Tiny, and you are talking to ???.\\\n   self.chat(situation_narrative, role_instruction)\\\n   continue_chat = get_valid_input(cf.purple(Start a new conversation with new setup? [Y/N]:), Y)\\\n   if continue_chat in [N, n]:\\\n    break\\\n   print(cf.blue(CT: See you!))\\\ndef chat(self, situation_narrative, role_instruction):\\\n print(cf.green(\\\n  Cadet-Tiny is running! Input [RESET] to reset the conversation history and [END] to end the conversation.))\\\n while True:\\\n  user_input = input(You: )\\\n  if user_input == [RESET]:\\\n   self.reset_history()\\\n   print(cf.green([Conversation history cleared. Chat with Cadet-Tiny!]))\\\n   continue\\\n  if user_input == [END]:\\\n   break\\\n  response = self.generate(situation_narrative, role_instruction, user_input)\\\n  print(cf.blue(CT:  + response))\\\ndef main():\\\n print(cf.bold | cf.blue(LOADING MODEL))\\\nCadetTiny = CadetTinyAgent()\\\nCadetTiny.run()\\\nif <strong>name</strong> == \\'<strong>main</strong>\\':\\\n main()\", \\'performance\\': {\\'dataset\\': \\'allenai/soda\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 64, "text": " I want to write a story about a brave knight and a dragon but I'm unable to come up with a good start. Help me with that.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 65, "text": " I need a text analysis tool that can automatically predict the most plausible missing text in a given sentence.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Conversational\\', \\'api_name\\': \\'microsoft/GODEL-v1_1-large-seq2seq\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'microsoft/GODEL-v1_1-large-seq2seq\\')\", \\'api_arguments\\': {\\'instruction\\': \\'Instruction: given a dialog context, you need to response empathically.\\', \\'knowledge\\': \\'\\', \\'dialog\\': [\\'Does money buy happiness?\\', \\'It is a question. Money buys you a lot of things, but not enough to buy happiness.\\', \\'What is the best way to buy happiness ?\\']}, \\'python_environment_requirements\\': {\\'transformers\\': \\'AutoTokenizer, AutoModelForSeq2SeqLM\\'}, \\'example_code\\': \"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\ntokenizer = AutoTokenizer.from_pretrained(microsoft/GODEL-v1_1-large-seq2seq)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(microsoft/GODEL-v1_1-large-seq2seq)\\\ndef generate(instruction, knowledge, dialog):\\\n if knowledge != \\'\\':\\\n knowledge = \\'[KNOWLEDGE] \\' + knowledge\\\n dialog = \\' EOS \\'.join(dialog)\\\n query = f{instruction} [CONTEXT] {dialog} {knowledge}\\\n input_ids = tokenizer(f{query}, return_tensors=pt).input_ids\\\n outputs = model.generate(input_ids, max_length=128, min_length=8, top_p=0.9, do_sample=True)\\\n output = tokenizer.decode(outputs[0], skip_special_tokens=True)\\\n return output\\\n\\\ninstruction = f\\'Instruction: given a dialog context, you need to response empathically.\\'\\\nknowledge = \\'\\'\\\ndialog = [\\\n \\'Does money buy happiness?\\',\\\n \\'It is a question. Money buys you a lot of things, but not enough to buy happiness.\\',\\\n \\'What is the best way to buy happiness ?\\'\\\n]\\\nresponse = generate(instruction, knowledge, dialog)\\\nprint(response)\", \\'performance\\': {\\'dataset\\': \\'Reddit discussion thread, instruction and knowledge grounded dialogs\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 66, "text": " Help me fill in the blanks in the following Chinese sentence: \\\"\\u4e0a\\u6d77\\u662f\\u4e2d\\u56fd\\u7684[MASK]\\u5927\\u57ce\\u5e02\\u3002\\\"\n###Input: \\u4e0a\\u6d77\\u662f\\u4e2d\\u56fd\\u7684[MASK]\\u5927\\u57ce\\u5e02\\u3002\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'ToddGoldfarb/Cadet-Tiny\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'ToddGoldfarb/Cadet-Tiny\\', low_cpu_mem_usage=True)\", \\'api_arguments\\': {\\'pretrained_model\\': \\'t5-small\\', \\'model_max_length\\': 512}, \\'python_environment_requirements\\': {\\'torch\\': \\'\\', \\'transformers\\': \\'\\', \\'colorful\\': \\'\\'}, \\'example_code\\': \"import torch\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nimport colorful as cf\\\ncf.use_true_colors()\\\ncf.use_style(\\'monokai\\')\\\nclass CadetTinyAgent:\\\n def <strong>init</strong>(self):\\\n  print(cf.bold | cf.purple(Waking up Cadet-Tiny...))\\\n  self.device = torch.device(cuda if torch.cuda.is_available() else cpu)\\\n  self.tokenizer = AutoTokenizer.from_pretrained(t5-small, model_max_length=512)\\\n  self.model = AutoModelForSeq2SeqLM.from_pretrained(ToddGoldfarb/Cadet-Tiny, low_cpu_mem_usage=True).to(self.device)\\\n  self.conversation_history = \\\ndef observe(self, observation):\\\n self.conversation_history = self.conversation_history + observation\\\n # The number 400 below is just a truncation safety net. It leaves room for 112 input tokens.\\\n if len(self.conversation_history) &gt; 400:\\\n self.conversation_history = self.conversation_history[112:]\\\ndef set_input(self, situation_narrative=, role_instruction=):\\\n input_text = dialogue: \\\n if situation_narrative != :\\\n input_text = input_text + situation_narrative\\\n if role_instruction != :\\\n input_text = input_text +  &lt;SEP&gt;  + role_instruction\\\n input_text = input_text +  &lt;TURN&gt;  + self.conversation_history\\\n # Uncomment the line below to see what is fed to the model.\\\n # print(input_text)\\\n return input_text\\\ndef generate(self, situation_narrative, role_instruction, user_response):\\\n user_response = user_response +  &lt;TURN&gt; \\\n self.observe(user_response)\\\n input_text = self.set_input(situation_narrative, role_instruction)\\\n inputs = self.tokenizer([input_text], return_tensors=pt).to(self.device)\\\n # I encourage you to change the hyperparameters of the model! Start by trying to modify the temperature.\\\n outputs = self.model.generate(inputs[input_ids], max_new_tokens=512, temperature=1, top_p=.95,\\\n do_sample=True)\\\n cadet_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\\\n added_turn = cadet_response +  &lt;TURN&gt; \\\n self.observe(added_turn)\\\n return cadet_response\\\ndef reset_history(self):\\\n self.conversation_history = []\\\ndef run(self):\\\n def get_valid_input(prompt, default):\\\n  while True:\\\n   user_input = input(prompt)\\\n   if user_input in [Y, N, y, n]:\\\n    return user_input\\\n   if user_input == :\\\n    return default\\\n  while True:\\\n   continue_chat = \\\n   # MODIFY THESE STRINGS TO YOUR LIKING :)\\\n   situation_narrative = Imagine you are Cadet-Tiny talking to ???.\\\n   role_instruction = You are Cadet-Tiny, and you are talking to ???.\\\n   self.chat(situation_narrative, role_instruction)\\\n   continue_chat = get_valid_input(cf.purple(Start a new conversation with new setup? [Y/N]:), Y)\\\n   if continue_chat in [N, n]:\\\n    break\\\n   print(cf.blue(CT: See you!))\\\ndef chat(self, situation_narrative, role_instruction):\\\n print(cf.green(\\\n  Cadet-Tiny is running! Input [RESET] to reset the conversation history and [END] to end the conversation.))\\\n while True:\\\n  user_input = input(You: )\\\n  if user_input == [RESET]:\\\n   self.reset_history()\\\n   print(cf.green([Conversation history cleared. Chat with Cadet-Tiny!]))\\\n   continue\\\n  if user_input == [END]:\\\n   break\\\n  response = self.generate(situation_narrative, role_instruction, user_input)\\\n  print(cf.blue(CT:  + response))\\\ndef main():\\\n print(cf.bold | cf.blue(LOADING MODEL))\\\nCadetTiny = CadetTinyAgent()\\\nCadetTiny.run()\\\nif <strong>name</strong> == \\'<strong>main</strong>\\':\\\n main()\", \\'performance\\': {\\'dataset\\': \\'allenai/soda\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 67, "text": " We are building a source code autocompletion tool which will complete the code snippet containing a masked token.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 68, "text": " I work for a Japanese company, and my manager needs me to take a look at a request from a client. I can understand fluent Japanese, but I need a little help filling in missing words from the text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 69, "text": " We are building a platform to compare and contrast user input sentences with existing sentences in our database. It should return similar results.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 70, "text": " I need a method to compare the similarity between two sentences to be used within a meme generator, so we can produce a meme with a similar caption.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Denoising Diffusion Probabilistic Models (DDPM)\\', \\'api_name\\': \\'google/ddpm-bedroom-256\\', \\'api_call\\': \"DDPMPipeline.from_pretrained(\\'google/ddpm-bedroom-256\\')\", \\'api_arguments\\': \\'None\\', \\'python_environment_requirements\\': \\'diffusers\\', \\'example_code\\': \\'!pip install diffusers\\\nfrom diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline\\\nmodel_id = google/ddpm-bedroom-256\\\nddpm = DDPMPipeline.from_pretrained(model_id)\\\nimage = ddpm().images[0]\\\nimage.save(ddpm_generated_image.png)\\', \\'performance\\': {\\'dataset\\': \\'CIFAR10\\', \\'accuracy\\': {\\'Inception score\\': 9.46, \\'FID score\\': 3.17}}, \\'description\\': \\'We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 71, "text": " A student is writing a research paper and needs help with finding similar articles in order to include them in the literature review section.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Zero-Shot Image Classification\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Zero-Shot Image Classification\\', \\'api_name\\': \\'microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\\', \\'api_call\\': \"pipeline(\\'zero-shot-image-classification\\', model=\\'microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\\')\", \\'api_arguments\\': \\'image, possible_class_names\\', \\'python_environment_requirements\\': \\'transformers, torch, torchvision\\', \\'example_code\\': \"from transformers import pipeline\\\nclip = pipeline(\\'zero-shot-image-classification\\', model=\\'microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\\')\\\nimage = \\'path/to/image.png\\'\\\npossible_class_names = [\\'class1\\', \\'class2\\', \\'class3\\']\\\nresult = clip(image, possible_class_names)\", \\'performance\\': {\\'dataset\\': \\'PMC-15M\\', \\'accuracy\\': \\'State of the art\\'}, \\'description\\': \\'BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 72, "text": " Create a solution to convert a given Japanese sentence into a speech audio file.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Text-to-Speech\\', \\'framework\\': \\'ESPnet\\', \\'functionality\\': \\'Text-to-Speech\\', \\'api_name\\': \\'mio/Artoria\\', \\'api_call\\': \"pipeline(\\'text-to-speech\\', model=\\'mio/Artoria\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline; tts = pipeline(\\'text-to-speech\\', model=\\'mio/Artoria\\'); tts(\\'s\\')\", \\'performance\\': {\\'dataset\\': \\'fate\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 73, "text": " We are working on a transcription service for our customers. We need a way to convert audio files into text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 74, "text": " We are creating an online video conference service, and we need to detect when two or more speakers are speaking at the same time in the audio.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'pyannote.audio\\', \\'functionality\\': \\'overlapped-speech-detection\\', \\'api_name\\': \\'pyannote/overlapped-speech-detection\\', \\'api_call\\': \"pipeline.from_pretrained(\\'pyannote/overlapped-speech-detection\\', use_auth_token=\\'ACCESS_TOKEN_GOES_HERE\\')\", \\'api_arguments\\': [\\'audio.wav\\'], \\'python_environment_requirements\\': [\\'pyannote.audio 2.1\\'], \\'example_code\\': \\'from pyannote.audio import Pipeline\\\npipeline = Pipeline.from_pretrained(pyannote/overlapped-speech-detection, use_auth_token=ACCESS_TOKEN_GOES_HERE)\\\noutput = pipeline(audio.wav)\\\nfor speech in output.get_timeline().support():\\\n  # two or more speakers are active between speech.start and speech.end\\\n  ...\\', \\'performance\\': {\\'dataset\\': \\'ami\\', \\'accuracy\\': None}, \\'description\\': \\'Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 75, "text": " Our company develops smart speaker devices that involve interaction with the user. We need to transcribe the input from the users with the maintained accent or language.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'csebuetnlp/mT5_multilingual_XLSum\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'csebuetnlp/mT5_multilingual_XLSum\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers==4.11.0.dev0\\'], \\'example_code\\': \"import re\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nWHITESPACE_HANDLER = lambda k: re.sub(\\'\\\\\\\\s+\\', \\' \\', re.sub(\\'\\\\\\\n+\\', \\' \\', k.strip()))\\\narticle_text = Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people\\'s scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We\\'re expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\\\nmodel_name = csebuetnlp/mT5_multilingual_XLSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\\\ninput_ids = tokenizer(\\\n [WHITESPACE_HANDLER(article_text)],\\\n return_tensors=pt,\\\n padding=max_length,\\\n truncation=True,\\\n max_length=512\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n max_length=84,\\\n no_repeat_ngram_size=2,\\\n num_beams=4\\\n)[0]\\\nsummary = tokenizer.decode(\\\n output_ids,\\\n skip_special_tokens=True,\\\n clean_up_tokenization_spaces=False\\\n)\\\nprint(summary)\", \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.5, \\'ROUGE-2\\': 13.934, \\'ROUGE-L\\': 28.988, \\'ROUGE-LSUM\\': 28.996, \\'loss\\': 2.067, \\'gen_len\\': 26.973}}, \\'description\\': \\'This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 76, "text": " One of our clients is facing noise issues on their audio recordings. Can you help them to remove the noise from the audio?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'videomae-small-finetuned-ssv2\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-small-finetuned-ssv2\\')\", \\'api_arguments\\': {\\'model_name\\': \\'MCG-NJU/videomae-small-finetuned-ssv2\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\\', \\'numpy\\': \\'import numpy as np\\', \\'torch\\': \\'import torch\\'}, \\'example_code\\': \\'video = list(np.random.randn(16, 3, 224, 224))\\\nfeature_extractor = VideoMAEFeatureExtractor.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\nmodel = VideoMAEForVideoClassification.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\ninputs = feature_extractor(video, return_tensors=pt)\\\nwith torch.no_grad():\\\n  outputs = model(**inputs)\\\n  logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'Something-Something V2\\', \\'accuracy\\': {\\'top-1\\': 66.8, \\'top-5\\': 90.3}}, \\'description\\': \\'VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 77, "text": " We are a media company and we have a large volume of Chinese language audio files. We want to transcribe the audios into chinese text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 78, "text": " Help us improve the listener experience from our customers by enhancing the audio of noisy recordings.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'ToddGoldfarb/Cadet-Tiny\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'ToddGoldfarb/Cadet-Tiny\\', low_cpu_mem_usage=True)\", \\'api_arguments\\': {\\'pretrained_model\\': \\'t5-small\\', \\'model_max_length\\': 512}, \\'python_environment_requirements\\': {\\'torch\\': \\'\\', \\'transformers\\': \\'\\', \\'colorful\\': \\'\\'}, \\'example_code\\': \"import torch\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nimport colorful as cf\\\ncf.use_true_colors()\\\ncf.use_style(\\'monokai\\')\\\nclass CadetTinyAgent:\\\n def <strong>init</strong>(self):\\\n  print(cf.bold | cf.purple(Waking up Cadet-Tiny...))\\\n  self.device = torch.device(cuda if torch.cuda.is_available() else cpu)\\\n  self.tokenizer = AutoTokenizer.from_pretrained(t5-small, model_max_length=512)\\\n  self.model = AutoModelForSeq2SeqLM.from_pretrained(ToddGoldfarb/Cadet-Tiny, low_cpu_mem_usage=True).to(self.device)\\\n  self.conversation_history = \\\ndef observe(self, observation):\\\n self.conversation_history = self.conversation_history + observation\\\n # The number 400 below is just a truncation safety net. It leaves room for 112 input tokens.\\\n if len(self.conversation_history) &gt; 400:\\\n self.conversation_history = self.conversation_history[112:]\\\ndef set_input(self, situation_narrative=, role_instruction=):\\\n input_text = dialogue: \\\n if situation_narrative != :\\\n input_text = input_text + situation_narrative\\\n if role_instruction != :\\\n input_text = input_text +  &lt;SEP&gt;  + role_instruction\\\n input_text = input_text +  &lt;TURN&gt;  + self.conversation_history\\\n # Uncomment the line below to see what is fed to the model.\\\n # print(input_text)\\\n return input_text\\\ndef generate(self, situation_narrative, role_instruction, user_response):\\\n user_response = user_response +  &lt;TURN&gt; \\\n self.observe(user_response)\\\n input_text = self.set_input(situation_narrative, role_instruction)\\\n inputs = self.tokenizer([input_text], return_tensors=pt).to(self.device)\\\n # I encourage you to change the hyperparameters of the model! Start by trying to modify the temperature.\\\n outputs = self.model.generate(inputs[input_ids], max_new_tokens=512, temperature=1, top_p=.95,\\\n do_sample=True)\\\n cadet_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\\\n added_turn = cadet_response +  &lt;TURN&gt; \\\n self.observe(added_turn)\\\n return cadet_response\\\ndef reset_history(self):\\\n self.conversation_history = []\\\ndef run(self):\\\n def get_valid_input(prompt, default):\\\n  while True:\\\n   user_input = input(prompt)\\\n   if user_input in [Y, N, y, n]:\\\n    return user_input\\\n   if user_input == :\\\n    return default\\\n  while True:\\\n   continue_chat = \\\n   # MODIFY THESE STRINGS TO YOUR LIKING :)\\\n   situation_narrative = Imagine you are Cadet-Tiny talking to ???.\\\n   role_instruction = You are Cadet-Tiny, and you are talking to ???.\\\n   self.chat(situation_narrative, role_instruction)\\\n   continue_chat = get_valid_input(cf.purple(Start a new conversation with new setup? [Y/N]:), Y)\\\n   if continue_chat in [N, n]:\\\n    break\\\n   print(cf.blue(CT: See you!))\\\ndef chat(self, situation_narrative, role_instruction):\\\n print(cf.green(\\\n  Cadet-Tiny is running! Input [RESET] to reset the conversation history and [END] to end the conversation.))\\\n while True:\\\n  user_input = input(You: )\\\n  if user_input == [RESET]:\\\n   self.reset_history()\\\n   print(cf.green([Conversation history cleared. Chat with Cadet-Tiny!]))\\\n   continue\\\n  if user_input == [END]:\\\n   break\\\n  response = self.generate(situation_narrative, role_instruction, user_input)\\\n  print(cf.blue(CT:  + response))\\\ndef main():\\\n print(cf.bold | cf.blue(LOADING MODEL))\\\nCadetTiny = CadetTinyAgent()\\\nCadetTiny.run()\\\nif <strong>name</strong> == \\'<strong>main</strong>\\':\\\n main()\", \\'performance\\': {\\'dataset\\': \\'allenai/soda\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 79, "text": " Our company is working on a project to automatically translate spoken English audio to spoken Hokkien audio. We need a speech-to-speech translation model.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Feature Extraction\\', \\'api_name\\': \\'microsoft/wavlm-large\\', \\'api_call\\': \"Wav2Vec2Model.from_pretrained(\\'microsoft/wavlm-large\\')\", \\'api_arguments\\': \\'speech input\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'To fine-tune the model for speech recognition, see the official speech recognition example. To fine-tune the model for speech classification, see the official audio classification example.\\', \\'performance\\': {\\'dataset\\': \\'SUPERB benchmark\\', \\'accuracy\\': \\'state-of-the-art performance\\'}, \\'description\\': \\'WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 80, "text": " We are a startup developing voice assistants. We need a keyword spotting system that can recognize user commands.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 81, "text": " The model needs to have speech recognition capability to identify languages in a given audio file.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'pyannote.audio\\', \\'functionality\\': \\'overlapped-speech-detection\\', \\'api_name\\': \\'pyannote/overlapped-speech-detection\\', \\'api_call\\': \"pipeline.from_pretrained(\\'pyannote/overlapped-speech-detection\\', use_auth_token=\\'ACCESS_TOKEN_GOES_HERE\\')\", \\'api_arguments\\': [\\'audio.wav\\'], \\'python_environment_requirements\\': [\\'pyannote.audio 2.1\\'], \\'example_code\\': \\'from pyannote.audio import Pipeline\\\npipeline = Pipeline.from_pretrained(pyannote/overlapped-speech-detection, use_auth_token=ACCESS_TOKEN_GOES_HERE)\\\noutput = pipeline(audio.wav)\\\nfor speech in output.get_timeline().support():\\\n  # two or more speakers are active between speech.start and speech.end\\\n  ...\\', \\'performance\\': {\\'dataset\\': \\'ami\\', \\'accuracy\\': None}, \\'description\\': \\'Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 82, "text": " I have just recorded a meeting, I want to find the best segments from the audio where people are speaking, and construct a summary.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Summarization\\', \\'api_name\\': \\'distilbart-cnn-12-6-samsum\\', \\'api_call\\': \"pipeline(\\'summarization\\', model=\\'philschmid/distilbart-cnn-12-6-samsum\\')\", \\'api_arguments\\': {\\'model\\': \\'philschmid/distilbart-cnn-12-6-samsum\\'}, \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"from transformers import pipeline\\\nsummarizer = pipeline(summarization, model=philschmid/distilbart-cnn-12-6-samsum)\\\nconversation = \\'\\'\\'Jeff: Can I train a ðŸ¤— Transformers model on Amazon SageMaker? \\\nPhilipp: Sure you can use the new Hugging Face Deep Learning Container. \\\nJeff: ok.\\\nJeff: and how can I get started? \\\nJeff: where can I find documentation? \\\nPhilipp: ok, ok you can find everything here. https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face <br />\\\n\\'\\'\\'\\\nsummarizer(conversation)\", \\'performance\\': {\\'dataset\\': \\'samsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 41.09, \\'ROUGE-2\\': 20.746, \\'ROUGE-L\\': 31.595, \\'ROUGE-LSUM\\': 38.339}}, \\'description\\': \\'This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 83, "text": " I am running a wine store, and I am looking for a machine learning model that can help me classify the quality of wine based on some given features.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 84, "text": " Build a simple application to predict the survival status of passengers on the Titanic based on their age, gender, and passenger class.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Classification\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Binary Classification\\', \\'api_name\\': \\'harithapliyal/autotrain-tatanic-survival-51030121311\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'harithapliyal/autotrain-tatanic-survival-51030121311\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'harithapliyal/autotrain-data-tatanic-survival\\', \\'accuracy\\': 0.872}, \\'description\\': \\'A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 85, "text": " I need to estimate CO2 emissions from vehicles based on their characteristics, such as engine size, transmission type, and miles traveled.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Classification\\', \\'framework\\': \\'Joblib\\', \\'functionality\\': \\'Carbon Emissions\\', \\'api_name\\': \\'tejas23/autotrain-amx2-1702259728\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'Validation Metrics\\', \\'accuracy\\': 0.831}, \\'description\\': \\'A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 86, "text": " We have been asked to predict future criminal re-offense from a given dataset. What model should we adopt and how do we proceed?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'financial-sentiment-analysis\\', \\'api_name\\': \\'yiyanghkust/finbert-tone\\', \\'api_call\\': \"BertForSequenceClassification.from_pretrained(\\'yiyanghkust/finbert-tone\\',num_labels=3)\", \\'api_arguments\\': [\\'sentences\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import BertTokenizer, BertForSequenceClassification\\\nfrom transformers import pipeline\\\nfinbert = BertForSequenceClassification.from_pretrained(\\'yiyanghkust/finbert-tone\\',num_labels=3)\\\ntokenizer = BertTokenizer.from_pretrained(\\'yiyanghkust/finbert-tone\\')\\\nnlp = pipeline(sentiment-analysis, model=finbert, tokenizer=tokenizer)\\\nsentences = [there is a shortage of capital, and we need extra financing,\\\n growth is strong and we have plenty of liquidity,\\\n there are doubts about our finances,\\\n profits are flat]\\\nresults = nlp(sentences)\\\nprint(results)\", \\'performance\\': {\\'dataset\\': \\'10,000 manually annotated sentences from analyst reports\\', \\'accuracy\\': \\'superior performance on financial tone analysis task\\'}, \\'description\\': \\'FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 87, "text": " Our company's goal is to predict carbon emissions based on the given features of the compound.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Joblib\\', \\'functionality\\': \\'Carbon Emissions\\', \\'api_name\\': \\'pcoloc/autotrain-600-dragino-1839063122\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'pcoloc/autotrain-data-600-dragino\\', \\'accuracy\\': {\\'Loss\\': 93.595, \\'R2\\': 0.502, \\'MSE\\': 8760.052, \\'MAE\\': 77.527, \\'RMSLE\\': 0.445}}, \\'description\\': \\'This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 88, "text": " The factory wants to make its production process more eco-friendly. Calculate the carbon emissions for given data.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Joblib\\', \\'functionality\\': \\'Carbon Emissions\\', \\'api_name\\': \\'pcoloc/autotrain-600-dragino-1839063122\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'pcoloc/autotrain-data-600-dragino\\', \\'accuracy\\': {\\'Loss\\': 93.595, \\'R2\\': 0.502, \\'MSE\\': 8760.052, \\'MAE\\': 77.527, \\'RMSLE\\': 0.445}}, \\'description\\': \\'This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 89, "text": " We want to predict the carbon emissions of a new line of electric vehicles for an annual report. Automate the process of loading a regression model, then calculate the forecast of emissions for this year.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'videomae-small-finetuned-ssv2\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-small-finetuned-ssv2\\')\", \\'api_arguments\\': {\\'model_name\\': \\'MCG-NJU/videomae-small-finetuned-ssv2\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\\', \\'numpy\\': \\'import numpy as np\\', \\'torch\\': \\'import torch\\'}, \\'example_code\\': \\'video = list(np.random.randn(16, 3, 224, 224))\\\nfeature_extractor = VideoMAEFeatureExtractor.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\nmodel = VideoMAEForVideoClassification.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\ninputs = feature_extractor(video, return_tensors=pt)\\\nwith torch.no_grad():\\\n  outputs = model(**inputs)\\\n  logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'Something-Something V2\\', \\'accuracy\\': {\\'top-1\\': 66.8, \\'top-5\\': 90.3}}, \\'description\\': \\'VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 90, "text": " We are planning to launch a website which provides tips to people for their daily lives. Can you please build a model to predict the appropriate amount of tips?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 91, "text": " We have a robotic arm in our warehouse that needs to be trained to optimize loading and unloading tasks. The robotic arm is based on the CartPole environment.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 92, "text": " There is an upcoming event called \\\"Space Party\\\" and we need a representative image for the event. Can you assist us in creating an image containing a party in space with astronauts and aliens having fun together?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Visual Question Answering\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'git-large-textvqa\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'microsoft/git-large-textvqa\\')\", \\'api_arguments\\': \\'image, question\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'For code examples, we refer to the documentation.\\', \\'performance\\': {\\'dataset\\': \\'TextVQA\\', \\'accuracy\\': \\'See table 11 in the paper for more details.\\'}, \\'description\\': \"GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using \\'teacher forcing\\' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text).\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 93, "text": " We're creating a promotional image for a wildlife-themed event. We need to display two tigers in a natural setting.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Feature Extraction\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'facebook/dragon-plus-context-encoder\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'facebook/dragon-plus-context-encoder\\')\", \\'api_arguments\\': [\\'pretrained\\'], \\'python_environment_requirements\\': [\\'torch\\', \\'transformers\\'], \\'example_code\\': \"import torch\\\nfrom transformers import AutoTokenizer, AutoModel\\\ntokenizer = AutoTokenizer.from_pretrained(\\'facebook/dragon-plus-query-encoder\\')\\\nquery_encoder = AutoModel.from_pretrained(\\'facebook/dragon-plus-query-encoder\\')\\\ncontext_encoder = AutoModel.from_pretrained(\\'facebook/dragon-plus-context-encoder\\')\\\nquery = \\'Where was Marie Curie born?\\'\\\ncontexts = [\\\n  \\'Maria Sklodowska, later known as Marie Curie, was born on November 7, 1867.\\',\\\n  \\'Born in Paris on 15 May 1859, Pierre Curie was the son of EugÃ¨ne Curie, a doctor of French Catholic origin from Alsace.\\'\\\n]\\\nquery_input = tokenizer(query, return_tensors=\\'pt\\')\\\nctx_input = tokenizer(contexts, padding=True, truncation=True, return_tensors=\\'pt\\')\\\nquery_emb = query_encoder(query_input).last_hidden_state[:, 0, :]\\\nctx_emb = context_encoder(ctx_input).last_hidden_state[:, 0, :]\\\nscore1 = query_emb @ ctx_emb[0]\\\nscore2 = query_emb @ ctx_emb[1]\", \\'performance\\': {\\'dataset\\': \\'MS MARCO\\', \\'accuracy\\': 39.0}, \\'description\\': \\'DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 94, "text": " We have a collection of low-resolution images of movie characters, and we need to upscale those images to get a more detailed high-resolution image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'Kirili4ik/mbart_ruDialogSum\\', \\'api_call\\': \"MBartForConditionalGeneration.from_pretrained(\\'Kirili4ik/mbart_ruDialogSum\\')\", \\'api_arguments\\': {\\'model_name\\': \\'Kirili4ik/mbart_ruDialogSum\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import MBartTokenizer, MBartForConditionalGeneration\\\nmodel_name = Kirili4ik/mbart_ruDialogSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)\\\nmodel.eval()\\\narticle_text = ...\\\ninput_ids = tokenizer(\\\n [article_text],\\\n max_length=600,\\\n padding=max_length,\\\n truncation=True,\\\n return_tensors=pt,\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n top_k=0,\\\n num_beams=3,\\\n no_repeat_ngram_size=3\\\n)[0]\\\nsummary = tokenizer.decode(output_ids, skip_special_tokens=True)\\\nprint(summary)\\', \\'performance\\': {\\'dataset\\': [{\\'name\\': \\'SAMSum Corpus (translated to Russian)\\', \\'accuracy\\': {\\'Validation ROGUE-1\\': 34.5, \\'Validation ROGUE-L\\': 33, \\'Test ROGUE-1\\': 31, \\'Test ROGUE-L\\': 28}}]}, \\'description\\': \\'MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 95, "text": " I want you to create a function that generates captions for a list of images.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'videomae-small-finetuned-ssv2\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-small-finetuned-ssv2\\')\", \\'api_arguments\\': {\\'model_name\\': \\'MCG-NJU/videomae-small-finetuned-ssv2\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\\', \\'numpy\\': \\'import numpy as np\\', \\'torch\\': \\'import torch\\'}, \\'example_code\\': \\'video = list(np.random.randn(16, 3, 224, 224))\\\nfeature_extractor = VideoMAEFeatureExtractor.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\nmodel = VideoMAEForVideoClassification.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\ninputs = feature_extractor(video, return_tensors=pt)\\\nwith torch.no_grad():\\\n  outputs = model(**inputs)\\\n  logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'Something-Something V2\\', \\'accuracy\\': {\\'top-1\\': 66.8, \\'top-5\\': 90.3}}, \\'description\\': \\'VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 96, "text": " We need a tool to help us generate textual descriptions for images and videos related to our product.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 97, "text": " We need to build an AI-powered tool to assist visually impaired users in understanding their surroundings by answering questions about images.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 98, "text": " I'm a nutritionist and want to help my clients by answering questions about their meals. They will send me an image of their food and ask me a question about it, like \\\"Is this vegan?\\\" or \\\"How many calories do you think it contains?\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'PyTorch Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'table-question-answering-tapas\\', \\'api_call\\': \"pipeline(\\'table-question-answering\\', model=\\'Meena/table-question-answering-tapas\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'This model can be loaded on the Inference API on-demand.\\', \\'performance\\': {\\'dataset\\': [{\\'name\\': \\'SQA (Sequential Question Answering by Microsoft)\\', \\'accuracy\\': None}, {\\'name\\': \\'WTQ (Wiki Table Questions by Stanford University)\\', \\'accuracy\\': None}, {\\'name\\': \\'WikiSQL (by Salesforce)\\', \\'accuracy\\': None}]}, \\'description\\': \\'TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 99, "text": " Our client is a legal firm that needs assistance in extracting specific information from a large number of legal documents. Automate the process of answering questions related to these documents.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Fill-Mask\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Fill-Mask\\', \\'api_name\\': \\'nlpaueb/legal-bert-small-uncased\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'nlpaueb/legal-bert-small-uncased\\')\", \\'api_arguments\\': {\\'pretrained_model_name_or_path\\': \\'nlpaueb/legal-bert-small-uncased\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'AutoTokenizer, AutoModel\\'}, \\'example_code\\': \"from transformers import AutoTokenizer, AutoModel\\\ntokenizer = AutoTokenizer.from_pretrained(\\'nlpaueb/legal-bert-small-uncased\\')\\\nmodel = AutoModel.from_pretrained(\\'nlpaueb/legal-bert-small-uncased\\')\", \\'performance\\': {\\'dataset\\': \\'Legal Corpora\\', \\'accuracy\\': \\'Comparable to larger models\\'}, \\'description\\': \\'LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 100, "text": " In a healthcare company, we are trying to create an automated system for answering patient-related questions based on their medical documents. We need a solution using NLP.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 101, "text": " Develop a program which can answer questions related to a scanned document.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'google/tapas-small-finetuned-wikisql-supervised\\', \\'api_call\\': \"TapasForQuestionAnswering.from_pretrained(\\'google/tapas-small-finetuned-wikisql-supervised\\')\", \\'api_arguments\\': \"model = TapasForQuestionAnswering.from_pretrained(\\'google/tapas-small-finetuned-wikisql-supervised\\')\", \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"from transformers import TapasTokenizer, TapasForQuestionAnswering\\\ntokenizer = TapasTokenizer.from_pretrained(\\'google/tapas-small-finetuned-wikisql-supervised\\')\\\nmodel = TapasForQuestionAnswering.from_pretrained(\\'google/tapas-small-finetuned-wikisql-supervised\\')\", \\'performance\\': {\\'dataset\\': \\'wikisql\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 102, "text": " I have received a PDF document and a question. My task is to find the answer part in the document.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'distilbert-base-uncased-distilled-squad\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'distilbert-base-uncased-distilled-squad\\')\", \\'api_arguments\\': [\\'question\\', \\'context\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\nquestion_answerer = pipeline(question-answering, model=\\'distilbert-base-uncased-distilled-squad\\')\\\ncontext = r\\\n... Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\\\n... question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\\\n... a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\\\n... \\\nresult = question_answerer(question=What is a good example of a question answering dataset?, context=context)\\\nprint(\\\n... fAnswer: \\'{result[\\'answer\\']}\\', score: {round(result[\\'score\\'], 4)}, start: {result[\\'start\\']}, end: {result[\\'end\\']}\\\n...)\", \\'performance\\': {\\'dataset\\': \\'SQuAD v1.1\\', \\'accuracy\\': \\'86.9 F1 score\\'}, \\'description\\': \"DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT\\'s performances as measured on the GLUE language understanding benchmark.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 103, "text": " An interior design firm builds a software to understand the depth of rooms captured in photographs for remodeling activities.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text2Text Generation\\', \\'api_name\\': \\'DialogLED-base-16384\\', \\'api_call\\': \"LEDForConditionalGeneration.from_pretrained(\\'MingZhong/DialogLED-base-16384\\')\", \\'api_arguments\\': \\'input_text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'arxiv\\', \\'accuracy\\': \\'2109.02492\\'}, \\'description\\': \\'DialogLED is a pre-trained model for long dialogue understanding and summarization. It builds on the Longformer-Encoder-Decoder (LED) architecture and uses window-based denoising as the pre-training task on a large amount of long dialogue data for further training. Here is a base version of DialogLED, the input length is limited to 16,384 in the pre-training phase.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 104, "text": " We are running an autonomous vehicle company and want to implement a depth estimation module for the real-time video feed captured by our camera.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 105, "text": " Our team wants to create a new app for autonomous vehicles. For that, we need to estimate the depth of the field from images.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'dreamlike-art/dreamlike-photoreal-2.0\\', \\'api_call\\': \"StableDiffusionPipeline.from_pretrained(\\'dreamlike-art/dreamlike-photoreal-2.0\\', torch_dtype=torch.float16)(prompt).images[0]\", \\'api_arguments\\': {\\'prompt\\': \\'photo, a church in the middle of a field of crops, bright cinematic lighting, gopro, fisheye lens\\'}, \\'python_environment_requirements\\': {\\'torch\\': \\'torch.float16\\', \\'diffusers\\': \\'StableDiffusionPipeline\\'}, \\'example_code\\': \\'from diffusers import StableDiffusionPipeline\\\nimport torch\\\nmodel_id = dreamlike-art/dreamlike-photoreal-2.0\\\npipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\\\npipe = pipe.to(cuda)\\\nprompt = photo, a church in the middle of a field of crops, bright cinematic lighting, gopro, fisheye lens\\\nimage = pipe(prompt).images[0]\\\nimage.save(./result.jpg)\\', \\'performance\\': {\\'dataset\\': \\'Stable Diffusion 1.5\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 106, "text": " As a city planner, I need to measure the depth of spaces in a series of images taken from streets.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Zero-Shot Image Classification\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Zero-Shot Image Classification\\', \\'api_name\\': \\'laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\\', \\'api_call\\': \"pipeline(\\'image-classification\\', model=\\'laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\\')\", \\'api_arguments\\': \\'image_path, class_names\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"results = model(image_path, class_names=\\'cat, dog, bird\\')\", \\'performance\\': {\\'dataset\\': \\'ImageNet-1k\\', \\'accuracy\\': \\'76.9\\'}, \\'description\\': \\'A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 107, "text": " In our online ecommerce platform, we want to build an AI app to automatically recognize the type of products. It should be able to identify common items like clothing, electronics, furniture, and more.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 108, "text": " We need to recognize the breed of dog in the given image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 109, "text": " Develop a solution that can categorize an image of a cell phone, laptop, or smartwatch as one of these respective device types.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'zero-shot-object-detection\\', \\'api_name\\': \\'google/owlvit-base-patch16\\', \\'api_call\\': \"OwlViTForObjectDetection.from_pretrained(\\'google/owlvit-base-patch16\\')\", \\'api_arguments\\': [\\'texts\\', \\'images\\'], \\'python_environment_requirements\\': [\\'requests\\', \\'PIL\\', \\'torch\\', \\'transformers\\'], \\'example_code\\': \\'processor = OwlViTProcessor.from_pretrained(google/owlvit-base-patch16)\\\nmodel = OwlViTForObjectDetection.from_pretrained(google/owlvit-base-patch16)\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\ntexts = [[a photo of a cat, a photo of a dog]]\\\ninputs = processor(text=texts, images=image, return_tensors=pt)\\\noutputs = model(**inputs)\\\ntarget_sizes = torch.Tensor([image.size[::-1]])\\\nresults = processor.post_process(outputs=outputs, target_sizes=target_sizes)\\', \\'performance\\': {\\'dataset\\': \\'COCO\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. OWL-ViT uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 110, "text": " Build a system to help companies identify logos from a collection of images.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'ToddGoldfarb/Cadet-Tiny\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'ToddGoldfarb/Cadet-Tiny\\', low_cpu_mem_usage=True)\", \\'api_arguments\\': {\\'pretrained_model\\': \\'t5-small\\', \\'model_max_length\\': 512}, \\'python_environment_requirements\\': {\\'torch\\': \\'\\', \\'transformers\\': \\'\\', \\'colorful\\': \\'\\'}, \\'example_code\\': \"import torch\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nimport colorful as cf\\\ncf.use_true_colors()\\\ncf.use_style(\\'monokai\\')\\\nclass CadetTinyAgent:\\\n def <strong>init</strong>(self):\\\n  print(cf.bold | cf.purple(Waking up Cadet-Tiny...))\\\n  self.device = torch.device(cuda if torch.cuda.is_available() else cpu)\\\n  self.tokenizer = AutoTokenizer.from_pretrained(t5-small, model_max_length=512)\\\n  self.model = AutoModelForSeq2SeqLM.from_pretrained(ToddGoldfarb/Cadet-Tiny, low_cpu_mem_usage=True).to(self.device)\\\n  self.conversation_history = \\\ndef observe(self, observation):\\\n self.conversation_history = self.conversation_history + observation\\\n # The number 400 below is just a truncation safety net. It leaves room for 112 input tokens.\\\n if len(self.conversation_history) &gt; 400:\\\n self.conversation_history = self.conversation_history[112:]\\\ndef set_input(self, situation_narrative=, role_instruction=):\\\n input_text = dialogue: \\\n if situation_narrative != :\\\n input_text = input_text + situation_narrative\\\n if role_instruction != :\\\n input_text = input_text +  &lt;SEP&gt;  + role_instruction\\\n input_text = input_text +  &lt;TURN&gt;  + self.conversation_history\\\n # Uncomment the line below to see what is fed to the model.\\\n # print(input_text)\\\n return input_text\\\ndef generate(self, situation_narrative, role_instruction, user_response):\\\n user_response = user_response +  &lt;TURN&gt; \\\n self.observe(user_response)\\\n input_text = self.set_input(situation_narrative, role_instruction)\\\n inputs = self.tokenizer([input_text], return_tensors=pt).to(self.device)\\\n # I encourage you to change the hyperparameters of the model! Start by trying to modify the temperature.\\\n outputs = self.model.generate(inputs[input_ids], max_new_tokens=512, temperature=1, top_p=.95,\\\n do_sample=True)\\\n cadet_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\\\n added_turn = cadet_response +  &lt;TURN&gt; \\\n self.observe(added_turn)\\\n return cadet_response\\\ndef reset_history(self):\\\n self.conversation_history = []\\\ndef run(self):\\\n def get_valid_input(prompt, default):\\\n  while True:\\\n   user_input = input(prompt)\\\n   if user_input in [Y, N, y, n]:\\\n    return user_input\\\n   if user_input == :\\\n    return default\\\n  while True:\\\n   continue_chat = \\\n   # MODIFY THESE STRINGS TO YOUR LIKING :)\\\n   situation_narrative = Imagine you are Cadet-Tiny talking to ???.\\\n   role_instruction = You are Cadet-Tiny, and you are talking to ???.\\\n   self.chat(situation_narrative, role_instruction)\\\n   continue_chat = get_valid_input(cf.purple(Start a new conversation with new setup? [Y/N]:), Y)\\\n   if continue_chat in [N, n]:\\\n    break\\\n   print(cf.blue(CT: See you!))\\\ndef chat(self, situation_narrative, role_instruction):\\\n print(cf.green(\\\n  Cadet-Tiny is running! Input [RESET] to reset the conversation history and [END] to end the conversation.))\\\n while True:\\\n  user_input = input(You: )\\\n  if user_input == [RESET]:\\\n   self.reset_history()\\\n   print(cf.green([Conversation history cleared. Chat with Cadet-Tiny!]))\\\n   continue\\\n  if user_input == [END]:\\\n   break\\\n  response = self.generate(situation_narrative, role_instruction, user_input)\\\n  print(cf.blue(CT:  + response))\\\ndef main():\\\n print(cf.bold | cf.blue(LOADING MODEL))\\\nCadetTiny = CadetTinyAgent()\\\nCadetTiny.run()\\\nif <strong>name</strong> == \\'<strong>main</strong>\\':\\\n main()\", \\'performance\\': {\\'dataset\\': \\'allenai/soda\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 111, "text": " Develop a pipeline that detects objects present in an image using computer vision.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Voice Activity Detection\\', \\'framework\\': \\'pyannote.audio\\', \\'functionality\\': \\'Automatic Speech Recognition\\', \\'api_name\\': \\'pyannote/voice-activity-detection\\', \\'api_call\\': \"Pipeline.from_pretrained(\\'pyannote/voice-activity-detection\\')\", \\'api_arguments\\': [\\'audio.wav\\'], \\'python_environment_requirements\\': [\\'pyannote.audio 2.1\\'], \\'example_code\\': \\'from pyannote.audio import Pipeline\\\npipeline = Pipeline.from_pretrained(pyannote/voice-activity-detection, use_auth_token=ACCESS_TOKEN_GOES_HERE)\\\noutput = pipeline(audio.wav)\\\nfor speech in output.get_timeline().support():\\\n  # active speech between speech.start and speech.end\\', \\'performance\\': {\\'dataset\\': \\'ami\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'A pretrained voice activity detection pipeline that detects active speech in audio files.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 112, "text": " Assit me to process and segment an image for further analysis.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Unconditional Image Generation\\', \\'api_name\\': \\'CompVis/ldm-celebahq-256\\', \\'api_call\\': \"DiffusionPipeline.from_pretrained(\\'CompVis/ldm-celebahq-256\\')\", \\'api_arguments\\': [\\'model_id\\'], \\'python_environment_requirements\\': [\\'diffusers\\'], \\'example_code\\': \\'!pip install diffusers\\\nfrom diffusers import DiffusionPipeline\\\nmodel_id = CompVis/ldm-celebahq-256\\\npipeline = DiffusionPipeline.from_pretrained(model_id)\\\nimage = pipeline(num_inference_steps=200)[sample]\\\nimage[0].save(ldm_generated_image.png)\\', \\'performance\\': {\\'dataset\\': \\'CelebA-HQ\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 113, "text": " We need to analyze satellite images to categorize the types of land use. For this purpose, I need to segment the images and identify different objects.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 114, "text": " We are a city planning department and want to evaluate the city layout. Analyze the image we provide to segment and understand the various urban elements.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 115, "text": " My company develops drones for agriculture purposes, and we need a model to segment aerial images accurately.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image Generation\\', \\'api_name\\': \\'stabilityai/stable-diffusion-2\\', \\'api_call\\': \"StableDiffusionPipeline.from_pretrained(\\'stabilityai/stable-diffusion-2\\', scheduler=EulerDiscreteScheduler.from_pretrained(\\'stabilityai/stable-diffusion-2\\', subfolder=scheduler), torch_dtype=torch.float16)\", \\'api_arguments\\': {\\'prompt\\': \\'a photo of an astronaut riding a horse on mars\\'}, \\'python_environment_requirements\\': [\\'diffusers\\', \\'transformers\\', \\'accelerate\\', \\'scipy\\', \\'safetensors\\'], \\'example_code\\': \\'from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\\\nmodel_id = stabilityai/stable-diffusion-2\\\nscheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=scheduler)\\\npipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\\\npipe = pipe.to(cuda)\\\nprompt = a photo of an astronaut riding a horse on mars\\\nimage = pipe(prompt).images[0]\\\nimage.save(astronaut_rides_horse.png)\\', \\'performance\\': {\\'dataset\\': \\'COCO2017 validation set\\', \\'accuracy\\': \\'Not optimized for FID scores\\'}, \\'description\\': \\'Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 116, "text": " I want to generate images from text descriptions and use the scribble images as control inputs for my project.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Image-to-Image\\', \\'api_name\\': \\'GreeneryScenery/SheepsControlV3\\', \\'api_call\\': \"pipeline(\\'image-to-image\\', model=\\'GreeneryScenery/SheepsControlV3\\')\", \\'api_arguments\\': {\\'image\\': \\'Path to image file\\', \\'text_guidance\\': \\'Optional text guidance for the model\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'latest\\', \\'torch\\': \\'latest\\'}, \\'example_code\\': [\\'from transformers import pipeline\\', \"model = pipeline(\\'image-to-image\\', model=\\'GreeneryScenery/SheepsControlV3\\')\", \"result = model({\\'image\\': \\'path/to/image.jpg\\', \\'text_guidance\\': \\'Optional text guidance\\'})\"], \\'performance\\': {\\'dataset\\': \\'GreeneryScenery/SheepsControlV3\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 118, "text": " We want to recommend workouts to our users, based on the type of sports they enjoy. Help us classify sports videos.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 119, "text": " We need to classify videos showing different actions for our new video moderation system.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 120, "text": " I need the AI to tell if an image is of a cat or a dog, regardless of its breed or species.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'ToddGoldfarb/Cadet-Tiny\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'ToddGoldfarb/Cadet-Tiny\\', low_cpu_mem_usage=True)\", \\'api_arguments\\': {\\'pretrained_model\\': \\'t5-small\\', \\'model_max_length\\': 512}, \\'python_environment_requirements\\': {\\'torch\\': \\'\\', \\'transformers\\': \\'\\', \\'colorful\\': \\'\\'}, \\'example_code\\': \"import torch\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nimport colorful as cf\\\ncf.use_true_colors()\\\ncf.use_style(\\'monokai\\')\\\nclass CadetTinyAgent:\\\n def <strong>init</strong>(self):\\\n  print(cf.bold | cf.purple(Waking up Cadet-Tiny...))\\\n  self.device = torch.device(cuda if torch.cuda.is_available() else cpu)\\\n  self.tokenizer = AutoTokenizer.from_pretrained(t5-small, model_max_length=512)\\\n  self.model = AutoModelForSeq2SeqLM.from_pretrained(ToddGoldfarb/Cadet-Tiny, low_cpu_mem_usage=True).to(self.device)\\\n  self.conversation_history = \\\ndef observe(self, observation):\\\n self.conversation_history = self.conversation_history + observation\\\n # The number 400 below is just a truncation safety net. It leaves room for 112 input tokens.\\\n if len(self.conversation_history) &gt; 400:\\\n self.conversation_history = self.conversation_history[112:]\\\ndef set_input(self, situation_narrative=, role_instruction=):\\\n input_text = dialogue: \\\n if situation_narrative != :\\\n input_text = input_text + situation_narrative\\\n if role_instruction != :\\\n input_text = input_text +  &lt;SEP&gt;  + role_instruction\\\n input_text = input_text +  &lt;TURN&gt;  + self.conversation_history\\\n # Uncomment the line below to see what is fed to the model.\\\n # print(input_text)\\\n return input_text\\\ndef generate(self, situation_narrative, role_instruction, user_response):\\\n user_response = user_response +  &lt;TURN&gt; \\\n self.observe(user_response)\\\n input_text = self.set_input(situation_narrative, role_instruction)\\\n inputs = self.tokenizer([input_text], return_tensors=pt).to(self.device)\\\n # I encourage you to change the hyperparameters of the model! Start by trying to modify the temperature.\\\n outputs = self.model.generate(inputs[input_ids], max_new_tokens=512, temperature=1, top_p=.95,\\\n do_sample=True)\\\n cadet_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\\\n added_turn = cadet_response +  &lt;TURN&gt; \\\n self.observe(added_turn)\\\n return cadet_response\\\ndef reset_history(self):\\\n self.conversation_history = []\\\ndef run(self):\\\n def get_valid_input(prompt, default):\\\n  while True:\\\n   user_input = input(prompt)\\\n   if user_input in [Y, N, y, n]:\\\n    return user_input\\\n   if user_input == :\\\n    return default\\\n  while True:\\\n   continue_chat = \\\n   # MODIFY THESE STRINGS TO YOUR LIKING :)\\\n   situation_narrative = Imagine you are Cadet-Tiny talking to ???.\\\n   role_instruction = You are Cadet-Tiny, and you are talking to ???.\\\n   self.chat(situation_narrative, role_instruction)\\\n   continue_chat = get_valid_input(cf.purple(Start a new conversation with new setup? [Y/N]:), Y)\\\n   if continue_chat in [N, n]:\\\n    break\\\n   print(cf.blue(CT: See you!))\\\ndef chat(self, situation_narrative, role_instruction):\\\n print(cf.green(\\\n  Cadet-Tiny is running! Input [RESET] to reset the conversation history and [END] to end the conversation.))\\\n while True:\\\n  user_input = input(You: )\\\n  if user_input == [RESET]:\\\n   self.reset_history()\\\n   print(cf.green([Conversation history cleared. Chat with Cadet-Tiny!]))\\\n   continue\\\n  if user_input == [END]:\\\n   break\\\n  response = self.generate(situation_narrative, role_instruction, user_input)\\\n  print(cf.blue(CT:  + response))\\\ndef main():\\\n print(cf.bold | cf.blue(LOADING MODEL))\\\nCadetTiny = CadetTinyAgent()\\\nCadetTiny.run()\\\nif <strong>name</strong> == \\'<strong>main</strong>\\':\\\n main()\", \\'performance\\': {\\'dataset\\': \\'allenai/soda\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 121, "text": " We have a set of pictures for pets (dogs and cats). We need to offer an AI-based solution to classify the pictures given the pet name.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 122, "text": " Our startup team is now building an app for diagnosing plant diseases based on images. We need to get the diagnosis for different types of plant issues.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Generative Commonsense Reasoning\\', \\'api_name\\': \\'mrm8488/t5-base-finetuned-common_gen\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'mrm8488/t5-base-finetuned-common_gen\\')\", \\'api_arguments\\': [\\'words\\', \\'max_length\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import AutoModelWithLMHead, AutoTokenizer\\\ntokenizer = AutoTokenizer.from_pretrained(mrm8488/t5-base-finetuned-common_gen)\\\nmodel = AutoModelWithLMHead.from_pretrained(mrm8488/t5-base-finetuned-common_gen)\\\ndef gen_sentence(words, max_length=32):\\\n input_text = words\\\n features = tokenizer([input_text], return_tensors=\\'pt\\')\\\noutput = model.generate(input_ids=features[\\'input_ids\\'], attention_mask=features[\\'attention_mask\\'], max_length=max_length)\\\nreturn tokenizer.decode(output[0], skip_special_tokens=True)\\\nwords = tree plant ground hole dig\\\ngen_sentence(words)\", \\'performance\\': {\\'dataset\\': \\'common_gen\\', \\'accuracy\\': {\\'ROUGE-2\\': 17.1, \\'ROUGE-L\\': 39.47}}, \\'description\\': \"Google\\'s T5 fine-tuned on CommonGen for Generative Commonsense Reasoning. CommonGen is a constrained text generation task, associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts; the task is to generate a coherent sentence describing an everyday scenario using these concepts.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 123, "text": " We need to analyze customer reviews and find out how well our new product is doing in the market.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 124, "text": " A new tutoring company is founded, and they want a tutoring AI. To do so, they need help in creating better explanations for a chemistry concept.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'financial-summarization-pegasus\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'human-centered-summarization/financial-summarization-pegasus\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import PegasusTokenizer, PegasusForConditionalGeneration, TFPegasusForConditionalGeneration\\\nmodel_name = human-centered-summarization/financial-summarization-pegasus\\\ntokenizer = PegasusTokenizer.from_pretrained(model_name)\\\nmodel = PegasusForConditionalGeneration.from_pretrained(model_name)\\\ntext_to_summarize = National Commercial Bank (NCB), Saudi Arabiaâ€™s largest lender by assets, agreed to buy rival Samba Financial Group for $15 billion in the biggest banking takeover this year.NCB will pay 28.45 riyals ($7.58) for each Samba share, according to a statement on Sunday, valuing it at about 55.7 billion riyals. NCB will offer 0.739 new shares for each Samba share, at the lower end of the 0.736-0.787 ratio the banks set when they signed an initial framework agreement in June.The offer is a 3.5% premium to Sambaâ€™s Oct. 8 closing price of 27.50 riyals and about 24% higher than the level the shares traded at before the talks were made public. Bloomberg News first reported the merger discussions.The new bank will have total assets of more than $220 billion, creating the Gulf regionâ€™s third-largest lender. The entityâ€™s $46 billion market capitalization nearly matches that of Qatar National Bank QPSC, which is still the Middle Eastâ€™s biggest lender with about $268 billion of assets.\\\ninput_ids = tokenizer(text_to_summarize, return_tensors=pt).input_ids\\\noutput = model.generate(input_ids, max_length=32, num_beams=5, early_stopping=True)\\\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\\', \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 35.206, \\'ROUGE-2\\': 16.569, \\'ROUGE-L\\': 30.128, \\'ROUGE-LSUM\\': 30.171}}, \\'description\\': \\'This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 125, "text": " Create a function that can determine if a given text is a question or a statement.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'results-yelp\\', \\'api_call\\': \"AutoTokenizer.from_pretrained(\\'bert-base-uncased\\')\", \\'api_arguments\\': {\\'tokenizer\\': \"AutoTokenizer.from_pretrained(\\'bert-base-uncased\\')\", \\'config\\': \"AutoConfig.from_pretrained(\\'potatobunny/results-yelp\\')\"}, \\'python_environment_requirements\\': {\\'Transformers\\': \\'4.18.0\\', \\'Pytorch\\': \\'1.10.0+cu111\\', \\'Datasets\\': \\'2.0.0\\', \\'Tokenizers\\': \\'0.12.1\\'}, \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'Yelp\\', \\'accuracy\\': 0.9302}, \\'description\\': \\'This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 126, "text": " I want to create a system that can answer questions by sorting out possible answers to a question.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'deepset/roberta-large-squad2\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'deepset/roberta-large-squad2\\')\", \\'api_arguments\\': [\\'question\\', \\'context\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline; nlp = pipeline(\\'question-answering\\', model=\\'deepset/roberta-large-squad2\\'); nlp({\\'question\\': \\'What is the capital of Germany?\\', \\'context\\': \\'Berlin is the capital of Germany.\\'})\", \\'performance\\': {\\'dataset\\': \\'squad_v2\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 127, "text": " We have a news article and we need to extract all the entities like the names of people, organizations, and locations.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Feature Extraction\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Feature Extraction\\', \\'api_name\\': \\'DeepPavlov/rubert-base-cased\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'DeepPavlov/rubert-base-cased\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'Russian part of Wikipedia and news data\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'RuBERT (Russian, cased, 12â€‘layer, 768â€‘hidden, 12â€‘heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERTâ€‘base as an initialization for RuBERT[1].\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 128, "text": " We are purchasing a CRM system to keep track of our customers and their organizations. We want to extract useful entities from customer emails automatically.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 129, "text": " As a researcher, I am trying to find an answer to my question in a table containing information about animals and their characteristics.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 130, "text": " A teacher wants to create a quiz for her students. We are now working on the questions and answers for the quiz that be arranged in a table format.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'google/tapas-base-finetuned-sqa\\', \\'api_call\\': \"TapasTokenizer.from_pretrained(\\'google/tapas-base-finetuned-sqa\\')\", \\'api_arguments\\': [\\'question\\', \\'table\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\n\\\n# Initialize the pipeline\\\ntapas_pipeline = pipeline(\\'table-question-answering\\', model=\\'google/tapas-base-finetuned-sqa\\')\\\n\\\n# Define the table and question\\\nquestion = \\'How many goals did player A score?\\'\\\ntable = [[\\'Player\\', \\'Goals\\'], [\\'Player A\\', 5], [\\'Player B\\', 3]]\\\n\\\n# Get the answer\\\nresult = tapas_pipeline(question=question, table=table)\\\nprint(result)\", \\'performance\\': {\\'dataset\\': \\'msr_sqa\\', \\'accuracy\\': 0.6874}, \\'description\\': \\'TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 131, "text": " I work for a financial company that stores all of its data in tables. We need a way to extract key information efficiently by asking natural language questions.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 132, "text": " We have a dataset related to coffee and tea prices. We need to answer a question on who sells hot chocolate and their prices.\n###Input: {\\\"table\\\": [[\\\"Shop\\\", \\\"Drink\\\", \\\"Price\\\"], [\\\"Cafe A\\\", \\\"Coffee\\\", \\\"3.00\\\"], [\\\"Cafe B\\\", \\\"Tea\\\", \\\"2.50\\\"], [\\\"Cafe C\\\", \\\"Hot Chocolate\\\", \\\"4.50\\\"], [\\\"Cafe D\\\", \\\"Hot Chocolate\\\", \\\"3.75\\\"]], \\\"queries\\\": [\\\"Which shops sell hot chocolate and what are their prices?\\\"]}\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 133, "text": " A company is running a survey and they want to know how many respondents have given a specific answer for each question of the survey.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 134, "text": " Extract information about a non-compete clause from a legal document with a context related to data protection.\n###Input: \\\"The data protection provisions set forth in this agreement shall be in effect for a period of 2 years after the termination of services. The non-compete clause states that the service provider is prohibited from providing similar services to any competitor within a 50-mile radius and during the 1-year period following termination of services.\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 135, "text": " Tell me the day of the game when it was played given the following context: \\\"The game was played on February 7, 2016 at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\\\"\n###Input: {'context': \\\"The game was played on February 7, 2016 at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\\\", 'question': \\\"What day was the game played on?\\\"}\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'csarron/bert-base-uncased-squad-v1\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'csarron/bert-base-uncased-squad-v1\\', tokenizer=\\'csarron/bert-base-uncased-squad-v1\\')\", \\'api_arguments\\': {\\'model\\': \\'csarron/bert-base-uncased-squad-v1\\', \\'tokenizer\\': \\'csarron/bert-base-uncased-squad-v1\\'}, \\'python_environment_requirements\\': \\'Python 3.7.5\\', \\'example_code\\': \"from transformers import pipeline\\\nqa_pipeline = pipeline(\\\n question-answering,\\\n model=csarron/bert-base-uncased-squad-v1,\\\n tokenizer=csarron/bert-base-uncased-squad-v1\\\n)\\\npredictions = qa_pipeline({\\\n \\'context\\': The game was played on February 7, 2016 at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California.,\\\n \\'question\\': What day was the game played on?\\\n})\\\nprint(predictions)\", \\'performance\\': {\\'dataset\\': \\'SQuAD1.1\\', \\'accuracy\\': {\\'EM\\': 80.9, \\'F1\\': 88.2}}, \\'description\\': \\'BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 136, "text": " We need to identify the relationship between two sentences whether they are contradictory, entail each other, or neutral.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'pyannote.audio\\', \\'functionality\\': \\'overlapped-speech-detection\\', \\'api_name\\': \\'pyannote/overlapped-speech-detection\\', \\'api_call\\': \"pipeline.from_pretrained(\\'pyannote/overlapped-speech-detection\\', use_auth_token=\\'ACCESS_TOKEN_GOES_HERE\\')\", \\'api_arguments\\': [\\'audio.wav\\'], \\'python_environment_requirements\\': [\\'pyannote.audio 2.1\\'], \\'example_code\\': \\'from pyannote.audio import Pipeline\\\npipeline = Pipeline.from_pretrained(pyannote/overlapped-speech-detection, use_auth_token=ACCESS_TOKEN_GOES_HERE)\\\noutput = pipeline(audio.wav)\\\nfor speech in output.get_timeline().support():\\\n  # two or more speakers are active between speech.start and speech.end\\\n  ...\\', \\'performance\\': {\\'dataset\\': \\'ami\\', \\'accuracy\\': None}, \\'description\\': \\'Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 137, "text": " I am a climate change agency, looking to have my research summaries translated into Chinese for international audiences.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 138, "text": " We are building an app to summarize long articles for users. We need a solution to create a condensed summary of the given text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 139, "text": " A news agency wants to summaries their international news articles daily.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Feature Extraction\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Feature Extraction\\', \\'api_name\\': \\'DeepPavlov/rubert-base-cased\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'DeepPavlov/rubert-base-cased\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'Russian part of Wikipedia and news data\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'RuBERT (Russian, cased, 12â€‘layer, 768â€‘hidden, 12â€‘heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERTâ€‘base as an initialization for RuBERT[1].\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 140, "text": " Design a smart home system that can have conversations with the user for controlling the home appliances.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'videomae-small-finetuned-ssv2\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-small-finetuned-ssv2\\')\", \\'api_arguments\\': {\\'model_name\\': \\'MCG-NJU/videomae-small-finetuned-ssv2\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\\', \\'numpy\\': \\'import numpy as np\\', \\'torch\\': \\'import torch\\'}, \\'example_code\\': \\'video = list(np.random.randn(16, 3, 224, 224))\\\nfeature_extractor = VideoMAEFeatureExtractor.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\nmodel = VideoMAEForVideoClassification.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\ninputs = feature_extractor(video, return_tensors=pt)\\\nwith torch.no_grad():\\\n  outputs = model(**inputs)\\\n  logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'Something-Something V2\\', \\'accuracy\\': {\\'top-1\\': 66.8, \\'top-5\\': 90.3}}, \\'description\\': \\'VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 141, "text": " An educational publishing company is developing a language comprehension program for elementary school students. They want a system that can generate a short story based on a given prompt.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Program Synthesis\\', \\'api_name\\': \\'Salesforce/codegen-350M-multi\\', \\'api_call\\': \"AutoTokenizer.from_pretrained(\\'Salesforce/codegen-350M-multi\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelForCausalLM\\\ntokenizer = AutoTokenizer.from_pretrained(Salesforce/codegen-350M-multi)\\\nmodel = AutoModelForCausalLM.from_pretrained(Salesforce/codegen-350M-multi)\\\ntext = def hello_world():\\\ninput_ids = tokenizer(text, return_tensors=pt).input_ids\\\ngenerated_ids = model.generate(input_ids, max_length=128)\\\nprint(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\\', \\'performance\\': {\\'dataset\\': \\'HumanEval and MTPB\\', \\'accuracy\\': \\'Refer to the paper for accuracy details\\'}, \\'description\\': \\'CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 142, "text": " Can you initiate a conversation with an AI model that plays the role of a friend who just got back from a conference?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'videomae-small-finetuned-ssv2\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-small-finetuned-ssv2\\')\", \\'api_arguments\\': {\\'model_name\\': \\'MCG-NJU/videomae-small-finetuned-ssv2\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\\', \\'numpy\\': \\'import numpy as np\\', \\'torch\\': \\'import torch\\'}, \\'example_code\\': \\'video = list(np.random.randn(16, 3, 224, 224))\\\nfeature_extractor = VideoMAEFeatureExtractor.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\nmodel = VideoMAEForVideoClassification.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\ninputs = feature_extractor(video, return_tensors=pt)\\\nwith torch.no_grad():\\\n  outputs = model(**inputs)\\\n  logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'Something-Something V2\\', \\'accuracy\\': {\\'top-1\\': 66.8, \\'top-5\\': 90.3}}, \\'description\\': \\'VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 143, "text": " As a software developer, I want a program that can automatically generate code snippets for me based on natural language descriptions.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Program Synthesis\\', \\'api_name\\': \\'Salesforce/codegen-350M-multi\\', \\'api_call\\': \"AutoTokenizer.from_pretrained(\\'Salesforce/codegen-350M-multi\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelForCausalLM\\\ntokenizer = AutoTokenizer.from_pretrained(Salesforce/codegen-350M-multi)\\\nmodel = AutoModelForCausalLM.from_pretrained(Salesforce/codegen-350M-multi)\\\ntext = def hello_world():\\\ninput_ids = tokenizer(text, return_tensors=pt).input_ids\\\ngenerated_ids = model.generate(input_ids, max_length=128)\\\nprint(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\\', \\'performance\\': {\\'dataset\\': \\'HumanEval and MTPB\\', \\'accuracy\\': \\'Refer to the paper for accuracy details\\'}, \\'description\\': \\'CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 144, "text": " Provide a short summary of an article about cryptocurrency investment risks.\n###Input: Cryptocurrencies have become exceedingly popular among investors seeking higher returns and diversification in their portfolios. However, investing in these digital currencies carries several inherent risks. Market volatility is a major factor \\u2013 cryptocurrencies can experience wild price swings, sometimes even within hours or minutes. This high volatility makes it difficult to predict the future value of the investments and can result in significant losses. Furthermore, the lack of regulatory oversight and security concerns may also lead to potential frauds and hacks, exposing investors to additional risk. Lastly, the environmental impact of mining digital currencies like Bitcoin has come under scrutiny, questioning the long-term sustainability of the cryptocurrency market.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 145, "text": " You have just met a person that speaks French. As a hotel manager, you need to tell them, \\\"Welcome to our hotel, we hope you enjoy your stay.\\\" in French.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Conversational\\', \\'api_name\\': \\'microsoft/GODEL-v1_1-large-seq2seq\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'microsoft/GODEL-v1_1-large-seq2seq\\')\", \\'api_arguments\\': {\\'instruction\\': \\'Instruction: given a dialog context, you need to response empathically.\\', \\'knowledge\\': \\'\\', \\'dialog\\': [\\'Does money buy happiness?\\', \\'It is a question. Money buys you a lot of things, but not enough to buy happiness.\\', \\'What is the best way to buy happiness ?\\']}, \\'python_environment_requirements\\': {\\'transformers\\': \\'AutoTokenizer, AutoModelForSeq2SeqLM\\'}, \\'example_code\\': \"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\ntokenizer = AutoTokenizer.from_pretrained(microsoft/GODEL-v1_1-large-seq2seq)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(microsoft/GODEL-v1_1-large-seq2seq)\\\ndef generate(instruction, knowledge, dialog):\\\n if knowledge != \\'\\':\\\n knowledge = \\'[KNOWLEDGE] \\' + knowledge\\\n dialog = \\' EOS \\'.join(dialog)\\\n query = f{instruction} [CONTEXT] {dialog} {knowledge}\\\n input_ids = tokenizer(f{query}, return_tensors=pt).input_ids\\\n outputs = model.generate(input_ids, max_length=128, min_length=8, top_p=0.9, do_sample=True)\\\n output = tokenizer.decode(outputs[0], skip_special_tokens=True)\\\n return output\\\n\\\ninstruction = f\\'Instruction: given a dialog context, you need to response empathically.\\'\\\nknowledge = \\'\\'\\\ndialog = [\\\n \\'Does money buy happiness?\\',\\\n \\'It is a question. Money buys you a lot of things, but not enough to buy happiness.\\',\\\n \\'What is the best way to buy happiness ?\\'\\\n]\\\nresponse = generate(instruction, knowledge, dialog)\\\nprint(response)\", \\'performance\\': {\\'dataset\\': \\'Reddit discussion thread, instruction and knowledge grounded dialogs\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 146, "text": " They are planning a trip to Germany and want to spend some leisure time in the parks of Munich, find out how to ask a question about the location of parks in Munich in German.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 147, "text": " We are a company offering speech to text services. We need to summarize the conversion and make it open-ended question.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 148, "text": " To help me with my writing, I need an AI tool that can fill in the gaps for me when I get stuck. It should be able to complete phrases or sentences.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 149, "text": " A writer needs help with generating the next word in the phrase \\\"The dog jumped over the\\\" __.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Image-to-Text\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'git-large-textcaps\\', \\'api_call\\': \"AutoModelForCausalLM.from_pretrained(\\'microsoft/git-large-textcaps\\')\", \\'api_arguments\\': \\'image, text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'N/A\\', \\'performance\\': {\\'dataset\\': \\'TextCaps\\', \\'accuracy\\': \\'Refer to the paper\\'}, \\'description\\': \"GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using \\'teacher forcing\\' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text).\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 151, "text": " Help me find similarity scores for different restaurant reviews.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Sentence Similarity\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Sentence Transformers\\', \\'api_name\\': \\'flax-sentence-embeddings/all_datasets_v4_MiniLM-L6\\', \\'api_call\\': \"SentenceTransformer(\\'flax-sentence-embeddings/all_datasets_v4_MiniLM-L6\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'sentence-transformers library\\', \\'example_code\\': \"from sentence_transformers import SentenceTransformer\\\nmodel = SentenceTransformer(\\'flax-sentence-embeddings/all_datasets_v4_MiniLM-L6\\')\\\ntext = Replace me by any text you\\'d like.\\\ntext_embbedding = model.encode(text)\", \\'performance\\': {\\'dataset\\': \\'1,097,953,922\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 152, "text": " Our company is building an automated assistance system for the visually impaired. We need a tool to convert text into spoken instructions.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Text-to-Speech\\', \\'framework\\': \\'ESPnet\\', \\'functionality\\': \\'Text-to-Speech\\', \\'api_name\\': \\'kan-bayashi_jvs_tts_finetune_jvs001_jsut_vits_raw_phn_jaconv_pyopenjta-truncated-178804\\', \\'api_call\\': \"AutoModelForCausalLM.from_pretrained(\\'espnet/kan-bayashi_jvs_tts_finetune_jvs001_jsut_vits_raw_phn_jaconv_pyopenjta-truncated-178804\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A Japanese text-to-speech model trained using the ESPnet framework. It is designed to convert text input into natural-sounding speech.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 153, "text": " I would like to create an application where users may listen to translations of English sentences. I need a Text-to-Speech model to support this functionality.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 154, "text": " We are a language learning app platform. We need a text-to-speech tool to read a sentence in multiple languages for our users.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 155, "text": " I need to create an audio output that translates the given text to speech for a French audiobook assistant.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Translation\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Translation\\', \\'api_name\\': \\'Helsinki-NLP/opus-mt-en-fr\\', \\'api_call\\': \"translate(\\'input_text\\', model=\\'Helsinki-NLP/opus-mt-en-fr\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'opus\\', \\'accuracy\\': {\\'BLEU\\': {\\'newsdiscussdev2015-enfr.en.fr\\': 33.8, \\'newsdiscusstest2015-enfr.en.fr\\': 40.0, \\'newssyscomb2009.en.fr\\': 29.8, \\'news-test2008.en.fr\\': 27.5, \\'newstest2009.en.fr\\': 29.4, \\'newstest2010.en.fr\\': 32.7, \\'newstest2011.en.fr\\': 34.3, \\'newstest2012.en.fr\\': 31.8, \\'newstest2013.en.fr\\': 33.2, \\'Tatoeba.en.fr\\': 50.5}}}, \\'description\\': \\'Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 156, "text": " We are opening a platform where users can record their own podcast and host it on our platform, can you help us to convert the audio into text automatically?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 157, "text": " We are currently working on the development of a speech-to-text application for transcription purposes. Can you help generate the required transcription code?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'videomae-small-finetuned-ssv2\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-small-finetuned-ssv2\\')\", \\'api_arguments\\': {\\'model_name\\': \\'MCG-NJU/videomae-small-finetuned-ssv2\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\\', \\'numpy\\': \\'import numpy as np\\', \\'torch\\': \\'import torch\\'}, \\'example_code\\': \\'video = list(np.random.randn(16, 3, 224, 224))\\\nfeature_extractor = VideoMAEFeatureExtractor.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\nmodel = VideoMAEForVideoClassification.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\ninputs = feature_extractor(video, return_tensors=pt)\\\nwith torch.no_grad():\\\n  outputs = model(**inputs)\\\n  logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'Something-Something V2\\', \\'accuracy\\': {\\'top-1\\': 66.8, \\'top-5\\': 90.3}}, \\'description\\': \\'VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 158, "text": " We are building an app for tour guides to transcribe what they say during the tour. Then the transcript will be translated into sign language.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 159, "text": " I am an English teacher. I have recently met a Hokkien speaker. I am looking to translate a conversational sentence from English to Hokkien to facilitate communication.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 160, "text": " Determine the keyword spoken in a recorded audio file.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Feature Extraction\\', \\'api_name\\': \\'microsoft/wavlm-large\\', \\'api_call\\': \"Wav2Vec2Model.from_pretrained(\\'microsoft/wavlm-large\\')\", \\'api_arguments\\': \\'speech input\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'To fine-tune the model for speech recognition, see the official speech recognition example. To fine-tune the model for speech classification, see the official audio classification example.\\', \\'performance\\': {\\'dataset\\': \\'SUPERB benchmark\\', \\'accuracy\\': \\'state-of-the-art performance\\'}, \\'description\\': \\'WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 161, "text": " Determine which speaker an audio segment belongs to using the provided audio file.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'pyannote.audio\\', \\'functionality\\': \\'Speaker Diarization\\', \\'api_name\\': \\'pyannote/speaker-diarization\\', \\'api_call\\': \"Pipeline.from_pretrained(\\'pyannote/speaker-diarization@2.1\\', use_auth_token=\\'ACCESS_TOKEN_GOES_HERE\\')\", \\'api_arguments\\': {\\'num_speakers\\': \\'int (optional)\\', \\'min_speakers\\': \\'int (optional)\\', \\'max_speakers\\': \\'int (optional)\\'}, \\'python_environment_requirements\\': \\'pyannote.audio 2.1.1\\', \\'example_code\\': [\\'from pyannote.audio import Pipeline\\', \\'pipeline = Pipeline.from_pretrained(pyannote/speaker-diarization@2.1, use_auth_token=ACCESS_TOKEN_GOES_HERE)\\', \\'diarization = pipeline(audio.wav)\\', \\'with open(audio.rttm, w) as rttm:\\', \\'  diarization.write_rttm(rttm)\\'], \\'performance\\': {\\'dataset\\': \\'ami\\', \\'accuracy\\': {\\'DER%\\': \\'18.91\\', \\'FA%\\': \\'4.48\\', \\'Miss%\\': \\'9.51\\', \\'Conf%\\': \\'4.91\\'}}, \\'description\\': \\'This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 162, "text": " We have a database of customer voices and are trying to build a voice recognition product so we can recognize customer voices when they call. How should we process and classify?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 163, "text": " We are developing a voice-controlled drone. Please identify the spoken command in the audio clip provided.\n###Input: \\\"audio_clip.wav\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 164, "text": " Make a summary video for our last team meeting. The audio from the video must identify who is speaking and when.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'camenduru/text2-video-zero\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'camenduru/text2-video-zero\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 165, "text": " I want to estimate the price of a house based on its features using this API. Please provide the code.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'videomae-small-finetuned-ssv2\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-small-finetuned-ssv2\\')\", \\'api_arguments\\': {\\'model_name\\': \\'MCG-NJU/videomae-small-finetuned-ssv2\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\\', \\'numpy\\': \\'import numpy as np\\', \\'torch\\': \\'import torch\\'}, \\'example_code\\': \\'video = list(np.random.randn(16, 3, 224, 224))\\\nfeature_extractor = VideoMAEFeatureExtractor.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\nmodel = VideoMAEForVideoClassification.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\ninputs = feature_extractor(video, return_tensors=pt)\\\nwith torch.no_grad():\\\n  outputs = model(**inputs)\\\n  logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'Something-Something V2\\', \\'accuracy\\': {\\'top-1\\': 66.8, \\'top-5\\': 90.3}}, \\'description\\': \\'VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 166, "text": " Our company wants to predict housing prices in the US based on given features. Help us use the trained model to predict the prices.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Joblib\\', \\'functionality\\': \\'Single Column Regression\\', \\'api_name\\': \\'jwan2021/autotrain-us-housing-prices-1771761512\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\', \\'json\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'jwan2021/autotrain-data-us-housing-prices\\', \\'accuracy\\': {\\'Loss\\': 122809.223, \\'R2\\': 0.884, \\'MSE\\': 15082105200.447, \\'MAE\\': 95586.887, \\'RMSLE\\': 0.13}}, \\'description\\': \\'A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 167, "text": " An environmental organization would like to use our Carbon Emissions prediction model to estimate CO2 emissions of different configurations of vehicles.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'distilbert-base-uncased-distilled-squad\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'distilbert-base-uncased-distilled-squad\\')\", \\'api_arguments\\': [\\'question\\', \\'context\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\nquestion_answerer = pipeline(question-answering, model=\\'distilbert-base-uncased-distilled-squad\\')\\\ncontext = r\\\n... Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\\\n... question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\\\n... a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\\\n... \\\nresult = question_answerer(question=What is a good example of a question answering dataset?, context=context)\\\nprint(\\\n... fAnswer: \\'{result[\\'answer\\']}\\', score: {round(result[\\'score\\'], 4)}, start: {result[\\'start\\']}, end: {result[\\'end\\']}\\\n...)\", \\'performance\\': {\\'dataset\\': \\'SQuAD v1.1\\', \\'accuracy\\': \\'86.9 F1 score\\'}, \\'description\\': \"DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT\\'s performances as measured on the GLUE language understanding benchmark.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 168, "text": " I am a data analyst working in pollution detection, find a model and develop a piece of code for me for environment monitoring.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text-to-Text Generation\\', \\'api_name\\': \\'philschmid/bart-large-cnn-samsum\\', \\'api_call\\': \"pipeline(\\'summarization\\', model=\\'philschmid/bart-large-cnn-samsum\\')\", \\'api_arguments\\': {\\'model\\': \\'philschmid/bart-large-cnn-samsum\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'latest\\'}, \\'example_code\\': \"from transformers import pipeline\\\nsummarizer = pipeline(summarization, model=philschmid/bart-large-cnn-samsum)\\\nconversation = \\'\\'\\'Jeff: Can I train a ðŸ¤— Transformers model on Amazon SageMaker? \\\nPhilipp: Sure you can use the new Hugging Face Deep Learning Container. \\\nJeff: ok.\\\nJeff: and how can I get started? \\\nJeff: where can I find documentation? \\\nPhilipp: ok, ok you can find everything here. https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face <br />\\\n\\'\\'\\'\\\nsummarizer(conversation)\", \\'performance\\': {\\'dataset\\': \\'samsum\\', \\'accuracy\\': {\\'eval_rouge1\\': 42.621, \\'eval_rouge2\\': 21.9825, \\'eval_rougeL\\': 33.034, \\'eval_rougeLsum\\': 39.6783, \\'test_rouge1\\': 41.3174, \\'test_rouge2\\': 20.8716, \\'test_rougeL\\': 32.1337, \\'test_rougeLsum\\': 38.4149}}, \\'description\\': \\'philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 169, "text": " We want to develop an intelligent prosthetic leg that can improve walking. Use a decision transformer to predict actions to be taken.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 170, "text": " You want to create a bot that can play the Pong No Frameskip-v4 game with exceptional skill.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'valhalla/t5-base-e2e-qg\\', \\'api_call\\': \"pipeline(\\'e2e-qg\\', model=\\'valhalla/t5-base-e2e-qg\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'Hugging Face Transformers\\'], \\'example_code\\': \"from pipelines import pipeline\\\n\\\ntext = Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python\\'s design philosophy emphasizes code readability with its notable use of significant whitespace.\\\n\\\nnlp = pipeline(e2e-qg, model=valhalla/t5-base-e2e-qg)\\\n\\\nnlp(text)\", \\'performance\\': {\\'dataset\\': \\'squad\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 171, "text": " I am a game developer working on a game project involving moving carts. I need to use reinforcement learning to improve the game experience.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'csarron/bert-base-uncased-squad-v1\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'csarron/bert-base-uncased-squad-v1\\', tokenizer=\\'csarron/bert-base-uncased-squad-v1\\')\", \\'api_arguments\\': {\\'model\\': \\'csarron/bert-base-uncased-squad-v1\\', \\'tokenizer\\': \\'csarron/bert-base-uncased-squad-v1\\'}, \\'python_environment_requirements\\': \\'Python 3.7.5\\', \\'example_code\\': \"from transformers import pipeline\\\nqa_pipeline = pipeline(\\\n question-answering,\\\n model=csarron/bert-base-uncased-squad-v1,\\\n tokenizer=csarron/bert-base-uncased-squad-v1\\\n)\\\npredictions = qa_pipeline({\\\n \\'context\\': The game was played on February 7, 2016 at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California.,\\\n \\'question\\': What day was the game played on?\\\n})\\\nprint(predictions)\", \\'performance\\': {\\'dataset\\': \\'SQuAD1.1\\', \\'accuracy\\': {\\'EM\\': 80.9, \\'F1\\': 88.2}}, \\'description\\': \\'BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 172, "text": " Develop a soccer playing agent that can outperform its opponents in a 2v2 environment.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Classification\\', \\'api_name\\': \\'facebook/convnext-large-224\\', \\'api_call\\': \"ConvNextForImageClassification.from_pretrained(\\'facebook/convnext-large-224\\')\", \\'api_arguments\\': {\\'pretrained_model_name_or_path\\': \\'facebook/convnext-large-224\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'Hugging Face Transformers\\', \\'torch\\': \\'PyTorch\\', \\'datasets\\': \\'Hugging Face Datasets\\'}, \\'example_code\\': {\\'import\\': [\\'from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification\\', \\'import torch\\', \\'from datasets import load_dataset\\'], \\'load_dataset\\': \"dataset = load_dataset(\\'huggingface/cats-image\\')\", \\'image\\': \"image = dataset[\\'test\\'][\\'image\\'][0]\", \\'feature_extractor\\': \"feature_extractor = ConvNextFeatureExtractor.from_pretrained(\\'facebook/convnext-large-224\\')\", \\'model\\': \"model = ConvNextForImageClassification.from_pretrained(\\'facebook/convnext-large-224\\')\", \\'inputs\\': \"inputs = feature_extractor(image, return_tensors=\\'pt\\')\", \\'logits\\': \\'with torch.no_grad():\\\n  logits = model(**inputs).logits\\', \\'predicted_label\\': \\'predicted_label = logits.argmax(-1).item()\\', \\'print\\': \\'print(model.config.id2label[predicted_label])\\'}, \\'performance\\': {\\'dataset\\': \\'imagenet-1k\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \"ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and \\'modernized\\' its design by taking the Swin Transformer as inspiration.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 173, "text": " We are tasked to analyze text for a Russian newspaper to help understand general sentiment and trends in the text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'financial-sentiment-analysis\\', \\'api_name\\': \\'ProsusAI/finbert\\', \\'api_call\\': \"AutoModelForSequenceClassification.from_pretrained(\\'ProsusAI/finbert\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"from transformers import pipeline; classifier = pipeline(\\'sentiment-analysis\\', model=\\'ProsusAI/finbert\\'); classifier(\\'your_text_here\\')\", \\'performance\\': {\\'dataset\\': \\'Financial PhraseBank\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 174, "text": " We want to generate an image from a textual description for our PowerPoint presentation.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 175, "text": " A new manga has been released and we would like to provide a manga reader app with translations. Get the text from the manga image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Visual Question Answering\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'git-large-textvqa\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'microsoft/git-large-textvqa\\')\", \\'api_arguments\\': \\'image, question\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'For code examples, we refer to the documentation.\\', \\'performance\\': {\\'dataset\\': \\'TextVQA\\', \\'accuracy\\': \\'See table 11 in the paper for more details.\\'}, \\'description\\': \"GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using \\'teacher forcing\\' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text).\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 176, "text": " We are building a social media site which creates automatic captions for users when they post a picture\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 177, "text": " There is robot in our factory which reads the image from the production line and then generate a text output based on the image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Image-to-Image\\', \\'api_name\\': \\'GreeneryScenery/SheepsControlV3\\', \\'api_call\\': \"pipeline(\\'image-to-image\\', model=\\'GreeneryScenery/SheepsControlV3\\')\", \\'api_arguments\\': {\\'image\\': \\'Path to image file\\', \\'text_guidance\\': \\'Optional text guidance for the model\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'latest\\', \\'torch\\': \\'latest\\'}, \\'example_code\\': [\\'from transformers import pipeline\\', \"model = pipeline(\\'image-to-image\\', model=\\'GreeneryScenery/SheepsControlV3\\')\", \"result = model({\\'image\\': \\'path/to/image.jpg\\', \\'text_guidance\\': \\'Optional text guidance\\'})\"], \\'performance\\': {\\'dataset\\': \\'GreeneryScenery/SheepsControlV3\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 178, "text": " I am a filmmaker, and I need to make a short video based on a scene description from a script.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video Synthesis\\', \\'api_name\\': \\'modelscope-damo-text-to-video-synthesis\\', \\'api_call\\': \"pipeline(\\'text-to-video-synthesis\\', model_dir.as_posix())\", \\'api_arguments\\': {\\'text\\': \\'A short text description in English\\'}, \\'python_environment_requirements\\': [\\'modelscope==1.4.2\\', \\'open_clip_torch\\', \\'pytorch-lightning\\'], \\'example_code\\': \"from huggingface_hub import snapshot_download\\\nfrom modelscope.pipelines import pipeline\\\nfrom modelscope.outputs import OutputKeys\\\nimport pathlib\\\n\\\nmodel_dir = pathlib.Path(\\'weights\\')\\\nsnapshot_download(\\'damo-vilab/modelscope-damo-text-to-video-synthesis\\',\\\n repo_type=\\'model\\', local_dir=model_dir)\\\n\\\npipe = pipeline(\\'text-to-video-synthesis\\', model_dir.as_posix())\\\n\\\ntest_text = {\\\n \\'text\\': \\'A panda eating bamboo on a rock.\\',\\\n}\\\n\\\noutput_video_path = pipe(test_text,)[OutputKeys.OUTPUT_VIDEO]\\\nprint(\\'output_video_path:\\', output_video_path)\", \\'performance\\': {\\'dataset\\': \\'Webvid, ImageNet, LAION5B\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 179, "text": " I'm an author and want to create a short video based on a brief passage from my book. Can you generate a video based on this text?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'camenduru/text2-video-zero\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'camenduru/text2-video-zero\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 180, "text": " I want to build an AI model that can analyze images and answer questions about the content of the image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Visual Question Answering\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'ivelin/donut-refexp-combined-v1\\', \\'api_call\\': \"pipeline(\\'visual-question-answering\\', model=\\'ivelin/donut-refexp-combined-v1\\')\", \\'api_arguments\\': \\'image, question\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"vqa(image=\\'path/to/image.jpg\\', question=\\'What is the color of the object?\\')\", \\'performance\\': {\\'dataset\\': \\'ivelin/donut-refexp-combined-v1\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 181, "text": " We are trying to develop an application that helps tourists get information about attractions by analyzing images they take and responding to questions.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 182, "text": " We have the financial documents of a company and we want to extract information about the cash flow. Modify the model so it can answer the questions related to the cash flow.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 183, "text": " Please generate a correct building plan leveraging the data given.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Feature Extraction\\', \\'api_name\\': \\'sberbank-ai/sbert_large_mt_nlu_ru\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'sberbank-ai/sbert_large_mt_nlu_ru\\')\", \\'api_arguments\\': [\\'sentences\\', \\'padding\\', \\'truncation\\', \\'max_length\\', \\'return_tensors\\'], \\'python_environment_requirements\\': [\\'transformers\\', \\'torch\\'], \\'example_code\\': \"from transformers import AutoTokenizer, AutoModel\\\nimport torch\\\n\\\n\\\n# Mean Pooling - Take attention mask into account for correct averaging\\\ndef mean_pooling(model_output, attention_mask):\\\n    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\\\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\\\n    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\\\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\\\n    return sum_embeddings / sum_mask\\\n\\\n\\\n# Sentences we want sentence embeddings for sentences = [\\'?\\']\\\n\\\n# Load AutoModel from huggingface model repository\\\ntokenizer = AutoTokenizer.from_pretrained(sberbank-ai/sbert_large_mt_nlu_ru)\\\nmodel = AutoModel.from_pretrained(sberbank-ai/sbert_large_mt_nlu_ru)\\\n\\\n# Tokenize sentences\\\nencoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=24, return_tensors=\\'pt\\')\\\n\\\n# Compute token embeddings\\\nwith torch.no_grad():\\\n    model_output = model(**encoded_input)\\\n\\\n# Perform pooling. In this case, mean pooling\\\nsentence_embeddings = mean_pooling(model_output, encoded_input[\\'attention_mask\\'])\", \\'performance\\': {\\'dataset\\': \\'Russian SuperGLUE\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'BERT large model multitask (cased) for Sentence Embeddings in Russian language.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 184, "text": " Help our drone video analyzing app estimate the depth in drone footage.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 185, "text": " As a salesperson, I need to analyze customer invoices to answer questions about the total amount, tax, and due date from an image file.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'layoutlm-invoices\\', \\'api_call\\': \"AutoModelForDocumentQuestionAnswering.from_pretrained(\\'impira/layoutlm-invoices\\')\", \\'api_arguments\\': \\'question, context\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"nlp(question=\\'What is the total amount?\\', context=\\'your_invoice_text\\')\", \\'performance\\': {\\'dataset\\': \\'proprietary dataset of invoices, SQuAD2.0, and DocVQA\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 186, "text": " We need to find out the depth information of a room for monitoring purposes.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 187, "text": " We are creating an autonomous car and need to estimate the depth of objects in a given scene.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 188, "text": " Help us create an AI solution to automatically label images taken by a security camera.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'facebook/wav2vec2-xlsr-53-espeak-cv-ft\\', \\'api_call\\': \"Wav2Vec2ForCTC.from_pretrained(\\'facebook/wav2vec2-xlsr-53-espeak-cv-ft\\')\", \\'api_arguments\\': {\\'model_name\\': \\'facebook/wav2vec2-xlsr-53-espeak-cv-ft\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'4.13.0\\', \\'torch\\': \\'1.10.0\\', \\'datasets\\': \\'1.14.0\\'}, \\'example_code\\': \\'processor = Wav2Vec2Processor.from_pretrained(facebook/wav2vec2-xlsr-53-espeak-cv-ft)\\\nmodel = Wav2Vec2ForCTC.from_pretrained(facebook/wav2vec2-xlsr-53-espeak-cv-ft)\\\nds = load_dataset(patrickvonplaten/librispeech_asr_dummy, clean, split=validation)\\\ninput_values = processor(ds[0][audio][array], return_tensors=pt).input_values\\\nwith torch.no_grad():\\\n    logits = model(input_values).logits\\\npredicted_ids = torch.argmax(logits, dim=-1)\\\ntranscription = processor.batch_decode(predicted_ids)\\', \\'performance\\': {\\'dataset\\': \\'common_voice\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 189, "text": " Develop a software to classify an image from a URL into a thousand categories.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Image-to-Text\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'naver-clova-ix/donut-base\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'naver-clova-ix/donut-base\\')\", \\'api_arguments\\': \\'image\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'result = donut(image_path)\\', \\'performance\\': {\\'dataset\\': \\'arxiv:2111.15664\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 190, "text": " Our delivery drones need to detect and avoid obstacles while flying. Develop a solution for them to detect objects in their path.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Object Detection\\', \\'api_name\\': \\'fcakyon/yolov5s-v7.0\\', \\'api_call\\': \"yolov5.load(\\'fcakyon/yolov5s-v7.0\\')\", \\'api_arguments\\': {\\'conf\\': 0.25, \\'iou\\': 0.45, \\'agnostic\\': False, \\'multi_label\\': False, \\'max_det\\': 1000, \\'img\\': \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\', \\'size\\': 640, \\'augment\\': True}, \\'python_environment_requirements\\': \\'pip install -U yolov5\\', \\'example_code\\': \"import yolov5\\\nmodel = yolov5.load(\\'fcakyon/yolov5s-v7.0\\')\\\nmodel.conf = 0.25\\\nmodel.iou = 0.45\\\nmodel.agnostic = False\\\nmodel.multi_label = False\\\nmodel.max_det = 1000\\\nimg = \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'\\\nresults = model(img)\\\nresults = model(img, size=640)\\\nresults = model(img, augment=True)\\\npredictions = results.pred[0]\\\nboxes = predictions[:, :4]\\\nscores = predictions[:, 4]\\\ncategories = predictions[:, 5]\\\nresults.show()\\\nresults.save(save_dir=\\'results/\\')\", \\'performance\\': {\\'dataset\\': \\'detection-datasets/coco\\', \\'accuracy\\': None}, \\'description\\': \\'Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 191, "text": " Develop a code to recognize objects in images using deformable-detr model.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'ToddGoldfarb/Cadet-Tiny\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'ToddGoldfarb/Cadet-Tiny\\', low_cpu_mem_usage=True)\", \\'api_arguments\\': {\\'pretrained_model\\': \\'t5-small\\', \\'model_max_length\\': 512}, \\'python_environment_requirements\\': {\\'torch\\': \\'\\', \\'transformers\\': \\'\\', \\'colorful\\': \\'\\'}, \\'example_code\\': \"import torch\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nimport colorful as cf\\\ncf.use_true_colors()\\\ncf.use_style(\\'monokai\\')\\\nclass CadetTinyAgent:\\\n def <strong>init</strong>(self):\\\n  print(cf.bold | cf.purple(Waking up Cadet-Tiny...))\\\n  self.device = torch.device(cuda if torch.cuda.is_available() else cpu)\\\n  self.tokenizer = AutoTokenizer.from_pretrained(t5-small, model_max_length=512)\\\n  self.model = AutoModelForSeq2SeqLM.from_pretrained(ToddGoldfarb/Cadet-Tiny, low_cpu_mem_usage=True).to(self.device)\\\n  self.conversation_history = \\\ndef observe(self, observation):\\\n self.conversation_history = self.conversation_history + observation\\\n # The number 400 below is just a truncation safety net. It leaves room for 112 input tokens.\\\n if len(self.conversation_history) &gt; 400:\\\n self.conversation_history = self.conversation_history[112:]\\\ndef set_input(self, situation_narrative=, role_instruction=):\\\n input_text = dialogue: \\\n if situation_narrative != :\\\n input_text = input_text + situation_narrative\\\n if role_instruction != :\\\n input_text = input_text +  &lt;SEP&gt;  + role_instruction\\\n input_text = input_text +  &lt;TURN&gt;  + self.conversation_history\\\n # Uncomment the line below to see what is fed to the model.\\\n # print(input_text)\\\n return input_text\\\ndef generate(self, situation_narrative, role_instruction, user_response):\\\n user_response = user_response +  &lt;TURN&gt; \\\n self.observe(user_response)\\\n input_text = self.set_input(situation_narrative, role_instruction)\\\n inputs = self.tokenizer([input_text], return_tensors=pt).to(self.device)\\\n # I encourage you to change the hyperparameters of the model! Start by trying to modify the temperature.\\\n outputs = self.model.generate(inputs[input_ids], max_new_tokens=512, temperature=1, top_p=.95,\\\n do_sample=True)\\\n cadet_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\\\n added_turn = cadet_response +  &lt;TURN&gt; \\\n self.observe(added_turn)\\\n return cadet_response\\\ndef reset_history(self):\\\n self.conversation_history = []\\\ndef run(self):\\\n def get_valid_input(prompt, default):\\\n  while True:\\\n   user_input = input(prompt)\\\n   if user_input in [Y, N, y, n]:\\\n    return user_input\\\n   if user_input == :\\\n    return default\\\n  while True:\\\n   continue_chat = \\\n   # MODIFY THESE STRINGS TO YOUR LIKING :)\\\n   situation_narrative = Imagine you are Cadet-Tiny talking to ???.\\\n   role_instruction = You are Cadet-Tiny, and you are talking to ???.\\\n   self.chat(situation_narrative, role_instruction)\\\n   continue_chat = get_valid_input(cf.purple(Start a new conversation with new setup? [Y/N]:), Y)\\\n   if continue_chat in [N, n]:\\\n    break\\\n   print(cf.blue(CT: See you!))\\\ndef chat(self, situation_narrative, role_instruction):\\\n print(cf.green(\\\n  Cadet-Tiny is running! Input [RESET] to reset the conversation history and [END] to end the conversation.))\\\n while True:\\\n  user_input = input(You: )\\\n  if user_input == [RESET]:\\\n   self.reset_history()\\\n   print(cf.green([Conversation history cleared. Chat with Cadet-Tiny!]))\\\n   continue\\\n  if user_input == [END]:\\\n   break\\\n  response = self.generate(situation_narrative, role_instruction, user_input)\\\n  print(cf.blue(CT:  + response))\\\ndef main():\\\n print(cf.bold | cf.blue(LOADING MODEL))\\\nCadetTiny = CadetTinyAgent()\\\nCadetTiny.run()\\\nif <strong>name</strong> == \\'<strong>main</strong>\\':\\\n main()\", \\'performance\\': {\\'dataset\\': \\'allenai/soda\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 192, "text": " I need to extract tables from a set of scanned document images to simplify data analysis.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023\\', \\'api_call\\': \"AutoModelForDocumentQuestionAnswering.from_pretrained(\\'L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023\\')\", \\'api_arguments\\': {}, \\'python_environment_requirements\\': {\\'transformers\\': \\'>=4.11.0\\'}, \\'example_code\\': {}, \\'performance\\': {\\'dataset\\': {}, \\'accuracy\\': {}}, \\'description\\': \\'A document question answering model based on LayoutLMv2, which can be used to extract answers from images with text and layout information.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 193, "text": " Our customers wish to automatically detect shoplifters in the store using a surveillance camera. Help them to implement object detection and identify potential thieves.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Object Detection\\', \\'api_name\\': \\'keremberke/yolov8m-csgo-player-detection\\', \\'api_call\\': \"YOLO(\\'keremberke/yolov8m-csgo-player-detection\\')\", \\'api_arguments\\': {\\'image\\': \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'}, \\'python_environment_requirements\\': \\'ultralyticsplus==0.0.23 ultralytics==8.0.21\\', \\'example_code\\': \"from ultralyticsplus import YOLO, render_result\\\nmodel = YOLO(\\'keremberke/yolov8m-csgo-player-detection\\')\\\nmodel.overrides[\\'conf\\'] = 0.25\\\nmodel.overrides[\\'iou\\'] = 0.45\\\nmodel.overrides[\\'agnostic_nms\\'] = False\\\nmodel.overrides[\\'max_det\\'] = 1000\\\nimage = \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'\\\nresults = model.predict(image)\\\nprint(results[0].boxes)\\\nrender = render_result(model=model, image=image, result=results[0])\\\nrender.show()\", \\'performance\\': {\\'dataset\\': \\'csgo-object-detection\\', \\'accuracy\\': 0.892}, \\'description\\': \"An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify \\'ct\\', \\'cthead\\', \\'t\\', and \\'thead\\' labels.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 194, "text": " Create an object detector that can detect blood cells in an image, such as platelets, red blood cells, and white blood cells.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Blood Cell Detection\\', \\'api_name\\': \\'keremberke/yolov8n-blood-cell-detection\\', \\'api_call\\': \"YOLO(\\'keremberke/yolov8n-blood-cell-detection\\')\", \\'api_arguments\\': {\\'conf\\': 0.25, \\'iou\\': 0.45, \\'agnostic_nms\\': False, \\'max_det\\': 1000}, \\'python_environment_requirements\\': \\'ultralyticsplus==0.0.23 ultralytics==8.0.21\\', \\'example_code\\': \"from ultralyticsplus import YOLO, render_result\\\nmodel = YOLO(\\'keremberke/yolov8n-blood-cell-detection\\')\\\nmodel.overrides[\\'conf\\'] = 0.25\\\nmodel.overrides[\\'iou\\'] = 0.45\\\nmodel.overrides[\\'agnostic_nms\\'] = False\\\nmodel.overrides[\\'max_det\\'] = 1000\\\nimage = \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'\\\nresults = model.predict(image)\\\nprint(results[0].boxes)\\\nrender = render_result(model=model, image=image, result=results[0])\\\nrender.show()\", \\'performance\\': {\\'dataset\\': \\'blood-cell-object-detection\\', \\'accuracy\\': 0.893}, \\'description\\': \\'This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 195, "text": " I am a real-estate agent working on a project where I need to convert images of room plans to a better visual representation.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 196, "text": " We recently received low resolution images of newly released products and need to upscale them for better quality.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 197, "text": " As a toy company, we are designing a new toy line. We'd like you to create an image of a toy robot using relevant text prompts as control input.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'videomae-small-finetuned-ssv2\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-small-finetuned-ssv2\\')\", \\'api_arguments\\': {\\'model_name\\': \\'MCG-NJU/videomae-small-finetuned-ssv2\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\\', \\'numpy\\': \\'import numpy as np\\', \\'torch\\': \\'import torch\\'}, \\'example_code\\': \\'video = list(np.random.randn(16, 3, 224, 224))\\\nfeature_extractor = VideoMAEFeatureExtractor.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\nmodel = VideoMAEForVideoClassification.from_pretrained(MCG-NJU/videomae-small-finetuned-ssv2)\\\ninputs = feature_extractor(video, return_tensors=pt)\\\nwith torch.no_grad():\\\n  outputs = model(**inputs)\\\n  logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'Something-Something V2\\', \\'accuracy\\': {\\'top-1\\': 66.8, \\'top-5\\': 90.3}}, \\'description\\': \\'VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 198, "text": " I'm developing a game that needs more Minecraft skins for some characters. How can I generete them with this model?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Diffusers\\', \\'api_name\\': \\'Minecraft-Skin-Diffusion\\', \\'api_call\\': \"DDPMPipeline.from_pretrained(\\'WiNE-iNEFF/Minecraft-Skin-Diffusion\\')\", \\'api_arguments\\': {}, \\'python_environment_requirements\\': [\\'diffusers\\'], \\'example_code\\': \"from diffusers import DDPMPipeline\\\npipeline = DDPMPipeline.from_pretrained(\\'WiNE-iNEFF/Minecraft-Skin-Diffusion\\')\\\nimage = pipeline().images[0].convert(\\'RGBA\\')\\\nimage\", \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 199, "text": " Find me a generative model to create cat images in 256x256 resolution.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image Generation\\', \\'api_name\\': \\'stabilityai/stable-diffusion-2-1-base\\', \\'api_call\\': \"StableDiffusionPipeline.from_pretrained(\\'stabilityai/stable-diffusion-2-1-base\\', scheduler=EulerDiscreteScheduler.from_pretrained(stabilityai/stable-diffusion-2-1-base, subfolder=scheduler), torch_dtype=torch.float16)\", \\'api_arguments\\': {\\'prompt\\': \\'a photo of an astronaut riding a horse on mars\\'}, \\'python_environment_requirements\\': [\\'diffusers\\', \\'transformers\\', \\'accelerate\\', \\'scipy\\', \\'safetensors\\'], \\'example_code\\': {\\'install_dependencies\\': \\'pip install diffusers transformers accelerate scipy safetensors\\', \\'code\\': \\'from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\\\nimport torch\\\nmodel_id = stabilityai/stable-diffusion-2-1-base\\\nscheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=scheduler)\\\npipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\\\npipe = pipe.to(cuda)\\\nprompt = a photo of an astronaut riding a horse on mars\\\nimage = pipe(prompt).images[0]\\\nimage.save(astronaut_rides_horse.png)\\'}, \\'performance\\': {\\'dataset\\': \\'COCO2017 validation set\\', \\'accuracy\\': \\'Not optimized for FID scores\\'}, \\'description\\': \\'Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 200, "text": " Our organization works with video surveillance. We need a system to analyze the videos and classify various events happening inside the video.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'camenduru/text2-video-zero\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'camenduru/text2-video-zero\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 201, "text": " People in my company need an automatic solution to categorize videos based on their content. The system should be able to recognize the main theme of a video with high accuracy.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'camenduru/text2-video-zero\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'camenduru/text2-video-zero\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 202, "text": " We want to build a product to classify images of pets into different categories.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Feature Extraction\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Feature Extraction\\', \\'api_name\\': \\'DeepPavlov/rubert-base-cased\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'DeepPavlov/rubert-base-cased\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'Russian part of Wikipedia and news data\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'RuBERT (Russian, cased, 12â€‘layer, 768â€‘hidden, 12â€‘heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERTâ€‘base as an initialization for RuBERT[1].\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
