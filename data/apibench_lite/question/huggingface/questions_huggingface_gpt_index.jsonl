{"question_id": 1, "text": " Design a feature for a social media website to recommend articles to users based on how similar the articles are to their previously liked articles.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Summarization\\', \\'api_name\\': \\'facebook/bart-large-cnn\\', \\'api_call\\': \"pipeline(\\'summarization\\', model=\\'facebook/bart-large-cnn\\')\", \\'api_arguments\\': [\\'ARTICLE\\', \\'max_length\\', \\'min_length\\', \\'do_sample\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import pipeline\\\nsummarizer = pipeline(summarization, model=facebook/bart-large-cnn)\\\nARTICLE = ...\\\nprint(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))\\', \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 42.949, \\'ROUGE-2\\': 20.815, \\'ROUGE-L\\': 30.619, \\'ROUGE-LSUM\\': 40.038}}, \\'description\\': \\'BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 2, "text": " The user is interested in a tool to find relationships between medical terms.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Token Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Named Entity Recognition\\', \\'api_name\\': \\'d4data/biomedical-ner-all\\', \\'api_call\\': \"AutoModelForTokenClassification.from_pretrained(\\'d4data/biomedical-ner-all\\')\", \\'api_arguments\\': {\\'model\\': \\'AutoModelForTokenClassification.from_pretrained(d4data/biomedical-ner-all)\\', \\'tokenizer\\': \\'AutoTokenizer.from_pretrained(d4data/biomedical-ner-all)\\', \\'aggregation_strategy\\': \\'simple\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\\'}, \\'example_code\\': \\'pipe(The patient reported no recurrence of palpitations at follow-up 6 months after the ablation.)\\', \\'performance\\': {\\'dataset\\': \\'Maccrobat\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'An English Named Entity Recognition model, trained on Maccrobat to recognize the bio-medical entities (107 entities) from a given text corpus (case reports etc.). This model was built on top of distilbert-base-uncased.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 3, "text": " As a journalist, I am curious about speech sentiment analysis in a group of people in a crowd. I want to extract features from the audio to run sentiment analysis.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentiment Analysis\\', \\'api_name\\': \\'michellejieli/NSFW_text_classifier\\', \\'api_call\\': \"pipeline(\\'sentiment-analysis\\', model=\\'michellejieli/NSFW_text_classification\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'classifier(I see you’ve set aside this special time to humiliate yourself in public.)\\', \\'performance\\': {\\'dataset\\': \\'Reddit posts\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 4, "text": " A chat service needs a way to compare and cluster similar sentences from users in different languages. Find a suitable feature extraction method to achieve this.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Sentence Similarity\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Feature Extraction\\', \\'api_name\\': \\'sentence-transformers/distilbert-base-nli-mean-tokens\\', \\'api_call\\': \"SentenceTransformer(\\'sentence-transformers/distilbert-base-nli-mean-tokens\\')\", \\'api_arguments\\': [\\'sentences\\'], \\'python_environment_requirements\\': \\'pip install -U sentence-transformers\\', \\'example_code\\': \"from sentence_transformers import SentenceTransformer\\\nsentences = [This is an example sentence, Each sentence is converted]\\\nmodel = SentenceTransformer(\\'sentence-transformers/distilbert-base-nli-mean-tokens\\')\\\nembeddings = model.encode(sentences)\\\nprint(embeddings)\", \\'performance\\': {\\'dataset\\': \\'https://seb.sbert.net\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 5, "text": " I am an interior designer and want to showcase a modern living room with a fireplace and a large window overlooking a forest. Create an image according to this description.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Denoising Diffusion Probabilistic Models (DDPM)\\', \\'api_name\\': \\'google/ddpm-bedroom-256\\', \\'api_call\\': \"DDPMPipeline.from_pretrained(\\'google/ddpm-bedroom-256\\')\", \\'api_arguments\\': \\'None\\', \\'python_environment_requirements\\': \\'diffusers\\', \\'example_code\\': \\'!pip install diffusers\\\nfrom diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline\\\nmodel_id = google/ddpm-bedroom-256\\\nddpm = DDPMPipeline.from_pretrained(model_id)\\\nimage = ddpm().images[0]\\\nimage.save(ddpm_generated_image.png)\\', \\'performance\\': {\\'dataset\\': \\'CIFAR10\\', \\'accuracy\\': {\\'Inception score\\': 9.46, \\'FID score\\': 3.17}}, \\'description\\': \\'We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 6, "text": " We need a product description for an image-based online store platform that will help customers understand the specifics of the product.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'Linaqruf/anything-v3.0\\', \\'api_call\\': \"Text2ImagePipeline(model=\\'Linaqruf/anything-v3.0\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A text-to-image model that generates images from text descriptions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 7, "text": " Create a program to generate a description for an image provided as input.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'prompthero/openjourney-v4\\', \\'api_call\\': \"pipeline(\\'text-to-image\\', model=\\'prompthero/openjourney-v4\\')\", \\'api_arguments\\': {\\'text\\': \\'string\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"generate_image(\\'your text here\\')\", \\'performance\\': {\\'dataset\\': \\'Midjourney v4 images\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 8, "text": " I am a financial analyst, and I receive report after report filled with charts helping to explain trends and data in my field. However, I also need to have this information in tabular format. Please help me extract a linearized table from this chart.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'tabular regression\\', \\'api_name\\': \\'farouk97/autotrain-test7-2644pc-linearregr-38619101723\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'farouk97/autotrain-data-test7-2644pc-linearregr\\', \\'accuracy\\': {\\'Loss\\': 0.145, \\'R2\\': 0.0, \\'MSE\\': 0.021, \\'MAE\\': 0.099, \\'RMSLE\\': 0.101}}, \\'description\\': \\'A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 9, "text": " We are building an automatic video generation platform based on user-provided text. We need a reliable model to convert text instructions into appropriate videos.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'camenduru/text2-video-zero\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'camenduru/text2-video-zero\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 10, "text": " How can I extract video content from a text file? Provide a code sample to generate the video based on the text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'chavinlo/TempoFunk\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'chavinlo/TempoFunk\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 11, "text": " We are developing a mobile app to demonstrate the AI's ability to generate a short video from text. The app focuses on processing written stories into video.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'ImRma/Brucelee\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'ImRma/Brucelee\\')\", \\'api_arguments\\': [\\'your_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A Hugging Face model for converting Persian and English text into video.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 12, "text": " Hey, I want to analyze images in my phone gallery and answer questions about them.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Document Question Answering\\', \\'api_name\\': \\'CQI_Visual_Question_Awnser_PT_v0\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=LayoutLMForQuestionAnswering.from_pretrained(\\'microsoft/layoutlm-base-uncased\\'))\", \\'api_arguments\\': [\\'url\\', \\'question\\'], \\'python_environment_requirements\\': [\\'PIL\\', \\'pytesseract\\', \\'PyTorch\\', \\'transformers\\'], \\'example_code\\': [\"nlp(\\'https://templates.invoicehome.com/invoice-template-us-neat-750px.png\\', \\'What is the invoice number?\\')\", \"nlp(\\'https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\\', \\'What is the purchase amount?\\')\", \"nlp(\\'https://www.accountingcoach.com/wp-content/uploads/2013/10/income-statement-example@2x.png\\', \\'What are the 2020 net sales?\\')\"], \\'performance\\': {\\'dataset\\': [{\\'accuracy\\': 0.9943977}, {\\'accuracy\\': 0.9912159}, {\\'accuracy\\': 0.59147286}]}, \\'description\\': \\'A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 13, "text": " My company wants to develop an application that will analyze images in relation to food and answer questions about them. We want it to handle questions like \\\"what is in the dish\\\" and \\\"how many calories does it have\\\".\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Document Question Answering\\', \\'api_name\\': \\'CQI_Visual_Question_Awnser_PT_v0\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=LayoutLMForQuestionAnswering.from_pretrained(\\'microsoft/layoutlm-base-uncased\\'))\", \\'api_arguments\\': [\\'url\\', \\'question\\'], \\'python_environment_requirements\\': [\\'PIL\\', \\'pytesseract\\', \\'PyTorch\\', \\'transformers\\'], \\'example_code\\': [\"nlp(\\'https://templates.invoicehome.com/invoice-template-us-neat-750px.png\\', \\'What is the invoice number?\\')\", \"nlp(\\'https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\\', \\'What is the purchase amount?\\')\", \"nlp(\\'https://www.accountingcoach.com/wp-content/uploads/2013/10/income-statement-example@2x.png\\', \\'What are the 2020 net sales?\\')\"], \\'performance\\': {\\'dataset\\': [{\\'accuracy\\': 0.9943977}, {\\'accuracy\\': 0.9912159}, {\\'accuracy\\': 0.59147286}]}, \\'description\\': \\'A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 14, "text": " We have received an invoice document, and would like to extract the total amount from it.\n###Input: {'question': 'What is the total amount?', 'context': 'Invoice information for order ABC_123\\\nProduct: Widget A, Quantity: 10, Price: $5 each\\\nProduct: Widget B, Quantity: 5, Price: $3 each\\\nProduct: Widget C, Quantity: 15, Price: $2 each\\\nSubtotal: $75, Tax: $6.38, Total Amount Due: $81.38'}\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'layoutlm-invoices\\', \\'api_call\\': \"AutoModelForDocumentQuestionAnswering.from_pretrained(\\'impira/layoutlm-invoices\\')\", \\'api_arguments\\': \\'question, context\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"nlp(question=\\'What is the total amount?\\', context=\\'your_invoice_text\\')\", \\'performance\\': {\\'dataset\\': \\'proprietary dataset of invoices, SQuAD2.0, and DocVQA\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 15, "text": " As a clerk in a school, you want to extract information from some student enrollment forms. These forms contain students' details such as Name, age, and address.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Text Classification\\', \\'api_name\\': \\'joeddav/distilbert-base-uncased-go-emotions-student\\', \\'api_call\\': \"pipeline(\\'text-classification\\', model=\\'joeddav/distilbert-base-uncased-go-emotions-student\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': [\\'transformers\\', \\'torch\\', \\'tensorflow\\'], \\'example_code\\': \"from transformers import pipeline\\\nnlp = pipeline(\\'text-classification\\', model=\\'joeddav/distilbert-base-uncased-go-emotions-student\\')\\\nresult = nlp(\\'I am so happy today!\\')\", \\'performance\\': {\\'dataset\\': \\'go_emotions\\'}, \\'description\\': \\'This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 16, "text": " Find a model that can be used to predict the properties of molecules based on their graph representations.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Carbon Emissions\\', \\'api_name\\': \\'kochetkovIT/autotrain-ironhack-49741119788\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'json\\', \\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'kochetkovIT/autotrain-data-ironhack\\', \\'accuracy\\': {\\'Loss\\': 2.603, \\'R2\\': 0.013, \\'MSE\\': 6.776, \\'MAE\\': 1.666, \\'RMSLE\\': 0.502}}, \\'description\\': \\'A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 17, "text": " Estimate the depth of a pool using computational depth estimation, given an underwater photo.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Depth Estimation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Depth Estimation\\', \\'api_name\\': \\'glpn-kitti\\', \\'api_call\\': \"GLPNForDepthEstimation.from_pretrained(\\'vinvino02/glpn-kitti\\')\", \\'api_arguments\\': \\'images, return_tensors\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'from transformers import GLPNFeatureExtractor, GLPNForDepthEstimation\\\nimport torch\\\nimport numpy as np\\\nfrom PIL import Image\\\nimport requests\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\nfeature_extractor = GLPNFeatureExtractor.from_pretrained(vinvino02/glpn-kitti)\\\nmodel = GLPNForDepthEstimation.from_pretrained(vinvino02/glpn-kitti)\\\ninputs = feature_extractor(images=image, return_tensors=pt)\\\nwith torch.no_grad():\\\n outputs = model(**inputs)\\\n predicted_depth = outputs.predicted_depth\\\nprediction = torch.nn.functional.interpolate(\\\n predicted_depth.unsqueeze(1),\\\n size=image.size[::-1],\\\n mode=bicubic,\\\n align_corners=False,\\\n)\\\noutput = prediction.squeeze().cpu().numpy()\\\nformatted = (output * 255 / np.max(output)).astype(uint8)\\\ndepth = Image.fromarray(formatted)\\', \\'performance\\': {\\'dataset\\': \\'KITTI\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 18, "text": " I need technology that can analyze images and estimate their depth in a single camera.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Depth Estimation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Depth Estimation\\', \\'api_name\\': \\'glpn-kitti\\', \\'api_call\\': \"GLPNForDepthEstimation.from_pretrained(\\'vinvino02/glpn-kitti\\')\", \\'api_arguments\\': \\'images, return_tensors\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'from transformers import GLPNFeatureExtractor, GLPNForDepthEstimation\\\nimport torch\\\nimport numpy as np\\\nfrom PIL import Image\\\nimport requests\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\nfeature_extractor = GLPNFeatureExtractor.from_pretrained(vinvino02/glpn-kitti)\\\nmodel = GLPNForDepthEstimation.from_pretrained(vinvino02/glpn-kitti)\\\ninputs = feature_extractor(images=image, return_tensors=pt)\\\nwith torch.no_grad():\\\n outputs = model(**inputs)\\\n predicted_depth = outputs.predicted_depth\\\nprediction = torch.nn.functional.interpolate(\\\n predicted_depth.unsqueeze(1),\\\n size=image.size[::-1],\\\n mode=bicubic,\\\n align_corners=False,\\\n)\\\noutput = prediction.squeeze().cpu().numpy()\\\nformatted = (output * 255 / np.max(output)).astype(uint8)\\\ndepth = Image.fromarray(formatted)\\', \\'performance\\': {\\'dataset\\': \\'KITTI\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 19, "text": " The client is a real estate company working on virtual tours. We need to help them estimate depth in images of houses.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Depth Estimation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Depth Estimation\\', \\'api_name\\': \\'glpn-kitti\\', \\'api_call\\': \"GLPNForDepthEstimation.from_pretrained(\\'vinvino02/glpn-kitti\\')\", \\'api_arguments\\': \\'images, return_tensors\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'from transformers import GLPNFeatureExtractor, GLPNForDepthEstimation\\\nimport torch\\\nimport numpy as np\\\nfrom PIL import Image\\\nimport requests\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\nfeature_extractor = GLPNFeatureExtractor.from_pretrained(vinvino02/glpn-kitti)\\\nmodel = GLPNForDepthEstimation.from_pretrained(vinvino02/glpn-kitti)\\\ninputs = feature_extractor(images=image, return_tensors=pt)\\\nwith torch.no_grad():\\\n outputs = model(**inputs)\\\n predicted_depth = outputs.predicted_depth\\\nprediction = torch.nn.functional.interpolate(\\\n predicted_depth.unsqueeze(1),\\\n size=image.size[::-1],\\\n mode=bicubic,\\\n align_corners=False,\\\n)\\\noutput = prediction.squeeze().cpu().numpy()\\\nformatted = (output * 255 / np.max(output)).astype(uint8)\\\ndepth = Image.fromarray(formatted)\\', \\'performance\\': {\\'dataset\\': \\'KITTI\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 20, "text": " Assist me in setting up an image classifier that can recognize objects within an image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Zero-Shot Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Zero-Shot Image Classification\\', \\'api_name\\': \\'patrickjohncyh/fashion-clip\\', \\'api_call\\': \"CLIPModel.from_pretrained(\\'patrickjohncyh/fashion-clip\\')\", \\'api_arguments\\': {\\'image\\': \\'File\\', \\'class_names\\': \\'String (comma-separated)\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import CLIPProcessor, CLIPModel; model = CLIPModel.from_pretrained(\\'patrickjohncyh/fashion-clip\\'); processor = CLIPProcessor.from_pretrained(\\'patrickjohncyh/fashion-clip\\'); inputs = processor(text=\\'blue shoes\\', images=image, return_tensors=\\'pt\\', padding=True); logits_per_image = model(**inputs).logits_per_image; probs = logits_per_image.softmax(dim=-1).tolist()[0]\", \\'performance\\': {\\'dataset\\': [{\\'name\\': \\'FMNIST\\', \\'accuracy\\': 0.83}, {\\'name\\': \\'KAGL\\', \\'accuracy\\': 0.73}, {\\'name\\': \\'DEEP\\', \\'accuracy\\': 0.62}]}, \\'description\\': \\'FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 21, "text": " Identify an object within an image based on textual description. For example, find a dog in the image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'zero-shot-object-detection\\', \\'api_name\\': \\'google/owlvit-base-patch16\\', \\'api_call\\': \"OwlViTForObjectDetection.from_pretrained(\\'google/owlvit-base-patch16\\')\", \\'api_arguments\\': [\\'texts\\', \\'images\\'], \\'python_environment_requirements\\': [\\'requests\\', \\'PIL\\', \\'torch\\', \\'transformers\\'], \\'example_code\\': \\'processor = OwlViTProcessor.from_pretrained(google/owlvit-base-patch16)\\\nmodel = OwlViTForObjectDetection.from_pretrained(google/owlvit-base-patch16)\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\ntexts = [[a photo of a cat, a photo of a dog]]\\\ninputs = processor(text=texts, images=image, return_tensors=pt)\\\noutputs = model(**inputs)\\\ntarget_sizes = torch.Tensor([image.size[::-1]])\\\nresults = processor.post_process(outputs=outputs, target_sizes=target_sizes)\\', \\'performance\\': {\\'dataset\\': \\'COCO\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. OWL-ViT uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 22, "text": " Our client is an AI gaming company and we need to develop a bot for the game Valorant. The bot should detect objects like dropped spike, enemy, planted spike, and teammate within the game.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Object Detection\\', \\'api_name\\': \\'keremberke/yolov8m-valorant-detection\\', \\'api_call\\': \"YOLO(\\'keremberke/yolov8m-valorant-detection\\')\", \\'api_arguments\\': {\\'conf\\': 0.25, \\'iou\\': 0.45, \\'agnostic_nms\\': False, \\'max_det\\': 1000}, \\'python_environment_requirements\\': \\'pip install ultralyticsplus==0.0.23 ultralytics==8.0.21\\', \\'example_code\\': \"from ultralyticsplus import YOLO, render_result\\\nmodel = YOLO(\\'keremberke/yolov8m-valorant-detection\\')\\\nmodel.overrides[\\'conf\\'] = 0.25\\\nmodel.overrides[\\'iou\\'] = 0.45\\\nmodel.overrides[\\'agnostic_nms\\'] = False\\\nmodel.overrides[\\'max_det\\'] = 1000\\\nimage = \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'\\\nresults = model.predict(image)\\\nprint(results[0].boxes)\\\nrender = render_result(model=model, image=image, result=results[0])\\\nrender.show()\", \\'performance\\': {\\'dataset\\': \\'valorant-object-detection\\', \\'accuracy\\': 0.965}, \\'description\\': \\'A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 23, "text": " A client from real estate agency needs to get a list of objects present in a series of pictures to prepare their property listings.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'dreamlike-art/dreamlike-photoreal-2.0\\', \\'api_call\\': \"StableDiffusionPipeline.from_pretrained(\\'dreamlike-art/dreamlike-photoreal-2.0\\', torch_dtype=torch.float16)(prompt).images[0]\", \\'api_arguments\\': {\\'prompt\\': \\'photo, a church in the middle of a field of crops, bright cinematic lighting, gopro, fisheye lens\\'}, \\'python_environment_requirements\\': {\\'torch\\': \\'torch.float16\\', \\'diffusers\\': \\'StableDiffusionPipeline\\'}, \\'example_code\\': \\'from diffusers import StableDiffusionPipeline\\\nimport torch\\\nmodel_id = dreamlike-art/dreamlike-photoreal-2.0\\\npipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\\\npipe = pipe.to(cuda)\\\nprompt = photo, a church in the middle of a field of crops, bright cinematic lighting, gopro, fisheye lens\\\nimage = pipe(prompt).images[0]\\\nimage.save(./result.jpg)\\', \\'performance\\': {\\'dataset\\': \\'Stable Diffusion 1.5\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 24, "text": " We are developing an application for smartphones which automatically separates elements in a user's photo, and we need to implement this feature.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Image-to-Text\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'kha-white/manga-ocr-base\\', \\'api_call\\': \"pipeline(\\'ocr\\', model=\\'kha-white/manga-ocr-base\\')\", \\'api_arguments\\': \\'image\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'manga109s\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 25, "text": " I have a picture of a room demonstrating a mixture of objects. The model needs to seperate the objects and label them accordingly.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Classification\\', \\'framework\\': \\'Joblib\\', \\'functionality\\': \\'Multi-class Classification\\', \\'api_name\\': \\'Alexei1/imdb\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'json\\', \\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'IMDB\\', \\'accuracy\\': 0.487}, \\'description\\': \\'A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 26, "text": " We want to randomly generate high-quality images of celebrity faces.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'gsdf/Counterfeit-V2.5\\', \\'api_call\\': \"pipeline(\\'text-to-image\\', model=\\'gsdf/Counterfeit-V2.5\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'((masterpiece,best quality)),1girl, solo, animal ears, rabbit, barefoot, knees up, dress, sitting, rabbit ears, short sleeves, looking at viewer, grass, short hair, smile, white hair, puffy sleeves, outdoors, puffy short sleeves, bangs, on ground, full body, animal, white dress, sunlight, brown eyes, dappled sunlight, day, depth of field\\', \\'performance\\': {\\'dataset\\': \\'EasyNegative\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 27, "text": " Generate a new image based on the online database of bedroom art.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Unconditional Image Generation\\', \\'api_name\\': \\'johnowhitaker/sd-class-wikiart-from-bedrooms\\', \\'api_call\\': \"DDPMPipeline.from_pretrained(\\'johnowhitaker/sd-class-wikiart-from-bedrooms\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'diffusers\\', \\'example_code\\': \"from diffusers import DDPMPipeline\\\npipeline = DDPMPipeline.from_pretrained(\\'johnowhitaker/sd-class-wikiart-from-bedrooms\\')\\\nimage = pipeline().images[0]\\\nimage\", \\'performance\\': {\\'dataset\\': \\'https://huggingface.co/datasets/huggan/wikiart\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 28, "text": " I run an online store that sells butterfly-themed products. Please generate an image of a cute butterfly for our social media page.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Unconditional Image Generation\\', \\'api_name\\': \\'ntrant7/sd-class-butterflies-32\\', \\'api_call\\': \"DDPMPipeline.from_pretrained(\\'ntrant7/sd-class-butterflies-32\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'diffusers\\'], \\'example_code\\': \"from diffusers import DDPMPipeline\\\npipeline = DDPMPipeline.from_pretrained(\\'ntrant7/sd-class-butterflies-32\\')\\\nimage = pipeline().images[0]\\\nimage\", \\'performance\\': {\\'dataset\\': \\'Not specified\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'This model is a diffusion model for unconditional image generation of cute butterflies.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 29, "text": " We need a video-based AI model for security purposes. We want the AI to check and categorize footage based on existing security guidelines.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'videomae-base-finetuned-RealLifeViolenceSituations-subset\\', \\'api_call\\': \"AutoModelForVideoClassification.from_pretrained(\\'dangle124/videomae-base-finetuned-RealLifeViolenceSituations-subset\\')\", \\'api_arguments\\': {\\'model_name\\': \\'dangle124/videomae-base-finetuned-RealLifeViolenceSituations-subset\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'4.27.2\\', \\'pytorch\\': \\'1.13.1\\', \\'datasets\\': \\'2.10.1\\', \\'tokenizers\\': \\'0.13.2\\'}, \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'unknown\\', \\'accuracy\\': 0.9533}, \\'description\\': \\'This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 30, "text": " A new project demands to classify videos for a social media platform. Let us create a video classification pipeline.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'chavinlo/TempoFunk\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'chavinlo/TempoFunk\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 31, "text": " I am an insurance adjustor. I need a zero-shot image classifier that will tell me whether a car has been involved in a major accident or had minor damages.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Zero-Shot Image Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Zero-Shot Image Classification\\', \\'api_name\\': \\'openai/clip-vit-large-patch14-336\\', \\'api_call\\': \"CLIPModel.from_pretrained(\\'openai/clip-vit-large-patch14\\').\", \\'api_arguments\\': \\'image_path, tokenizer, model\\', \\'python_environment_requirements\\': \\'Transformers 4.21.3, TensorFlow 2.8.2, Tokenizers 0.12.1\\', \\'example_code\\': \\'N/A\\', \\'performance\\': {\\'dataset\\': \\'unknown\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'This model was trained from scratch on an unknown dataset.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 32, "text": " I want to analyze a medical image to find out if it's an X-ray, an MRI scan, or a CT scan.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Image-to-Text\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'kha-white/manga-ocr-base\\', \\'api_call\\': \"pipeline(\\'ocr\\', model=\\'kha-white/manga-ocr-base\\')\", \\'api_arguments\\': \\'image\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'manga109s\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 33, "text": " We are building a quiz application where the image will be shown, and we have to choose a dressings matching that image. Please help in classifying the image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Zero-Shot Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Zero-Shot Image Classification\\', \\'api_name\\': \\'clip-vit-base-patch32-ko\\', \\'api_call\\': \"pipeline(\\'zero-shot-image-classification\\', model=\\'Bingsu/clip-vit-base-patch32-ko\\')\", \\'api_arguments\\': {\\'images\\': \\'url\\', \\'candidate_labels\\': \\'Array of strings\\', \\'hypothesis_template\\': \\'String\\'}, \\'python_environment_requirements\\': [\\'transformers\\', \\'torch\\', \\'PIL\\', \\'requests\\'], \\'example_code\\': \"from transformers import pipeline\\\nrepo = \\'Bingsu/clip-vit-base-patch32-ko\\'\\\npipe = pipeline(\\'zero-shot-image-classification\\', model=repo)\\\nurl = \\'http://images.cocodataset.org/val2017/000000039769.jpg\\'\\\nresult = pipe(images=url, candidate_labels=[], hypothesis_template=\\'{}\\')\\\nresult\", \\'performance\\': {\\'dataset\\': \\'AIHUB\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 34, "text": " We're developing a chatbot that can quickly identify and describe images for our Chinese-speaking users.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Generation\\', \\'api_name\\': \\'mywateriswet/ShuanBot\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'mywateriswet/ShuanBot\\')\", \\'api_arguments\\': \\'message\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"response = chatbot(\\'What is your name?\\')\", \\'performance\\': {\\'dataset\\': \\'N/A\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 35, "text": " We would like to understand the sentiment of user's messages in a customer support chat system.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Generation\\', \\'api_name\\': \\'mywateriswet/ShuanBot\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'mywateriswet/ShuanBot\\')\", \\'api_arguments\\': \\'message\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"response = chatbot(\\'What is your name?\\')\", \\'performance\\': {\\'dataset\\': \\'N/A\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 36, "text": " As a book store owner, I want to classify customer reviews into positive and negative sentiments.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentiment Analysis\\', \\'api_name\\': \\'michellejieli/NSFW_text_classifier\\', \\'api_call\\': \"pipeline(\\'sentiment-analysis\\', model=\\'michellejieli/NSFW_text_classification\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'classifier(I see you’ve set aside this special time to humiliate yourself in public.)\\', \\'performance\\': {\\'dataset\\': \\'Reddit posts\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 37, "text": " I am the owner of a news website. I have several consumers' comments about our publishing news. I want to analyze the sentiments of these comments.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentiment Analysis\\', \\'api_name\\': \\'michellejieli/NSFW_text_classifier\\', \\'api_call\\': \"pipeline(\\'sentiment-analysis\\', model=\\'michellejieli/NSFW_text_classification\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'classifier(I see you’ve set aside this special time to humiliate yourself in public.)\\', \\'performance\\': {\\'dataset\\': \\'Reddit posts\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 38, "text": " Our business is expanding to international markets. Analyze the sentiment of the following customer review to better understand their satisfaction with our product: \\\"\\u00a1Esto es maravilloso! Me encanta.\\\"\n###Input: \\\"\\u00a1Esto es maravilloso! Me encanta.\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentiment Analysis\\', \\'api_name\\': \\'finiteautomata/beto-sentiment-analysis\\', \\'api_call\\': \"pipeline(\\'sentiment-analysis\\', model=\\'finiteautomata/beto-sentiment-analysis\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'Hugging Face Transformers library\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'TASS 2020 corpus\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Model trained with TASS 2020 corpus (around ~5k tweets) of several dialects of Spanish. Base model is BETO, a BERT model trained in Spanish. Uses POS, NEG, NEU labels.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 39, "text": " We are a forum moderator team looking for a solution to classify comments into toxic or non-toxic categories.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'martin-ha/toxic-comment-model\\', \\'api_call\\': \"pipeline(model=\\'martin-ha/toxic-comment-model\\')\", \\'api_arguments\\': {\\'model_path\\': \\'martin-ha/toxic-comment-model\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import AutoModelForSequenceClassification, AutoTokenizer, TextClassificationPipeline\\\nmodel_path = martin-ha/toxic-comment-model\\\ntokenizer = AutoTokenizer.from_pretrained(model_path)\\\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\\\npipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\\\nprint(pipeline(\\'This is a test text.\\'))\", \\'performance\\': {\\'dataset\\': \\'held-out test set\\', \\'accuracy\\': 0.94, \\'f1-score\\': 0.59}, \\'description\\': \\'This model is a fine-tuned version of the DistilBERT model to classify toxic comments.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 40, "text": " My company is launching a social media campaign. We need an AI-based system that would automatically analyze the sentiment of any user-generated reviews or tweets concerning our product.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentiment Analysis\\', \\'api_name\\': \\'cardiffnlp/twitter-roberta-base-sentiment-latest\\', \\'api_call\\': \"pipeline(sentiment-analysis, model=AutoModel.from_pretrained(\\'cardiffnlp/twitter-roberta-base-sentiment-latest\\'), tokenizer=AutoTokenizer.from_pretrained(\\'cardiffnlp/twitter-roberta-base-sentiment-latest\\'))\", \\'api_arguments\\': {\\'model\\': \\'model_path\\', \\'tokenizer\\': \\'model_path\\'}, \\'python_environment_requirements\\': [\\'transformers\\', \\'numpy\\', \\'scipy\\'], \\'example_code\\': \\'from transformers import pipeline\\\nsentiment_task = pipeline(sentiment-analysis, model=model_path, tokenizer=model_path)\\\nsentiment_task(Covid cases are increasing fast!)\\', \\'performance\\': {\\'dataset\\': \\'tweet_eval\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. The model is suitable for English.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 41, "text": " I have jobs descriptions in French for sales manager, please highlight names of organizations or cities within the text.\n###Input: \\\"La soci\\u00e9t\\u00e9 de Paris est sp\\u00e9cialis\\u00e9e dans la vente de v\\u00e9hicules \\u00e9lectriques. Responsable des ventes, vous travaillerez au sein d'une \\u00e9quipe dynamique dans l'agence de Lyon. Vous \\u00eates charg\\u00e9(e) de d\\u00e9velopper le portefeuille client et d'assurer la satisfaction des clients existants. Dans ce contexte, vous devrez travailler en lien \\u00e9troit avec le directeur commercial et les autres \\u00e9quipes de l'entreprise. Une exp\\u00e9rience pr\\u00e9alable chez Renault est un atout.\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Audio-to-Audio\\', \\'framework\\': \\'Fairseq\\', \\'functionality\\': \\'speech-to-speech-translation\\', \\'api_name\\': \\'facebook/textless_sm_en_fr\\', \\'api_call\\': \"load_model_ensemble_and_task_from_hf_hub(\\'facebook/textless_sm_en_fr\\')\", \\'api_arguments\\': [\\'input_file\\'], \\'python_environment_requirements\\': [\\'huggingface_hub\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 42, "text": " In order to have a better understanding of our clients, I'd like to identify the names of people and organizations mentioned in the following customer review.\n###Input: \\\"I recently purchased a MacBook Pro from Apple Inc. and had a fantastic customer support experience. John from their tech support team was incredibly helpful and professional.\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'Zixtrauce/JohnBot\\', \\'api_call\\': \"AutoModelForCausalLM.from_pretrained(\\'Zixtrauce/JohnBot\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'Input a message to start chatting with Zixtrauce/JohnBot.\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 43, "text": " I am building a social media app that requires people to write fascinating stories rather than boring sentences. Detect named entities in a sentence by using an NER model.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Token Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Named Entity Recognition\\', \\'api_name\\': \\'dslim/bert-base-NER-uncased\\', \\'api_call\\': \"pipeline(\\'ner\\', model=\\'dslim/bert-base-NER-uncased\\')\", \\'api_arguments\\': {}, \\'python_environment_requirements\\': {\\'transformers\\': \\'>=4.0.0\\'}, \\'example_code\\': \"nlp(\\'My name is John and I live in New York.\\')\", \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 44, "text": " We have a large dataset of customer orders in the form of a table. Help us answer questions about this data.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'google/tapas-small-finetuned-sqa\\', \\'api_call\\': \"pipeline(\\'table-question-answering\\', model=\\'google/tapas-small-finetuned-sqa\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'msr_sqa\\', \\'accuracy\\': 0.6155}, \\'description\\': \\'TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 45, "text": " Gather information about annual income and age demographics of employees to predict retirement patterns. Make sure to identify top employees for potential promotions.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Classification\\', \\'framework\\': \\'Joblib\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'abhishek/autotrain-adult-census-xgboost\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'abhishek/autotrain-adult-census-xgboost\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'json\\', \\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'scikit-learn/adult-census-income\\', \\'accuracy\\': 0.8750191923844618}, \\'description\\': \"A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual\\'s income is above or below $50,000 per year.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 46, "text": " To track our sales data, we need to find total sales of a specific product based on a table containing sales information per week.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'google/tapas-small-finetuned-sqa\\', \\'api_call\\': \"pipeline(\\'table-question-answering\\', model=\\'google/tapas-small-finetuned-sqa\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'msr_sqa\\', \\'accuracy\\': 0.6155}, \\'description\\': \\'TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 47, "text": " I have a table containing information about various animals and their important characteristics. I need the system to answer a query to provide information about the tallest animal in the table.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'google/tapas-small-finetuned-sqa\\', \\'api_call\\': \"pipeline(\\'table-question-answering\\', model=\\'google/tapas-small-finetuned-sqa\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'msr_sqa\\', \\'accuracy\\': 0.6155}, \\'description\\': \\'TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 48, "text": " You are building an app that allows users to find quick answers to textbook questions. Users will send a message with the question, and the answer should be detected directly from the textbook content.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'distilbert-base-uncased-distilled-squad\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'distilbert-base-uncased-distilled-squad\\')\", \\'api_arguments\\': [\\'question\\', \\'context\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\nquestion_answerer = pipeline(question-answering, model=\\'distilbert-base-uncased-distilled-squad\\')\\\ncontext = r\\\n... Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\\\n... question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\\\n... a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\\\n... \\\nresult = question_answerer(question=What is a good example of a question answering dataset?, context=context)\\\nprint(\\\n... fAnswer: \\'{result[\\'answer\\']}\\', score: {round(result[\\'score\\'], 4)}, start: {result[\\'start\\']}, end: {result[\\'end\\']}\\\n...)\", \\'performance\\': {\\'dataset\\': \\'SQuAD v1.1\\', \\'accuracy\\': \\'86.9 F1 score\\'}, \\'description\\': \"DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT\\'s performances as measured on the GLUE language understanding benchmark.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 49, "text": " We want to make sure clarify some questions about the legal implications of a new partnership contract for a real estate development project.\n###Input: We hereby grant the Licensee the exclusive right to develop, construct, operate and promote the Project, as well as to manage the daily operations of the Licensed Facilities during the Term. In consideration for the grant of the License, the Licensee shall pay to the Licensor the full amount of Ten Million (10,000,000) Dollars within thirty (30) days after the execution hereof.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'impira/layoutlm-invoices\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'impira/layoutlm-invoices\\')\", \\'api_arguments\\': \\'question, context\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"qa_pipeline(question=\\'your question\\', context=\\'your document context\\')\", \\'performance\\': {\\'dataset\\': \\'proprietary dataset of invoices, SQuAD2.0, and DocVQA\\', \\'accuracy\\': \\'not provided\\'}, \\'description\\': \\'This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 50, "text": " Help me setup a tinyroberta model from deepset for Question and Answer. Provide a sample input and output.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'deepset/tinyroberta-squad2\\', \\'api_call\\': \"AutoModelForQuestionAnswering.from_pretrained(\\'deepset/tinyroberta-squad2\\')\", \\'api_arguments\\': {\\'model_name_or_path\\': \\'deepset/tinyroberta-squad2\\', \\'question\\': \\'Why is model conversion important?\\', \\'context\\': \\'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\\\nmodel_name = deepset/tinyroberta-squad2\\\nnlp = pipeline(\\'question-answering\\', model=model_name, tokenizer=model_name)\\\nQA_input = {\\\n \\'question\\': \\'Why is model conversion important?\\',\\\n \\'context\\': \\'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.\\'\\\n}\\\nres = nlp(QA_input)\", \\'performance\\': {\\'dataset\\': \\'squad_v2\\', \\'accuracy\\': {\\'exact\\': 78.69114798281817, \\'f1\\': 81.9198998536977}}, \\'description\\': \\'This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 51, "text": " I want to build a tool to answer questions automatically from a given document. Which model do you recommend for this task?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'distilbert-base-uncased-distilled-squad\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'distilbert-base-uncased-distilled-squad\\')\", \\'api_arguments\\': [\\'question\\', \\'context\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\nquestion_answerer = pipeline(question-answering, model=\\'distilbert-base-uncased-distilled-squad\\')\\\ncontext = r\\\n... Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\\\n... question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\\\n... a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\\\n... \\\nresult = question_answerer(question=What is a good example of a question answering dataset?, context=context)\\\nprint(\\\n... fAnswer: \\'{result[\\'answer\\']}\\', score: {round(result[\\'score\\'], 4)}, start: {result[\\'start\\']}, end: {result[\\'end\\']}\\\n...)\", \\'performance\\': {\\'dataset\\': \\'SQuAD v1.1\\', \\'accuracy\\': \\'86.9 F1 score\\'}, \\'description\\': \"DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT\\'s performances as measured on the GLUE language understanding benchmark.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 52, "text": " We have a French news agency and we want to categorize the news articles based on sports, politics, and science.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Zero-Shot Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Zero-Shot Classification\\', \\'api_name\\': \\'BaptisteDoyen/camembert-base-xnli\\', \\'api_call\\': \"pipeline(\\'zero-shot-classification\\', model=\\'BaptisteDoyen/camembert-base-xnli\\')\", \\'api_arguments\\': {\\'sequence\\': \\'str\\', \\'candidate_labels\\': \\'List[str]\\', \\'hypothesis_template\\': \\'str\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"sequence = L\\'équipe de France joue aujourd\\'hui au Parc des Princes\\\ncandidate_labels = [sport,politique,science]\\\nhypothesis_template = Ce texte parle de {}.\\\nclassifier(sequence, candidate_labels, hypothesis_template=hypothesis_template)\", \\'performance\\': {\\'dataset\\': \\'xnli\\', \\'accuracy\\': {\\'validation\\': 81.4, \\'test\\': 81.7}}, \\'description\\': \\'Camembert-base model fine-tuned on french part of XNLI dataset. One of the few Zero-Shot classification models working on French.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 53, "text": " I need a solution to detect whether a piece of news is talking about technology, sports, or politics.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentiment Analysis\\', \\'api_name\\': \\'michellejieli/NSFW_text_classifier\\', \\'api_call\\': \"pipeline(\\'sentiment-analysis\\', model=\\'michellejieli/NSFW_text_classification\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'classifier(I see you’ve set aside this special time to humiliate yourself in public.)\\', \\'performance\\': {\\'dataset\\': \\'Reddit posts\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 54, "text": " I want to build a chatbot that is used by language learners who want to communicate in French while they only know English. Generate a response for an English message.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Generation\\', \\'api_name\\': \\'mywateriswet/ShuanBot\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'mywateriswet/ShuanBot\\')\", \\'api_arguments\\': \\'message\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"response = chatbot(\\'What is your name?\\')\", \\'performance\\': {\\'dataset\\': \\'N/A\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 55, "text": " Translate the following text from French to English: \\u201cLe syst\\u00e8me \\u00e9ducatif fran\\u00e7ais est compos\\u00e9 d'\\u00e9coles maternelles, d'\\u00e9coles \\u00e9l\\u00e9mentaires, de coll\\u00e8ges et de lyc\\u00e9es.\\u201d\n###Input: Le syst\\u00e8me \\u00e9ducatif fran\\u00e7ais est compos\\u00e9 d'\\u00e9coles maternelles, d'\\u00e9coles \\u00e9l\\u00e9mentaires, de coll\\u00e8ges et de lyc\\u00e9es.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Translation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Translation\\', \\'api_name\\': \\'opus-mt-fr-en\\', \\'api_call\\': \"pipeline(\\'translation_fr_to_en\\', model=\\'Helsinki-NLP/opus-mt-fr-en\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\', \\'torch\\'], \\'example_code\\': \"translation_pipeline(\\'Bonjour, comment ça va?\\')\", \\'performance\\': {\\'dataset\\': \\'opus\\', \\'accuracy\\': {\\'BLEU\\': {\\'newsdiscussdev2015-enfr.fr.en\\': 33.1, \\'newsdiscusstest2015-enfr.fr.en\\': 38.7, \\'newssyscomb2009.fr.en\\': 30.3, \\'news-test2008.fr.en\\': 26.2, \\'newstest2009.fr.en\\': 30.2, \\'newstest2010.fr.en\\': 32.2, \\'newstest2011.fr.en\\': 33.0, \\'newstest2012.fr.en\\': 32.8, \\'newstest2013.fr.en\\': 33.9, \\'newstest2014-fren.fr.en\\': 37.8, \\'Tatoeba.fr.en\\': 57.5}}}, \\'description\\': \\'Helsinki-NLP/opus-mt-fr-en is a machine translation model trained to translate from French to English. It is based on the Marian NMT framework and trained on the OPUS dataset.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 56, "text": " I want to translate a text from one language to another.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Translation\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Translation\\', \\'api_name\\': \\'Helsinki-NLP/opus-mt-en-fr\\', \\'api_call\\': \"translate(\\'input_text\\', model=\\'Helsinki-NLP/opus-mt-en-fr\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'opus\\', \\'accuracy\\': {\\'BLEU\\': {\\'newsdiscussdev2015-enfr.en.fr\\': 33.8, \\'newsdiscusstest2015-enfr.en.fr\\': 40.0, \\'newssyscomb2009.en.fr\\': 29.8, \\'news-test2008.en.fr\\': 27.5, \\'newstest2009.en.fr\\': 29.4, \\'newstest2010.en.fr\\': 32.7, \\'newstest2011.en.fr\\': 34.3, \\'newstest2012.en.fr\\': 31.8, \\'newstest2013.en.fr\\': 33.2, \\'Tatoeba.en.fr\\': 50.5}}}, \\'description\\': \\'Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 57, "text": " Our team member has written a long article that needs to be published on a company blog. Can you provide a shorter summary to be used as a snippet on the landing page?\n###Input: \\\"Apple Inc. reported its quarterly earnings results yesterday. The company posted a record-breaking revenue of $123.9 billion for the first quarter of 2022, up by 11% from the same period last year. The increase was fueled by stronger demand for iPhones, iPads, and Macs, as well as continued growth in its services segment. Apple's operating profit for the quarter came in at $38.3 billion, up 17% from a year earlier. The results surpassed analysts' expectations, who had anticipated revenue of around $118 billion. This strong performance is largely attributed to the successful launch of the iPhone 13, which has enjoyed robust sales since its debut in September. Apple CEO Tim Cook said in a statement, \\\"Our record-breaking quarter reflects the strength of our entire ecosystem, from our innovative products and services to the unmatched dedication of our teams around the world.\\\" Despite the ongoing global supply chain disruptions, Apple has managed to maintain its growth trajectory, thanks in part to its vertically integrated operations and nimble supply chain management. The company is expected to face stiffer competition going forward, particularly in the smartphone market, as rivals introduce new devices and increased pricing pressures.\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'financial-summarization-pegasus\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'human-centered-summarization/financial-summarization-pegasus\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import PegasusTokenizer, PegasusForConditionalGeneration, TFPegasusForConditionalGeneration\\\nmodel_name = human-centered-summarization/financial-summarization-pegasus\\\ntokenizer = PegasusTokenizer.from_pretrained(model_name)\\\nmodel = PegasusForConditionalGeneration.from_pretrained(model_name)\\\ntext_to_summarize = National Commercial Bank (NCB), Saudi Arabia’s largest lender by assets, agreed to buy rival Samba Financial Group for $15 billion in the biggest banking takeover this year.NCB will pay 28.45 riyals ($7.58) for each Samba share, according to a statement on Sunday, valuing it at about 55.7 billion riyals. NCB will offer 0.739 new shares for each Samba share, at the lower end of the 0.736-0.787 ratio the banks set when they signed an initial framework agreement in June.The offer is a 3.5% premium to Samba’s Oct. 8 closing price of 27.50 riyals and about 24% higher than the level the shares traded at before the talks were made public. Bloomberg News first reported the merger discussions.The new bank will have total assets of more than $220 billion, creating the Gulf region’s third-largest lender. The entity’s $46 billion market capitalization nearly matches that of Qatar National Bank QPSC, which is still the Middle East’s biggest lender with about $268 billion of assets.\\\ninput_ids = tokenizer(text_to_summarize, return_tensors=pt).input_ids\\\noutput = model.generate(input_ids, max_length=32, num_beams=5, early_stopping=True)\\\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\\', \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 35.206, \\'ROUGE-2\\': 16.569, \\'ROUGE-L\\': 30.128, \\'ROUGE-LSUM\\': 30.171}}, \\'description\\': \\'This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 58, "text": " Write a summary of a conference held by the World Health Organization discussing the impacts of climate change on human health.\n###Input: Over the past week, the World Health Organization held a conference discussing the impacts of climate change on human health. The conference brought together leading experts from around the world to examine the current problems affecting people's health due to changing environmental conditions. The topics of discussion included increased occurrence of heat-related illnesses, heightened rates of vector-borne diseases, and the growing problem of air pollution. The conference concluded with a call to action for governments and organizations to invest in mitigating and adapting to the negative consequences of climate change for the sake of public health.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Abstractive Text Summarization\\', \\'api_name\\': \\'plguillou/t5-base-fr-sum-cnndm\\', \\'api_call\\': \"T5ForConditionalGeneration.from_pretrained(\\'plguillou/t5-base-fr-sum-cnndm\\')\", \\'api_arguments\\': {\\'input_text\\': \\'summarize: ARTICLE\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import T5Tokenizer, T5ForConditionalGeneration\\'}, \\'example_code\\': \\'tokenizer = T5Tokenizer.from_pretrained(plguillou/t5-base-fr-sum-cnndm)\\\nmodel = T5ForConditionalGeneration.from_pretrained(plguillou/t5-base-fr-sum-cnndm)\\', \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'ROUGE-1\\': 44.5252, \\'ROUGE-2\\': 22.652, \\'ROUGE-L\\': 29.8866}, \\'description\\': \\'This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 59, "text": " Please provide a brief overview of a news article.\n###Input: A new study suggests that eating chocolate at least once a week can lead to better cognition. The study, published in the journal Appetite, analyzed data from over 900 adults and found that individuals who consumed chocolate at least once a week performed better on cognitive tests than those who consumed chocolate less frequently. Researchers believe that the beneficial effects of chocolate on cognition may be due to the presence of flavonoids, which have been shown to be antioxidant-rich and to improve brain blood flow.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Classification\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Binary Classification\\', \\'api_name\\': \\'desertdev/autotrain-imdb-sentiment-analysis-44994113085\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'desertdev/autotrain-data-imdb-sentiment-analysis\\', \\'accuracy\\': 0.565}, \\'description\\': \\'A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 60, "text": " I developed a document generation app, I need to create a summary of a long article given as input to provide to my users before they read the full article.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Summarization\\', \\'api_name\\': \\'pszemraj/long-t5-tglobal-base-16384-book-summary\\', \\'api_call\\': \"T5ForConditionalGeneration.from_pretrained(\\'pszemraj/long-t5-tglobal-base-16384-book-summary\\')\", \\'api_arguments\\': [\\'long_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\nimport torch\\\nsummarizer = pipeline(\\\n summarization,\\\n pszemraj/long-t5-tglobal-base-16384-book-summary,\\\n device=0 if torch.cuda.is_available() else -1,\\\n)\\\nlong_text = Here is a lot of text I don\\'t want to read. Replace me\\\nresult = summarizer(long_text)\\\nprint(result[0][summary_text])\", \\'performance\\': {\\'dataset\\': \\'kmfoda/booksum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.408, \\'ROUGE-2\\': 6.065, \\'ROUGE-L\\': 16.721, \\'ROUGE-LSUM\\': 33.34}}, \\'description\\': \\'A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 61, "text": " We need a quick summary of a news article we found online. Can you help us with that?\n###Input: Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people's scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We're expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'csebuetnlp/mT5_multilingual_XLSum\\', \\'api_call\\': \"AutoModelForSeq2SeqLM.from_pretrained(\\'csebuetnlp/mT5_multilingual_XLSum\\')\", \\'api_arguments\\': [\\'model_name\\'], \\'python_environment_requirements\\': [\\'transformers==4.11.0.dev0\\'], \\'example_code\\': \"import re\\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\\nWHITESPACE_HANDLER = lambda k: re.sub(\\'\\\\\\\\s+\\', \\' \\', re.sub(\\'\\\\\\\n+\\', \\' \\', k.strip()))\\\narticle_text = Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people\\'s scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We\\'re expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\\\nmodel_name = csebuetnlp/mT5_multilingual_XLSum\\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\\\ninput_ids = tokenizer(\\\n [WHITESPACE_HANDLER(article_text)],\\\n return_tensors=pt,\\\n padding=max_length,\\\n truncation=True,\\\n max_length=512\\\n)[input_ids]\\\noutput_ids = model.generate(\\\n input_ids=input_ids,\\\n max_length=84,\\\n no_repeat_ngram_size=2,\\\n num_beams=4\\\n)[0]\\\nsummary = tokenizer.decode(\\\n output_ids,\\\n skip_special_tokens=True,\\\n clean_up_tokenization_spaces=False\\\n)\\\nprint(summary)\", \\'performance\\': {\\'dataset\\': \\'xsum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.5, \\'ROUGE-2\\': 13.934, \\'ROUGE-L\\': 28.988, \\'ROUGE-LSUM\\': 28.996, \\'loss\\': 2.067, \\'gen_len\\': 26.973}}, \\'description\\': \\'This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 62, "text": " We'd like our chatbot to act as a fictional character for engaging with our users.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Generation\\', \\'api_name\\': \\'mywateriswet/ShuanBot\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'mywateriswet/ShuanBot\\')\", \\'api_arguments\\': \\'message\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"response = chatbot(\\'What is your name?\\')\", \\'performance\\': {\\'dataset\\': \\'N/A\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 63, "text": " Write a story about a spaceship journey to a distant planet in search of a new home for humanity.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'prompthero/openjourney\\', \\'api_call\\': \"StableDiffusionPipeline.from_pretrained(\\'prompthero/openjourney\\', torch_dtype=torch.float16)\", \\'api_arguments\\': {\\'prompt\\': \\'string\\'}, \\'python_environment_requirements\\': [\\'diffusers\\', \\'torch\\'], \\'example_code\\': \\'from diffusers import StableDiffusionPipeline\\\nimport torch\\\nmodel_id = prompthero/openjourney\\\npipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\\\npipe = pipe.to(cuda)\\\nprompt = retro serie of different cars with different colors and shapes, mdjrny-v4 style\\\nimage = pipe(prompt).images[0]\\\nimage.save(./retro_cars.png)\\', \\'performance\\': {\\'dataset\\': \\'Midjourney images\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 64, "text": " I want to write a story about a brave knight and a dragon but I'm unable to come up with a good start. Help me with that.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 65, "text": " I need a text analysis tool that can automatically predict the most plausible missing text in a given sentence.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentence Correction\\', \\'api_name\\': \\'flexudy/t5-base-multi-sentence-doctor\\', \\'api_call\\': \"AutoModelWithLMHead.from_pretrained(\\'flexudy/t5-base-multi-sentence-doctor\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelWithLMHead\\\ntokenizer = AutoTokenizer.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\nmodel = AutoModelWithLMHead.from_pretrained(flexudy/t5-base-multi-sentence-doctor)\\\ninput_text = repair_sentence: m a medical doct context: {That is my job I a}{or I save lives} </s>\\\ninput_ids = tokenizer.encode(input_text, return_tensors=pt)\\\noutputs = model.generate(input_ids, max_length=32, num_beams=1)\\\nsentence = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\\\nassert sentence == I am a medical doctor.\\', \\'performance\\': {\\'dataset\\': \\'tatoeba\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 66, "text": " Help me fill in the blanks in the following Chinese sentence: \\\"\\u4e0a\\u6d77\\u662f\\u4e2d\\u56fd\\u7684[MASK]\\u5927\\u57ce\\u5e02\\u3002\\\"\n###Input: \\u4e0a\\u6d77\\u662f\\u4e2d\\u56fd\\u7684[MASK]\\u5927\\u57ce\\u5e02\\u3002\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Fill-Mask\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Fill-Mask\\', \\'api_name\\': \\'uer/albert-base-chinese-cluecorpussmall\\', \\'api_call\\': \"AlbertForMaskedLM.from_pretrained(\\'uer/albert-base-chinese-cluecorpussmall\\')\", \\'api_arguments\\': [\\'model\\', \\'tokenizer\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import BertTokenizer, AlbertForMaskedLM, FillMaskPipeline\\\ntokenizer = BertTokenizer.from_pretrained(uer/albert-base-chinese-cluecorpussmall)\\\nmodel = AlbertForMaskedLM.from_pretrained(uer/albert-base-chinese-cluecorpussmall)\\\nunmasker = FillMaskPipeline(model, tokenizer)\\\nunmasker(中国的首都是[MASK]京。)\\', \\'performance\\': {\\'dataset\\': \\'CLUECorpusSmall\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 67, "text": " We are building a source code autocompletion tool which will complete the code snippet containing a masked token.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Fill-Mask\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Fill-Mask\\', \\'api_name\\': \\'camembert-base\\', \\'api_call\\': \"pipeline(\\'fill-mask\\', model=\\'camembert-base\\', tokenizer=\\'camembert-base\\')\", \\'api_arguments\\': [\\'model\\', \\'tokenizer\\'], \\'python_environment_requirements\\': [\\'transformers\\', \\'torch\\'], \\'example_code\\': \"from transformers import pipeline; camembert_fill_mask = pipeline(\\'fill-mask\\', model=\\'camembert-base\\', tokenizer=\\'camembert-base\\'); results = camembert_fill_mask(\\'Le camembert est <mask> :)\\')\", \\'performance\\': {\\'dataset\\': \\'oscar\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 68, "text": " I work for a Japanese company, and my manager needs me to take a look at a request from a client. I can understand fluent Japanese, but I need a little help filling in missing words from the text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Fill-Mask\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Fill-Mask\\', \\'api_name\\': \\'cl-tohoku/bert-base-japanese\\', \\'api_call\\': \"AutoModelForMaskedLM.from_pretrained(\\'cl-tohoku/bert-base-japanese\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"fill_mask(\\'[MASK]\\')\", \\'performance\\': {\\'dataset\\': \\'wikipedia\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 69, "text": " We are building a platform to compare and contrast user input sentences with existing sentences in our database. It should return similar results.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Sentence Similarity\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Sentence Transformers\\', \\'api_name\\': \\'sentence-transformers/distiluse-base-multilingual-cased-v1\\', \\'api_call\\': \"SentenceTransformer(\\'sentence-transformers/distiluse-base-multilingual-cased-v1\\')\", \\'api_arguments\\': [\\'sentences\\'], \\'python_environment_requirements\\': \\'pip install -U sentence-transformers\\', \\'example_code\\': \"from sentence_transformers import SentenceTransformer\\\nsentences = [This is an example sentence, Each sentence is converted]\\\nmodel = SentenceTransformer(\\'sentence-transformers/distiluse-base-multilingual-cased-v1\\')\\\nembeddings = model.encode(sentences)\\\nprint(embeddings)\", \\'performance\\': {\\'dataset\\': \\'https://seb.sbert.net\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 70, "text": " I need a method to compare the similarity between two sentences to be used within a meme generator, so we can produce a meme with a similar caption.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Sentence Similarity\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Sentence Transformers\\', \\'api_name\\': \\'sentence-transformers/distiluse-base-multilingual-cased-v2\\', \\'api_call\\': \"SentenceTransformer(\\'sentence-transformers/distiluse-base-multilingual-cased-v2\\')\", \\'api_arguments\\': [\\'sentences\\'], \\'python_environment_requirements\\': \\'pip install -U sentence-transformers\\', \\'example_code\\': \"from sentence_transformers import SentenceTransformer\\\nsentences = [This is an example sentence, Each sentence is converted]\\\nmodel = SentenceTransformer(\\'sentence-transformers/distiluse-base-multilingual-cased-v2\\')\\\nembeddings = model.encode(sentences)\\\nprint(embeddings)\", \\'performance\\': {\\'dataset\\': \\'https://seb.sbert.net\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 71, "text": " A student is writing a research paper and needs help with finding similar articles in order to include them in the literature review section.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Sentence Similarity\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Sentence Embeddings\\', \\'api_name\\': \\'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\\', \\'api_call\\': \"SentenceTransformer(\\'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\\')\", \\'api_arguments\\': [\\'sentences\\'], \\'python_environment_requirements\\': \\'pip install -U sentence-transformers\\', \\'example_code\\': \"from sentence_transformers import SentenceTransformer\\\nsentences = [This is an example sentence, Each sentence is converted]\\\nmodel = SentenceTransformer(\\'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\\')\\\nembeddings = model.encode(sentences)\\\nprint(embeddings)\", \\'performance\\': {\\'dataset\\': \\'https://seb.sbert.net\\', \\'accuracy\\': \\'Automated evaluation\\'}, \\'description\\': \\'This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 72, "text": " Create a solution to convert a given Japanese sentence into a speech audio file.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Speech Recognition\\', \\'api_name\\': \\'jonatasgrosman/wav2vec2-large-xlsr-53-japanese\\', \\'api_call\\': \"SpeechRecognitionModel(\\'jonatasgrosman/wav2vec2-large-xlsr-53-japanese\\')\", \\'api_arguments\\': [\\'audio_paths\\'], \\'python_environment_requirements\\': [\\'huggingsound\\', \\'torch\\', \\'librosa\\', \\'datasets\\', \\'transformers\\'], \\'example_code\\': \\'from huggingsound import SpeechRecognitionModel\\\nmodel = SpeechRecognitionModel(jonatasgrosman/wav2vec2-large-xlsr-53-japanese)\\\naudio_paths = [/path/to/file.mp3, /path/to/another_file.wav]\\\ntranscriptions = model.transcribe(audio_paths)\\', \\'performance\\': {\\'dataset\\': \\'common_voice\\', \\'accuracy\\': {\\'WER\\': 81.8, \\'CER\\': 20.16}}, \\'description\\': \\'Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 73, "text": " We are working on a transcription service for our customers. We need a way to convert audio files into text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'CTranslate2\\', \\'functionality\\': \\'Automatic Speech Recognition\\', \\'api_name\\': \\'guillaumekln/faster-whisper-large-v2\\', \\'api_call\\': \"WhisperModel(\\'large-v2\\')\", \\'api_arguments\\': [\\'audio.mp3\\'], \\'python_environment_requirements\\': [\\'faster_whisper\\'], \\'example_code\\': \\'from faster_whisper import WhisperModel\\\nmodel = WhisperModel(large-v2)\\\nsegments, info = model.transcribe(audio.mp3)\\\nfor segment in segments:\\\n print([%.2fs -&gt; %.2fs] %s % (segment.start, segment.end, segment.text))\\', \\'performance\\': {\\'dataset\\': \\'99 languages\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 74, "text": " We are creating an online video conference service, and we need to detect when two or more speakers are speaking at the same time in the audio.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Voice Activity Detection\\', \\'framework\\': \\'pyannote.audio\\', \\'functionality\\': \\'Speaker diarization\\', \\'api_name\\': \\'johnislarry/cloned-pyannote-speaker-diarization-endpoint\\', \\'api_call\\': \"Pipeline.from_pretrained(\\'pyannote/speaker-diarization@2.1\\',use_auth_token=\\'ACCESS_TOKEN_GOES_HERE\\')\", \\'api_arguments\\': [\\'num_speakers\\', \\'min_speakers\\', \\'max_speakers\\', \\'segmentation_onset\\'], \\'python_environment_requirements\\': \\'pyannote.audio 2.0\\', \\'example_code\\': {\\'load_pipeline\\': \\'from pyannote.audio import Pipeline\\\npipeline = Pipeline.from_pretrained(pyannote/speaker-diarization@2022.07)\\', \\'apply_pipeline\\': \\'diarization = pipeline(audio.wav)\\', \\'save_output\\': \\'with open(audio.rttm, w) as rttm:\\\n  diarization.write_rttm(rttm)\\'}, \\'performance\\': {\\'dataset\\': [{\\'name\\': \\'AISHELL-4\\', \\'accuracy\\': {\\'DER%\\': 14.61, \\'FA%\\': 3.31, \\'Miss%\\': 4.35, \\'Conf%\\': 6.95}}, {\\'name\\': \\'AMI Mix-Headset only_words\\', \\'accuracy\\': {\\'DER%\\': 18.21, \\'FA%\\': 3.28, \\'Miss%\\': 11.07, \\'Conf%\\': 3.87}}, {\\'name\\': \\'AMI Array1-01 only_words\\', \\'accuracy\\': {\\'DER%\\': 29.0, \\'FA%\\': 2.71, \\'Miss%\\': 21.61, \\'Conf%\\': 4.68}}, {\\'name\\': \\'CALLHOME Part2\\', \\'accuracy\\': {\\'DER%\\': 30.24, \\'FA%\\': 3.71, \\'Miss%\\': 16.86, \\'Conf%\\': 9.66}}, {\\'name\\': \\'DIHARD 3 Full\\', \\'accuracy\\': {\\'DER%\\': 20.99, \\'FA%\\': 4.25, \\'Miss%\\': 10.74, \\'Conf%\\': 6.0}}, {\\'name\\': \\'REPERE Phase 2\\', \\'accuracy\\': {\\'DER%\\': 12.62, \\'FA%\\': 1.55, \\'Miss%\\': 3.3, \\'Conf%\\': 7.76}}, {\\'name\\': \\'VoxConverse v0.0.2\\', \\'accuracy\\': {\\'DER%\\': 12.76, \\'FA%\\': 3.45, \\'Miss%\\': 3.85, \\'Conf%\\': 5.46}}]}, \\'description\\': \\'This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 75, "text": " Our company develops smart speaker devices that involve interaction with the user. We need to transcribe the input from the users with the maintained accent or language.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Text-to-Speech\\', \\'framework\\': \\'ESPnet\\', \\'functionality\\': \\'Text-to-Speech\\', \\'api_name\\': \\'SYSPIN/Telugu_Male_TTS\\', \\'api_call\\': \"pipeline(\\'text-to-speech\\', model=\\'SYSPIN/Telugu_Male_TTS\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A Telugu Male Text-to-Speech model using the ESPnet framework, provided by Hugging Face.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 76, "text": " One of our clients is facing noise issues on their audio recordings. Can you help them to remove the noise from the audio?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Voice Activity Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Voice Activity Detection, Speech-to-Noise Ratio, and C50 Room Acoustics Estimation\\', \\'api_name\\': \\'pyannote/brouhaha\\', \\'api_call\\': \"Model.from_pretrained(\\'pyannote/brouhaha\\', use_auth_token=\\'ACCESS_TOKEN_GOES_HERE\\')\", \\'api_arguments\\': [\\'audio.wav\\'], \\'python_environment_requirements\\': [\\'pyannote-audio\\', \\'brouhaha-vad\\'], \\'example_code\\': [\\'from pyannote.audio import Model\\', \\'model = Model.from_pretrained(pyannote/brouhaha, use_auth_token=ACCESS_TOKEN_GOES_HERE)\\', \\'from pyannote.audio import Inference\\', \\'inference = Inference(model)\\', \\'output = inference(audio.wav)\\', \\'for frame, (vad, snr, c50) in output:\\', \\'  t = frame.middle\\', \\'  print(f{t:8.3f} vad={100*vad:.0f}% snr={snr:.0f} c50={c50:.0f})\\'], \\'performance\\': {\\'dataset\\': \\'LibriSpeech, AudioSet, EchoThief, MIT-Acoustical-Reverberation-Scene\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 77, "text": " We are a media company and we have a large volume of Chinese language audio files. We want to transcribe the audios into chinese text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'CTranslate2\\', \\'functionality\\': \\'Automatic Speech Recognition\\', \\'api_name\\': \\'guillaumekln/faster-whisper-large-v2\\', \\'api_call\\': \"WhisperModel(\\'large-v2\\')\", \\'api_arguments\\': [\\'audio.mp3\\'], \\'python_environment_requirements\\': [\\'faster_whisper\\'], \\'example_code\\': \\'from faster_whisper import WhisperModel\\\nmodel = WhisperModel(large-v2)\\\nsegments, info = model.transcribe(audio.mp3)\\\nfor segment in segments:\\\n print([%.2fs -&gt; %.2fs] %s % (segment.start, segment.end, segment.text))\\', \\'performance\\': {\\'dataset\\': \\'99 languages\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 78, "text": " Help us improve the listener experience from our customers by enhancing the audio of noisy recordings.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Voice Activity Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Voice Activity Detection, Speech-to-Noise Ratio, and C50 Room Acoustics Estimation\\', \\'api_name\\': \\'pyannote/brouhaha\\', \\'api_call\\': \"Model.from_pretrained(\\'pyannote/brouhaha\\', use_auth_token=\\'ACCESS_TOKEN_GOES_HERE\\')\", \\'api_arguments\\': [\\'audio.wav\\'], \\'python_environment_requirements\\': [\\'pyannote-audio\\', \\'brouhaha-vad\\'], \\'example_code\\': [\\'from pyannote.audio import Model\\', \\'model = Model.from_pretrained(pyannote/brouhaha, use_auth_token=ACCESS_TOKEN_GOES_HERE)\\', \\'from pyannote.audio import Inference\\', \\'inference = Inference(model)\\', \\'output = inference(audio.wav)\\', \\'for frame, (vad, snr, c50) in output:\\', \\'  t = frame.middle\\', \\'  print(f{t:8.3f} vad={100*vad:.0f}% snr={snr:.0f} c50={c50:.0f})\\'], \\'performance\\': {\\'dataset\\': \\'LibriSpeech, AudioSet, EchoThief, MIT-Acoustical-Reverberation-Scene\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 79, "text": " Our company is working on a project to automatically translate spoken English audio to spoken Hokkien audio. We need a speech-to-speech translation model.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Text-to-Speech\\', \\'framework\\': \\'Fairseq\\', \\'functionality\\': \\'Text-to-Speech\\', \\'api_name\\': \\'unit_hifigan_HK_layer12.km2500_frame_TAT-TTS\\', \\'api_call\\': \"load_model_ensemble_and_task_from_hf_hub(\\'facebook/unit_hifigan_HK_layer12.km2500_frame_TAT-TT\\')\", \\'api_arguments\\': {\\'unit\\': \\'Text input for the TTS model\\'}, \\'python_environment_requirements\\': [\\'fairseq\\', \\'huggingface_hub\\', \\'torchaudio\\'], \\'example_code\\': \"import json\\\nimport os\\\nfrom pathlib import Path\\\nimport IPython.display as ipd\\\nfrom fairseq import hub_utils\\\nfrom fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\\\nfrom fairseq.models.speech_to_text.hub_interface import S2THubInterface\\\nfrom fairseq.models.text_to_speech import CodeHiFiGANVocoder\\\nfrom fairseq.models.text_to_speech.hub_interface import VocoderHubInterface\\\nfrom huggingface_hub import snapshot_download\\\nimport torchaudio\\\ncache_dir = os.getenv(HUGGINGFACE_HUB_CACHE)\\\nlibrary_name = fairseq\\\ncache_dir = (\\\n cache_dir or (Path.home() / .cache / library_name).as_posix()\\\n)\\\ncache_dir = snapshot_download(\\\n ffacebook/unit_hifigan_HK_layer12.km2500_frame_TAT-TTS, cache_dir=cache_dir, library_name=library_name\\\n)\\\nx = hub_utils.from_pretrained(\\\n cache_dir,\\\n model.pt,\\\n .,\\\n archive_map=CodeHiFiGANVocoder.hub_models(),\\\n config_yaml=config.json,\\\n fp16=False,\\\n is_vocoder=True,\\\n)\\\nwith open(f{x[\\'args\\'][\\'data\\']}/config.json) as f:\\\n vocoder_cfg = json.load(f)\\\nassert (\\\n len(x[args][model_path]) == 1\\\n), Too many vocoder models in the input\\\nvocoder = CodeHiFiGANVocoder(x[args][model_path][0], vocoder_cfg)\\\ntts_model = VocoderHubInterface(vocoder_cfg, vocoder)\\\ntts_sample = tts_model.get_model_input(unit)\\\nwav, sr = tts_model.get_prediction(tts_sample)\\\nipd.Audio(wav, rate=sr)\", \\'performance\\': {\\'dataset\\': \\'TAT-TTS\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 80, "text": " We are a startup developing voice assistants. We need a keyword spotting system that can recognize user commands.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Voice Activity Detection\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Voice Activity Detection\\', \\'api_name\\': \\'d4data/Indian-voice-cloning\\', \\'api_call\\': \"pipeline(\\'voice-activity-detection\\', model=\\'d4data/Indian-voice-cloning\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A model for detecting voice activity in Indian languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 81, "text": " The model needs to have speech recognition capability to identify languages in a given audio file.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Speech Recognition\\', \\'api_name\\': \\'jonatasgrosman/wav2vec2-large-xlsr-53-portuguese\\', \\'api_call\\': \"SpeechRecognitionModel(\\'jonatasgrosman/wav2vec2-large-xlsr-53-portuguese\\')\", \\'api_arguments\\': [\\'audio_paths\\'], \\'python_environment_requirements\\': [\\'huggingsound\\', \\'torch\\', \\'librosa\\', \\'datasets\\', \\'transformers\\'], \\'example_code\\': \\'from huggingsound import SpeechRecognitionModel\\\nmodel = SpeechRecognitionModel(jonatasgrosman/wav2vec2-large-xlsr-53-portuguese)\\\naudio_paths = [/path/to/file.mp3, /path/to/another_file.wav]\\\ntranscriptions = model.transcribe(audio_paths)\\', \\'performance\\': {\\'dataset\\': \\'mozilla-foundation/common_voice_6_0\\', \\'accuracy\\': {\\'Test WER\\': 11.31, \\'Test CER\\': 3.74, \\'Test WER (+LM)\\': 9.01, \\'Test CER (+LM)\\': 3.21}}, \\'description\\': \\'Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 82, "text": " I have just recorded a meeting, I want to find the best segments from the audio where people are speaking, and construct a summary.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Voice Activity Detection\\', \\'framework\\': \\'pyannote.audio\\', \\'functionality\\': \\'Speaker diarization\\', \\'api_name\\': \\'johnislarry/cloned-pyannote-speaker-diarization-endpoint\\', \\'api_call\\': \"Pipeline.from_pretrained(\\'pyannote/speaker-diarization@2.1\\',use_auth_token=\\'ACCESS_TOKEN_GOES_HERE\\')\", \\'api_arguments\\': [\\'num_speakers\\', \\'min_speakers\\', \\'max_speakers\\', \\'segmentation_onset\\'], \\'python_environment_requirements\\': \\'pyannote.audio 2.0\\', \\'example_code\\': {\\'load_pipeline\\': \\'from pyannote.audio import Pipeline\\\npipeline = Pipeline.from_pretrained(pyannote/speaker-diarization@2022.07)\\', \\'apply_pipeline\\': \\'diarization = pipeline(audio.wav)\\', \\'save_output\\': \\'with open(audio.rttm, w) as rttm:\\\n  diarization.write_rttm(rttm)\\'}, \\'performance\\': {\\'dataset\\': [{\\'name\\': \\'AISHELL-4\\', \\'accuracy\\': {\\'DER%\\': 14.61, \\'FA%\\': 3.31, \\'Miss%\\': 4.35, \\'Conf%\\': 6.95}}, {\\'name\\': \\'AMI Mix-Headset only_words\\', \\'accuracy\\': {\\'DER%\\': 18.21, \\'FA%\\': 3.28, \\'Miss%\\': 11.07, \\'Conf%\\': 3.87}}, {\\'name\\': \\'AMI Array1-01 only_words\\', \\'accuracy\\': {\\'DER%\\': 29.0, \\'FA%\\': 2.71, \\'Miss%\\': 21.61, \\'Conf%\\': 4.68}}, {\\'name\\': \\'CALLHOME Part2\\', \\'accuracy\\': {\\'DER%\\': 30.24, \\'FA%\\': 3.71, \\'Miss%\\': 16.86, \\'Conf%\\': 9.66}}, {\\'name\\': \\'DIHARD 3 Full\\', \\'accuracy\\': {\\'DER%\\': 20.99, \\'FA%\\': 4.25, \\'Miss%\\': 10.74, \\'Conf%\\': 6.0}}, {\\'name\\': \\'REPERE Phase 2\\', \\'accuracy\\': {\\'DER%\\': 12.62, \\'FA%\\': 1.55, \\'Miss%\\': 3.3, \\'Conf%\\': 7.76}}, {\\'name\\': \\'VoxConverse v0.0.2\\', \\'accuracy\\': {\\'DER%\\': 12.76, \\'FA%\\': 3.45, \\'Miss%\\': 3.85, \\'Conf%\\': 5.46}}]}, \\'description\\': \\'This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 83, "text": " I am running a wine store, and I am looking for a machine learning model that can help me classify the quality of wine based on some given features.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Classification\\', \\'framework\\': \\'Scikit-learn\\', \\'functionality\\': \\'Wine Quality classification\\', \\'api_name\\': \\'julien-c/wine-quality\\', \\'api_call\\': \"joblib.load(cached_download(hf_hub_url(\\'julien-c/wine-quality\\', \\'winequality-red.csv\\')))\", \\'api_arguments\\': [\\'X\\'], \\'python_environment_requirements\\': [\\'huggingface_hub\\', \\'joblib\\', \\'pandas\\'], \\'example_code\\': \\'from huggingface_hub import hf_hub_url, cached_download\\\nimport joblib\\\nimport pandas as pd\\\nREPO_ID = julien-c/wine-quality\\\nFILENAME = sklearn_model.joblib\\\nmodel = joblib.load(cached_download(\\\n hf_hub_url(REPO_ID, FILENAME)\\\n))\\\ndata_file = cached_download(\\\n hf_hub_url(REPO_ID, winequality-red.csv)\\\n)\\\nwinedf = pd.read_csv(data_file, sep=;)\\\nX = winedf.drop([quality], axis=1)\\\nY = winedf[quality]\\\nprint(X[:3])\\\nlabels = model.predict(X[:3])\\\nmodel.score(X, Y)\\', \\'performance\\': {\\'dataset\\': \\'julien-c/wine-quality\\', \\'accuracy\\': 0.6616635397123202}, \\'description\\': \\'A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 84, "text": " Build a simple application to predict the survival status of passengers on the Titanic based on their age, gender, and passenger class.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Classification\\', \\'framework\\': \\'Scikit-learn\\', \\'functionality\\': \\'Binary Classification\\', \\'api_name\\': \\'danupurnomo/dummy-titanic\\', \\'api_call\\': \"load_model(cached_download(hf_hub_url(\\'danupurnomo/dummy-titanic\\', \\'titanic_model.h5\\')))\", \\'api_arguments\\': [\\'new_data\\'], \\'python_environment_requirements\\': [\\'huggingface_hub\\', \\'joblib\\', \\'pandas\\', \\'numpy\\', \\'tensorflow\\'], \\'example_code\\': \"from huggingface_hub import hf_hub_url, cached_download\\\nimport joblib\\\nimport pandas as pd\\\nimport numpy as np\\\nfrom tensorflow.keras.models import load_model\\\nREPO_ID = \\'danupurnomo/dummy-titanic\\'\\\nPIPELINE_FILENAME = \\'final_pipeline.pkl\\'\\\nTF_FILENAME = \\'titanic_model.h5\\'\\\nmodel_pipeline = joblib.load(cached_download(\\\n hf_hub_url(REPO_ID, PIPELINE_FILENAME)\\\n))\\\nmodel_seq = load_model(cached_download(\\\n hf_hub_url(REPO_ID, TF_FILENAME)\\\n))\", \\'performance\\': {\\'dataset\\': \\'Titanic\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 85, "text": " I need to estimate CO2 emissions from vehicles based on their characteristics, such as engine size, transmission type, and miles traveled.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Carbon Emissions\\', \\'api_name\\': \\'kochetkovIT/autotrain-ironhack-49741119788\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'json\\', \\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'kochetkovIT/autotrain-data-ironhack\\', \\'accuracy\\': {\\'Loss\\': 2.603, \\'R2\\': 0.013, \\'MSE\\': 6.776, \\'MAE\\': 1.666, \\'RMSLE\\': 0.502}}, \\'description\\': \\'A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 86, "text": " We have been asked to predict future criminal re-offense from a given dataset. What model should we adopt and how do we proceed?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Classification\\', \\'framework\\': \\'Scikit-learn\\', \\'functionality\\': \\'Classification\\', \\'api_name\\': \\'imodels/figs-compas-recidivism\\', \\'api_call\\': \"joblib.load(cached_download(hf_hub_url(\\'imodels/figs-compas-recidivism\\', \\'sklearn_model.joblib\\')))\", \\'api_arguments\\': [\\'REPO_ID\\', \\'FILENAME\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'huggingface_hub\\', \\'pandas\\', \\'numpy\\', \\'datasets\\', \\'imodels\\', \\'sklearn.model_selection\\'], \\'example_code\\': \"from huggingface_hub import hf_hub_url, cached_download\\\nimport joblib\\\nimport pandas as pd\\\nREPO_ID = imodels/figs-compas-recidivism\\\nFILENAME = sklearn_model.joblib\\\nmodel = joblib.load(cached_download(\\\n hf_hub_url(REPO_ID, FILENAME)\\\n))\\\npreds = model.predict(X_test)\\\nprint(\\'accuracy\\', np.mean(preds==y_test))\", \\'performance\\': {\\'dataset\\': \\'imodels/compas-recidivism\\', \\'accuracy\\': 0.6759165485112416}, \\'description\\': \\'A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 87, "text": " Our company's goal is to predict carbon emissions based on the given features of the compound.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Carbon Emissions\\', \\'api_name\\': \\'kochetkovIT/autotrain-ironhack-49741119788\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'json\\', \\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'kochetkovIT/autotrain-data-ironhack\\', \\'accuracy\\': {\\'Loss\\': 2.603, \\'R2\\': 0.013, \\'MSE\\': 6.776, \\'MAE\\': 1.666, \\'RMSLE\\': 0.502}}, \\'description\\': \\'A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 88, "text": " The factory wants to make its production process more eco-friendly. Calculate the carbon emissions for given data.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Carbon Emissions\\', \\'api_name\\': \\'45473113800\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'samvelkoch/autotrain-data-prknsn-2\\', \\'accuracy\\': {\\'Loss\\': 5.079, \\'R2\\': 0.109, \\'MSE\\': 25.795, \\'MAE\\': 3.78, \\'RMSLE\\': 0.849}}, \\'description\\': \\'A tabular regression model trained with AutoTrain for predicting carbon emissions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 89, "text": " We want to predict the carbon emissions of a new line of electric vehicles for an annual report. Automate the process of loading a regression model, then calculate the forecast of emissions for this year.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Carbon Emissions\\', \\'api_name\\': \\'kochetkovIT/autotrain-ironhack-49741119788\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'json\\', \\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'kochetkovIT/autotrain-data-ironhack\\', \\'accuracy\\': {\\'Loss\\': 2.603, \\'R2\\': 0.013, \\'MSE\\': 6.776, \\'MAE\\': 1.666, \\'RMSLE\\': 0.502}}, \\'description\\': \\'A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 90, "text": " We are planning to launch a website which provides tips to people for their daily lives. Can you please build a model to predict the appropriate amount of tips?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Scikit-learn\\', \\'functionality\\': \\'baseline-trainer\\', \\'api_name\\': \\'merve/tips9y0jvt5q-tip-regression\\', \\'api_call\\': \"pipeline(\\'tabular-regression\\', model=\\'merve/tips9y0jvt5q-tip-regression\\')\", \\'api_arguments\\': \\'N/A\\', \\'python_environment_requirements\\': \\'dabl\\', \\'example_code\\': \\'N/A\\', \\'performance\\': {\\'dataset\\': \\'tips9y0jvt5q\\', \\'accuracy\\': {\\'r2\\': 0.41524, \\'neg_mean_squared_error\\': -1.098792}}, \\'description\\': \\'Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 91, "text": " We have a robotic arm in our warehouse that needs to be trained to optimize loading and unloading tasks. The robotic arm is based on the CartPole environment.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Reinforcement Learning\\', \\'framework\\': \\'Stable-Baselines3\\', \\'functionality\\': \\'CartPole-v1\\', \\'api_name\\': \\'dqn-CartPole-v1\\', \\'api_call\\': \"load_from_hub(repo_id=\\'sb3/dqn-CartPole-v1\\',filename=\\'{MODEL FILENAME}.zip\\',)\", \\'api_arguments\\': [\\'algo\\', \\'env\\', \\'logs\\'], \\'python_environment_requirements\\': [\\'rl_zoo3\\', \\'stable-baselines3\\', \\'stable-baselines3-contrib\\'], \\'example_code\\': \\'python train.py --algo dqn --env CartPole-v1 -f logs/\\', \\'performance\\': {\\'dataset\\': \\'CartPole-v1\\', \\'accuracy\\': \\'500.00 +/- 0.00\\'}, \\'description\\': \\'This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 92, "text": " There is an upcoming event called \\\"Space Party\\\" and we need a representative image for the event. Can you assist us in creating an image containing a party in space with astronauts and aliens having fun together?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'prompthero/openjourney-v4\\', \\'api_call\\': \"pipeline(\\'text-to-image\\', model=\\'prompthero/openjourney-v4\\')\", \\'api_arguments\\': {\\'text\\': \\'string\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"generate_image(\\'your text here\\')\", \\'performance\\': {\\'dataset\\': \\'Midjourney v4 images\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 93, "text": " We're creating a promotional image for a wildlife-themed event. We need to display two tigers in a natural setting.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'tuner007/pegasus_summarizer\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'tuner007/pegasus_summarizer\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'pip install sentencepiece\\'], \\'example_code\\': \"context = \\\nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day\\'s play.You can say whatever you want to chant, but don\\'t throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England\\'s score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\\\n\\\nget_response(context)\", \\'performance\\': {\\'dataset\\': \\'cnn_dailymail\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.604, \\'ROUGE-2\\': 14.64, \\'ROUGE-L\\': 23.884, \\'ROUGE-LSUM\\': 32.902, \\'loss\\': 2.576, \\'gen_len\\': 76.398}}, \\'description\\': \\'PEGASUS fine-tuned for summarization\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 94, "text": " We have a collection of low-resolution images of movie characters, and we need to upscale those images to get a more detailed high-resolution image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Image Upscaling\\', \\'api_name\\': \\'stabilityai/sd-x2-latent-upscaler\\', \\'api_call\\': \\'StableDiffusionLatentUpscalePipeline.from_pretrained(stabilityai/sd-x2-latent-upscaler, torch_dtype=torch.float16)\\', \\'api_arguments\\': {\\'prompt\\': \\'text prompt\\', \\'image\\': \\'low resolution latents\\', \\'num_inference_steps\\': 20, \\'guidance_scale\\': 0, \\'generator\\': \\'torch generator\\'}, \\'python_environment_requirements\\': [\\'git+https://github.com/huggingface/diffusers.git\\', \\'transformers\\', \\'accelerate\\', \\'scipy\\', \\'safetensors\\'], \\'example_code\\': \\'from diffusers import StableDiffusionLatentUpscalePipeline, StableDiffusionPipeline\\\nimport torch\\\npipeline = StableDiffusionPipeline.from_pretrained(CompVis/stable-diffusion-v1-4, torch_dtype=torch.float16)\\\npipeline.to(cuda)\\\nupscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(stabilityai/sd-x2-latent-upscaler, torch_dtype=torch.float16)\\\nupscaler.to(cuda)\\\nprompt = a photo of an astronaut high resolution, unreal engine, ultra realistic\\\ngenerator = torch.manual_seed(33)\\\nlow_res_latents = pipeline(prompt, generator=generator, output_type=latent).images\\\nupscaled_image = upscaler(prompt=prompt, image=low_res_latents, num_inference_steps=20, guidance_scale=0, generator=generator).images[0]\\\nupscaled_image.save(astronaut_1024.png)\\', \\'performance\\': {\\'dataset\\': \\'LAION-2B\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \"Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion\\'s latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 95, "text": " I want you to create a function that generates captions for a list of images.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Image-to-Text\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'promptcap-coco-vqa\\', \\'api_call\\': \"PromptCap(\\'vqascore/promptcap-coco-vqa\\')\", \\'api_arguments\\': {\\'prompt\\': \\'string\\', \\'image\\': \\'string\\'}, \\'python_environment_requirements\\': \\'pip install promptcap\\', \\'example_code\\': [\\'import torch\\', \\'from promptcap import PromptCap\\', \\'model = PromptCap(vqascore/promptcap-coco-vqa)\\', \\'if torch.cuda.is_available():\\', \\'  model.cuda()\\', \\'prompt = please describe this image according to the given question: what piece of clothing is this boy putting on?\\', \\'image = glove_boy.jpeg\\', \\'print(model.caption(prompt, image))\\'], \\'performance\\': {\\'dataset\\': {\\'coco\\': {\\'accuracy\\': \\'150 CIDEr\\'}, \\'OK-VQA\\': {\\'accuracy\\': \\'60.4%\\'}, \\'A-OKVQA\\': {\\'accuracy\\': \\'59.6%\\'}}}, \\'description\\': \\'PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 96, "text": " We need a tool to help us generate textual descriptions for images and videos related to our product.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'camenduru/text2-video-zero\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'camenduru/text2-video-zero\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 97, "text": " We need to build an AI-powered tool to assist visually impaired users in understanding their surroundings by answering questions about images.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Visual Question Answering\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Visual Question Answering\\', \\'api_name\\': \\'temp_vilt_vqa\\', \\'api_call\\': \"pipeline(\\'visual-question-answering\\', model=\\'Bingsu/temp_vilt_vqa\\', tokenizer=\\'Bingsu/temp_vilt_vqa\\')\", \\'api_arguments\\': {\\'model\\': \\'Bingsu/temp_vilt_vqa\\', \\'tokenizer\\': \\'Bingsu/temp_vilt_vqa\\'}, \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A visual question answering model for answering questions related to images using the Hugging Face Transformers library.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 98, "text": " I'm a nutritionist and want to help my clients by answering questions about their meals. They will send me an image of their food and ask me a question about it, like \\\"Is this vegan?\\\" or \\\"How many calories do you think it contains?\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'vision-encoder-decoder\\', \\'api_name\\': \\'naver-clova-ix/donut-base-finetuned-docvqa\\', \\'api_call\\': \"pipeline(\\'document-question-answering\\', model=\\'donut-base-finetuned-docvqa\\')\", \\'api_arguments\\': {\\'image\\': \\'path_to_image\\', \\'question\\': \\'your_question\\'}, \\'python_environment_requirements\\': \\'Transformers\\', \\'example_code\\': \"from transformers import pipeline\\\n\\\n# Initialize the pipeline\\\ndoc_qa = pipeline(\\'document-question-answering\\', model=\\'naver-clova-ix/donut-base-finetuned-docvqa\\')\\\n\\\n# Load an image and ask a question\\\nimage_path = \\'path_to_image\\'\\\nquestion = \\'your_question\\'\\\n\\\n# Get the answer\\\nanswer = doc_qa({\\'image\\': image_path, \\'question\\': question})\\\nprint(answer)\", \\'performance\\': {\\'dataset\\': \\'DocVQA\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 99, "text": " Our client is a legal firm that needs assistance in extracting specific information from a large number of legal documents. Automate the process of answering questions related to these documents.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Document Question Answering\\', \\'api_name\\': \\'CQI_Visual_Question_Awnser_PT_v0\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=LayoutLMForQuestionAnswering.from_pretrained(\\'microsoft/layoutlm-base-uncased\\'))\", \\'api_arguments\\': [\\'url\\', \\'question\\'], \\'python_environment_requirements\\': [\\'PIL\\', \\'pytesseract\\', \\'PyTorch\\', \\'transformers\\'], \\'example_code\\': [\"nlp(\\'https://templates.invoicehome.com/invoice-template-us-neat-750px.png\\', \\'What is the invoice number?\\')\", \"nlp(\\'https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\\', \\'What is the purchase amount?\\')\", \"nlp(\\'https://www.accountingcoach.com/wp-content/uploads/2013/10/income-statement-example@2x.png\\', \\'What are the 2020 net sales?\\')\"], \\'performance\\': {\\'dataset\\': [{\\'accuracy\\': 0.9943977}, {\\'accuracy\\': 0.9912159}, {\\'accuracy\\': 0.59147286}]}, \\'description\\': \\'A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 100, "text": " In a healthcare company, we are trying to create an automated system for answering patient-related questions based on their medical documents. We need a solution using NLP.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'deepset/roberta-base-squad2-covid\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=RobertaForQuestionAnswering.from_pretrained(\\'deepset/roberta-base-squad2-covid\\'), tokenizer=RobertaTokenizer.from_pretrained(\\'deepset/roberta-base-squad2-covid\\'))\", \\'api_arguments\\': {\\'model_name\\': \\'deepset/roberta-base-squad2-covid\\', \\'tokenizer\\': \\'deepset/roberta-base-squad2-covid\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': {\\'QA_input\\': {\\'question\\': \\'Why is model conversion important?\\', \\'context\\': \\'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.\\'}, \\'res\\': \\'nlp(QA_input)\\'}, \\'performance\\': {\\'dataset\\': \\'squad_v2\\', \\'accuracy\\': {\\'XVAL_EM\\': 0.17890995260663506, \\'XVAL_f1\\': 0.49925444207319924, \\'XVAL_top_3_recall\\': 0.8021327014218009}}, \\'description\\': \\'This model is a Roberta-based model fine-tuned on SQuAD-style CORD-19 annotations for the task of extractive question answering in the context of COVID-19. It can be used with the Hugging Face Transformers library for question answering tasks.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 101, "text": " Develop a program which can answer questions related to a scanned document.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Document Question Answering\\', \\'api_name\\': \\'CQI_Visual_Question_Awnser_PT_v0\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=LayoutLMForQuestionAnswering.from_pretrained(\\'microsoft/layoutlm-base-uncased\\'))\", \\'api_arguments\\': [\\'url\\', \\'question\\'], \\'python_environment_requirements\\': [\\'PIL\\', \\'pytesseract\\', \\'PyTorch\\', \\'transformers\\'], \\'example_code\\': [\"nlp(\\'https://templates.invoicehome.com/invoice-template-us-neat-750px.png\\', \\'What is the invoice number?\\')\", \"nlp(\\'https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\\', \\'What is the purchase amount?\\')\", \"nlp(\\'https://www.accountingcoach.com/wp-content/uploads/2013/10/income-statement-example@2x.png\\', \\'What are the 2020 net sales?\\')\"], \\'performance\\': {\\'dataset\\': [{\\'accuracy\\': 0.9943977}, {\\'accuracy\\': 0.9912159}, {\\'accuracy\\': 0.59147286}]}, \\'description\\': \\'A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 102, "text": " I have received a PDF document and a question. My task is to find the answer part in the document.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Document Question Answering\\', \\'api_name\\': \\'CQI_Visual_Question_Awnser_PT_v0\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=LayoutLMForQuestionAnswering.from_pretrained(\\'microsoft/layoutlm-base-uncased\\'))\", \\'api_arguments\\': [\\'url\\', \\'question\\'], \\'python_environment_requirements\\': [\\'PIL\\', \\'pytesseract\\', \\'PyTorch\\', \\'transformers\\'], \\'example_code\\': [\"nlp(\\'https://templates.invoicehome.com/invoice-template-us-neat-750px.png\\', \\'What is the invoice number?\\')\", \"nlp(\\'https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\\', \\'What is the purchase amount?\\')\", \"nlp(\\'https://www.accountingcoach.com/wp-content/uploads/2013/10/income-statement-example@2x.png\\', \\'What are the 2020 net sales?\\')\"], \\'performance\\': {\\'dataset\\': [{\\'accuracy\\': 0.9943977}, {\\'accuracy\\': 0.9912159}, {\\'accuracy\\': 0.59147286}]}, \\'description\\': \\'A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 103, "text": " An interior design firm builds a software to understand the depth of rooms captured in photographs for remodeling activities.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Denoising Diffusion Probabilistic Models (DDPM)\\', \\'api_name\\': \\'google/ddpm-bedroom-256\\', \\'api_call\\': \"DDPMPipeline.from_pretrained(\\'google/ddpm-bedroom-256\\')\", \\'api_arguments\\': \\'None\\', \\'python_environment_requirements\\': \\'diffusers\\', \\'example_code\\': \\'!pip install diffusers\\\nfrom diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline\\\nmodel_id = google/ddpm-bedroom-256\\\nddpm = DDPMPipeline.from_pretrained(model_id)\\\nimage = ddpm().images[0]\\\nimage.save(ddpm_generated_image.png)\\', \\'performance\\': {\\'dataset\\': \\'CIFAR10\\', \\'accuracy\\': {\\'Inception score\\': 9.46, \\'FID score\\': 3.17}}, \\'description\\': \\'We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 104, "text": " We are running an autonomous vehicle company and want to implement a depth estimation module for the real-time video feed captured by our camera.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Depth Estimation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Depth Estimation\\', \\'api_name\\': \\'glpn-kitti\\', \\'api_call\\': \"GLPNForDepthEstimation.from_pretrained(\\'vinvino02/glpn-kitti\\')\", \\'api_arguments\\': \\'images, return_tensors\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'from transformers import GLPNFeatureExtractor, GLPNForDepthEstimation\\\nimport torch\\\nimport numpy as np\\\nfrom PIL import Image\\\nimport requests\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\nfeature_extractor = GLPNFeatureExtractor.from_pretrained(vinvino02/glpn-kitti)\\\nmodel = GLPNForDepthEstimation.from_pretrained(vinvino02/glpn-kitti)\\\ninputs = feature_extractor(images=image, return_tensors=pt)\\\nwith torch.no_grad():\\\n outputs = model(**inputs)\\\n predicted_depth = outputs.predicted_depth\\\nprediction = torch.nn.functional.interpolate(\\\n predicted_depth.unsqueeze(1),\\\n size=image.size[::-1],\\\n mode=bicubic,\\\n align_corners=False,\\\n)\\\noutput = prediction.squeeze().cpu().numpy()\\\nformatted = (output * 255 / np.max(output)).astype(uint8)\\\ndepth = Image.fromarray(formatted)\\', \\'performance\\': {\\'dataset\\': \\'KITTI\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 105, "text": " Our team wants to create a new app for autonomous vehicles. For that, we need to estimate the depth of the field from images.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Depth Estimation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Depth Estimation\\', \\'api_name\\': \\'glpn-kitti\\', \\'api_call\\': \"GLPNForDepthEstimation.from_pretrained(\\'vinvino02/glpn-kitti\\')\", \\'api_arguments\\': \\'images, return_tensors\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'from transformers import GLPNFeatureExtractor, GLPNForDepthEstimation\\\nimport torch\\\nimport numpy as np\\\nfrom PIL import Image\\\nimport requests\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\nfeature_extractor = GLPNFeatureExtractor.from_pretrained(vinvino02/glpn-kitti)\\\nmodel = GLPNForDepthEstimation.from_pretrained(vinvino02/glpn-kitti)\\\ninputs = feature_extractor(images=image, return_tensors=pt)\\\nwith torch.no_grad():\\\n outputs = model(**inputs)\\\n predicted_depth = outputs.predicted_depth\\\nprediction = torch.nn.functional.interpolate(\\\n predicted_depth.unsqueeze(1),\\\n size=image.size[::-1],\\\n mode=bicubic,\\\n align_corners=False,\\\n)\\\noutput = prediction.squeeze().cpu().numpy()\\\nformatted = (output * 255 / np.max(output)).astype(uint8)\\\ndepth = Image.fromarray(formatted)\\', \\'performance\\': {\\'dataset\\': \\'KITTI\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 106, "text": " As a city planner, I need to measure the depth of spaces in a series of images taken from streets.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Depth Estimation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Depth Estimation\\', \\'api_name\\': \\'glpn-nyu-finetuned-diode\\', \\'api_call\\': \"pipeline(\\'depth-estimation\\', model=\\'sayakpaul/glpn-nyu-finetuned-diode\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'diode-subset\\', \\'accuracy\\': {\\'Loss\\': 0.4359, \\'Rmse\\': 0.4276}}, \\'description\\': \\'This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 107, "text": " In our online ecommerce platform, we want to build an AI app to automatically recognize the type of products. It should be able to identify common items like clothing, electronics, furniture, and more.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Classification\\', \\'api_name\\': \\'abhishek/autotrain-dog-vs-food\\', \\'api_call\\': \"pipeline(\\'image-classification\\', model=\\'abhishek/autotrain-dog-vs-food\\')\", \\'api_arguments\\': \\'image_path\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'sasha/dog-food\\', \\'accuracy\\': 0.998}, \\'description\\': \"A pre-trained model for classifying images as either dog or food using Hugging Face\\'s AutoTrain framework.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 108, "text": " We need to recognize the breed of dog in the given image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Classification\\', \\'api_name\\': \\'julien-c/hotdog-not-hotdog\\', \\'api_call\\': \"pipeline(\\'image-classification\\', model=\\'julien-c/hotdog-not-hotdog\\')\", \\'api_arguments\\': \\'image\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': 0.825}, \\'description\\': \\'A model that classifies images as hotdog or not hotdog.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 109, "text": " Develop a solution that can categorize an image of a cell phone, laptop, or smartwatch as one of these respective device types.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Classification\\', \\'api_name\\': \\'julien-c/hotdog-not-hotdog\\', \\'api_call\\': \"pipeline(\\'image-classification\\', model=\\'julien-c/hotdog-not-hotdog\\')\", \\'api_arguments\\': \\'image\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': 0.825}, \\'description\\': \\'A model that classifies images as hotdog or not hotdog.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 110, "text": " Build a system to help companies identify logos from a collection of images.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Zero-Shot Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Zero-Shot Image Classification\\', \\'api_name\\': \\'patrickjohncyh/fashion-clip\\', \\'api_call\\': \"CLIPModel.from_pretrained(\\'patrickjohncyh/fashion-clip\\')\", \\'api_arguments\\': {\\'image\\': \\'File\\', \\'class_names\\': \\'String (comma-separated)\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import CLIPProcessor, CLIPModel; model = CLIPModel.from_pretrained(\\'patrickjohncyh/fashion-clip\\'); processor = CLIPProcessor.from_pretrained(\\'patrickjohncyh/fashion-clip\\'); inputs = processor(text=\\'blue shoes\\', images=image, return_tensors=\\'pt\\', padding=True); logits_per_image = model(**inputs).logits_per_image; probs = logits_per_image.softmax(dim=-1).tolist()[0]\", \\'performance\\': {\\'dataset\\': [{\\'name\\': \\'FMNIST\\', \\'accuracy\\': 0.83}, {\\'name\\': \\'KAGL\\', \\'accuracy\\': 0.73}, {\\'name\\': \\'DEEP\\', \\'accuracy\\': 0.62}]}, \\'description\\': \\'FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 111, "text": " Develop a pipeline that detects objects present in an image using computer vision.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'microsoft/table-transformer-structure-recognition\\', \\'api_call\\': \"pipeline(\\'object-detection\\', model=\\'microsoft/table-transformer-structure-recognition\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'PubTables1M\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 112, "text": " Assit me to process and segment an image for further analysis.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Segmentation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Segmentation\\', \\'api_name\\': \\'keremberke/yolov8m-pcb-defect-segmentation\\', \\'api_call\\': \"YOLO(\\'keremberke/yolov8m-pcb-defect-segmentation\\')\", \\'api_arguments\\': {\\'image\\': \\'URL or local path to the image\\'}, \\'python_environment_requirements\\': [\\'ultralyticsplus==0.0.24\\', \\'ultralytics==8.0.23\\'], \\'example_code\\': [\\'from ultralyticsplus import YOLO, render_result\\', \"model = YOLO(\\'keremberke/yolov8m-pcb-defect-segmentation\\')\", \"model.overrides[\\'conf\\'] = 0.25\", \"model.overrides[\\'iou\\'] = 0.45\", \"model.overrides[\\'agnostic_nms\\'] = False\", \"model.overrides[\\'max_det\\'] = 1000\", \"image = \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'\", \\'results = model.predict(image)\\', \\'print(results[0].boxes)\\', \\'print(results[0].masks)\\', \\'render = render_result(model=model, image=image, result=results[0])\\', \\'render.show()\\'], \\'performance\\': {\\'dataset\\': \\'pcb-defect-segmentation\\', \\'accuracy\\': {\\'mAP@0.5(box)\\': 0.568, \\'mAP@0.5(mask)\\': 0.557}}, \\'description\\': \\'A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 113, "text": " We need to analyze satellite images to categorize the types of land use. For this purpose, I need to segment the images and identify different objects.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Segmentation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Segmentation\\', \\'api_name\\': \\'keremberke/yolov8s-building-segmentation\\', \\'api_call\\': \"YOLO(\\'keremberke/yolov8s-building-segmentation\\')\", \\'api_arguments\\': [\\'conf\\', \\'iou\\', \\'agnostic_nms\\', \\'max_det\\', \\'image\\'], \\'python_environment_requirements\\': [\\'ultralyticsplus==0.0.21\\'], \\'example_code\\': [\\'from ultralyticsplus import YOLO, render_result\\', \"model = YOLO(\\'keremberke/yolov8s-building-segmentation\\')\", \"model.overrides[\\'conf\\'] = 0.25\", \"model.overrides[\\'iou\\'] = 0.45\", \"model.overrides[\\'agnostic_nms\\'] = False\", \"model.overrides[\\'max_det\\'] = 1000\", \"image = \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'\", \\'results = model.predict(image)\\', \\'print(results[0].boxes)\\', \\'print(results[0].masks)\\', \\'render = render_result(model=model, image=image, result=results[0])\\', \\'render.show()\\'], \\'performance\\': {\\'dataset\\': \\'satellite-building-segmentation\\', \\'accuracy\\': {\\'mAP@0.5(box)\\': 0.661, \\'mAP@0.5(mask)\\': 0.651}}, \\'description\\': \\'A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 114, "text": " We are a city planning department and want to evaluate the city layout. Analyze the image we provide to segment and understand the various urban elements.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Segmentation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Semantic Segmentation\\', \\'api_name\\': \\'nvidia/segformer-b2-finetuned-cityscapes-1024-1024\\', \\'api_call\\': \"SegformerForSemanticSegmentation.from_pretrained(\\'nvidia/segformer-b2-finetuned-cityscapes-1024-1024\\')\", \\'api_arguments\\': {\\'images\\': \\'image\\', \\'return_tensors\\': \\'pt\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'latest\\', \\'PIL\\': \\'latest\\', \\'requests\\': \\'latest\\'}, \\'example_code\\': \"from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation\\\nfrom PIL import Image\\\nimport requests\\\nfeature_extractor = SegformerFeatureExtractor.from_pretrained(\\'nvidia/segformer-b2-finetuned-cityscapes-1024-1024\\')\\\nmodel = SegformerForSemanticSegmentation.from_pretrained(\\'nvidia/segformer-b2-finetuned-cityscapes-1024-1024\\')\\\nurl = \\'http://images.cocodataset.org/val2017/000000039769.jpg\\'\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\ninputs = feature_extractor(images=image, return_tensors=\\'pt\\')\\\noutputs = model(**inputs)\\\nlogits = outputs.logits\", \\'performance\\': {\\'dataset\\': \\'Cityscapes\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 115, "text": " My company develops drones for agriculture purposes, and we need a model to segment aerial images accurately.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Segmentation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'clipseg-rd64-refined\\', \\'api_call\\': \"pipeline(\\'image-segmentation\\', model=\\'CIDAS/clipseg-rd64-refined\\')\", \\'api_arguments\\': {\\'model\\': \\'CIDAS/clipseg-rd64-refined\\'}, \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by Lüddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 116, "text": " I want to generate images from text descriptions and use the scribble images as control inputs for my project.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image-to-Image\\', \\'framework\\': \\'Diffusers\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'lllyasviel/control_v11p_sd15_scribble\\', \\'api_call\\': \"ControlNetModel.from_pretrained(\\'lllyasviel/control_v11p_sd15_scribble\\')\", \\'api_arguments\\': {\\'checkpoint\\': \\'lllyasviel/control_v11p_sd15_scribble\\', \\'torch_dtype\\': \\'torch.float16\\'}, \\'python_environment_requirements\\': [\\'diffusers\\', \\'transformers\\', \\'accelerate\\', \\'controlnet_aux==0.3.0\\'], \\'example_code\\': \"import torch\\\nimport os\\\nfrom huggingface_hub import HfApi\\\nfrom pathlib import Path\\\nfrom diffusers.utils import load_image\\\nfrom PIL import Image\\\nimport numpy as np\\\nfrom controlnet_aux import PidiNetDetector, HEDdetector\\\nfrom diffusers import (\\\n ControlNetModel,\\\n StableDiffusionControlNetPipeline,\\\n UniPCMultistepScheduler,\\\n)\\\ncheckpoint = lllyasviel/control_v11p_sd15_scribble\\\nimage = load_image(\\\n https://huggingface.co/lllyasviel/control_v11p_sd15_scribble/resolve/main/images/input.png\\\n)\\\nprompt = royal chamber with fancy bed\\\nprocessor = HEDdetector.from_pretrained(\\'lllyasviel/Annotators\\')\\\ncontrol_image = processor(image, scribble=True)\\\ncontrol_image.save(./images/control.png)\\\ncontrolnet = ControlNetModel.from_pretrained(checkpoint, torch_dtype=torch.float16)\\\npipe = StableDiffusionControlNetPipeline.from_pretrained(\\\n runwayml/stable-diffusion-v1-5, controlnet=controlnet, torch_dtype=torch.float16\\\n)\\\npipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\\\npipe.enable_model_cpu_offload()\\\ngenerator = torch.manual_seed(0)\\\nimage = pipe(prompt, num_inference_steps=30, generator=generator, image=control_image).images[0]\\\nimage.save(\\'images/image_out.png\\')\", \\'performance\\': {\\'dataset\\': \\'Stable Diffusion v1-5\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 118, "text": " We want to recommend workouts to our users, based on the type of sports they enjoy. Help us classify sports videos.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'MCG-NJU/videomae-base-short-finetuned-kinetics\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-base-short-finetuned-kinetics\\')\", \\'api_arguments\\': [\\'video\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import VideoMAEImageProcessor, VideoMAEForVideoClassification\\\nimport numpy as np\\\nimport torch\\\nvideo = list(np.random.randn(16, 3, 224, 224))\\\nprocessor = VideoMAEImageProcessor.from_pretrained(\\'MCG-NJU/videomae-base-short-finetuned-kinetics\\')\\\nmodel = VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-base-short-finetuned-kinetics\\')\\\ninputs = processor(video, return_tensors=\\'pt\\')\\\nwith torch.no_grad():\\\n outputs = model(**inputs)\\\n logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(\\'Predicted class:\\', model.config.id2label[predicted_class_idx])\", \\'performance\\': {\\'dataset\\': \\'Kinetics-400\\', \\'accuracy\\': {\\'top-1\\': 79.4, \\'top-5\\': 94.1}}, \\'description\\': \\'VideoMAE model pre-trained for 800 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 119, "text": " We need to classify videos showing different actions for our new video moderation system.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'MCG-NJU/videomae-base-short-finetuned-kinetics\\', \\'api_call\\': \"VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-base-short-finetuned-kinetics\\')\", \\'api_arguments\\': [\\'video\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import VideoMAEImageProcessor, VideoMAEForVideoClassification\\\nimport numpy as np\\\nimport torch\\\nvideo = list(np.random.randn(16, 3, 224, 224))\\\nprocessor = VideoMAEImageProcessor.from_pretrained(\\'MCG-NJU/videomae-base-short-finetuned-kinetics\\')\\\nmodel = VideoMAEForVideoClassification.from_pretrained(\\'MCG-NJU/videomae-base-short-finetuned-kinetics\\')\\\ninputs = processor(video, return_tensors=\\'pt\\')\\\nwith torch.no_grad():\\\n outputs = model(**inputs)\\\n logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(\\'Predicted class:\\', model.config.id2label[predicted_class_idx])\", \\'performance\\': {\\'dataset\\': \\'Kinetics-400\\', \\'accuracy\\': {\\'top-1\\': 79.4, \\'top-5\\': 94.1}}, \\'description\\': \\'VideoMAE model pre-trained for 800 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 120, "text": " I need the AI to tell if an image is of a cat or a dog, regardless of its breed or species.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Classification\\', \\'api_name\\': \\'abhishek/autotrain-dog-vs-food\\', \\'api_call\\': \"pipeline(\\'image-classification\\', model=\\'abhishek/autotrain-dog-vs-food\\')\", \\'api_arguments\\': \\'image_path\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'sasha/dog-food\\', \\'accuracy\\': 0.998}, \\'description\\': \"A pre-trained model for classifying images as either dog or food using Hugging Face\\'s AutoTrain framework.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 121, "text": " We have a set of pictures for pets (dogs and cats). We need to offer an AI-based solution to classify the pictures given the pet name.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Classification\\', \\'api_name\\': \\'abhishek/autotrain-dog-vs-food\\', \\'api_call\\': \"pipeline(\\'image-classification\\', model=\\'abhishek/autotrain-dog-vs-food\\')\", \\'api_arguments\\': \\'image_path\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'sasha/dog-food\\', \\'accuracy\\': 0.998}, \\'description\\': \"A pre-trained model for classifying images as either dog or food using Hugging Face\\'s AutoTrain framework.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 122, "text": " Our startup team is now building an app for diagnosing plant diseases based on images. We need to get the diagnosis for different types of plant issues.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Classification\\', \\'api_name\\': \\'martinezomg/vit-base-patch16-224-diabetic-retinopathy\\', \\'api_call\\': \"pipeline(\\'image-classification\\', \\'martinezomg/vit-base-patch16-224-diabetic-retinopathy\\')\", \\'api_arguments\\': {\\'model_name\\': \\'martinezomg/vit-base-patch16-224-diabetic-retinopathy\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'4.28.1\\', \\'pytorch\\': \\'2.0.0+cu118\\', \\'datasets\\': \\'2.11.0\\', \\'tokenizers\\': \\'0.13.3\\'}, \\'example_code\\': \"from transformers import pipeline\\\nimage_classifier = pipeline(\\'image-classification\\', \\'martinezomg/vit-base-patch16-224-diabetic-retinopathy\\')\\\nresult = image_classifier(\\'path/to/image.jpg\\')\", \\'performance\\': {\\'dataset\\': \\'None\\', \\'accuracy\\': 0.7744}, \\'description\\': \\'This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 123, "text": " We need to analyze customer reviews and find out how well our new product is doing in the market.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentiment Analysis\\', \\'api_name\\': \\'michellejieli/NSFW_text_classifier\\', \\'api_call\\': \"pipeline(\\'sentiment-analysis\\', model=\\'michellejieli/NSFW_text_classification\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'classifier(I see you’ve set aside this special time to humiliate yourself in public.)\\', \\'performance\\': {\\'dataset\\': \\'Reddit posts\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \\'DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 124, "text": " A new tutoring company is founded, and they want a tutoring AI. To do so, they need help in creating better explanations for a chemistry concept.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Generation\\', \\'api_name\\': \\'mywateriswet/ShuanBot\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'mywateriswet/ShuanBot\\')\", \\'api_arguments\\': \\'message\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"response = chatbot(\\'What is your name?\\')\", \\'performance\\': {\\'dataset\\': \\'N/A\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 125, "text": " Create a function that can determine if a given text is a question or a statement.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Classification\\', \\'api_name\\': \\'shahrukhx01/question-vs-statement-classifier\\', \\'api_call\\': \"AutoModelForSequenceClassification.from_pretrained(\\'shahrukhx01/question-vs-statement-classifier\\')\", \\'api_arguments\\': {\\'tokenizer\\': \\'AutoTokenizer.from_pretrained(shahrukhx01/question-vs-statement-classifier)\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'from transformers import AutoTokenizer, AutoModelForSequenceClassification\\'}, \\'example_code\\': \\'tokenizer = AutoTokenizer.from_pretrained(shahrukhx01/question-vs-statement-classifier)\\\nmodel = AutoModelForSequenceClassification.from_pretrained(shahrukhx01/question-vs-statement-classifier)\\', \\'performance\\': {\\'dataset\\': \\'Haystack\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 126, "text": " I want to create a system that can answer questions by sorting out possible answers to a question.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'distilbert-base-uncased-distilled-squad\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'distilbert-base-uncased-distilled-squad\\')\", \\'api_arguments\\': [\\'question\\', \\'context\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\nquestion_answerer = pipeline(question-answering, model=\\'distilbert-base-uncased-distilled-squad\\')\\\ncontext = r\\\n... Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\\\n... question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\\\n... a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\\\n... \\\nresult = question_answerer(question=What is a good example of a question answering dataset?, context=context)\\\nprint(\\\n... fAnswer: \\'{result[\\'answer\\']}\\', score: {round(result[\\'score\\'], 4)}, start: {result[\\'start\\']}, end: {result[\\'end\\']}\\\n...)\", \\'performance\\': {\\'dataset\\': \\'SQuAD v1.1\\', \\'accuracy\\': \\'86.9 F1 score\\'}, \\'description\\': \"DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT\\'s performances as measured on the GLUE language understanding benchmark.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 127, "text": " We have a news article and we need to extract all the entities like the names of people, organizations, and locations.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Token Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Named Entity Recognition\\', \\'api_name\\': \\'dslim/bert-base-NER-uncased\\', \\'api_call\\': \"pipeline(\\'ner\\', model=\\'dslim/bert-base-NER-uncased\\')\", \\'api_arguments\\': {}, \\'python_environment_requirements\\': {\\'transformers\\': \\'>=4.0.0\\'}, \\'example_code\\': \"nlp(\\'My name is John and I live in New York.\\')\", \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 128, "text": " We are purchasing a CRM system to keep track of our customers and their organizations. We want to extract useful entities from customer emails automatically.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Generation\\', \\'api_name\\': \\'mywateriswet/ShuanBot\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'mywateriswet/ShuanBot\\')\", \\'api_arguments\\': \\'message\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"response = chatbot(\\'What is your name?\\')\", \\'performance\\': {\\'dataset\\': \\'N/A\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 129, "text": " As a researcher, I am trying to find an answer to my question in a table containing information about animals and their characteristics.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'google/tapas-small-finetuned-sqa\\', \\'api_call\\': \"pipeline(\\'table-question-answering\\', model=\\'google/tapas-small-finetuned-sqa\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'msr_sqa\\', \\'accuracy\\': 0.6155}, \\'description\\': \\'TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 130, "text": " A teacher wants to create a quiz for her students. We are now working on the questions and answers for the quiz that be arranged in a table format.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'google/tapas-small-finetuned-sqa\\', \\'api_call\\': \"pipeline(\\'table-question-answering\\', model=\\'google/tapas-small-finetuned-sqa\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'msr_sqa\\', \\'accuracy\\': 0.6155}, \\'description\\': \\'TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 131, "text": " I work for a financial company that stores all of its data in tables. We need a way to extract key information efficiently by asking natural language questions.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'google/tapas-small-finetuned-sqa\\', \\'api_call\\': \"pipeline(\\'table-question-answering\\', model=\\'google/tapas-small-finetuned-sqa\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'msr_sqa\\', \\'accuracy\\': 0.6155}, \\'description\\': \\'TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 132, "text": " We have a dataset related to coffee and tea prices. We need to answer a question on who sells hot chocolate and their prices.\n###Input: {\\\"table\\\": [[\\\"Shop\\\", \\\"Drink\\\", \\\"Price\\\"], [\\\"Cafe A\\\", \\\"Coffee\\\", \\\"3.00\\\"], [\\\"Cafe B\\\", \\\"Tea\\\", \\\"2.50\\\"], [\\\"Cafe C\\\", \\\"Hot Chocolate\\\", \\\"4.50\\\"], [\\\"Cafe D\\\", \\\"Hot Chocolate\\\", \\\"3.75\\\"]], \\\"queries\\\": [\\\"Which shops sell hot chocolate and what are their prices?\\\"]}\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Table Question Answering\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Table Question Answering\\', \\'api_name\\': \\'google/tapas-small-finetuned-sqa\\', \\'api_call\\': \"pipeline(\\'table-question-answering\\', model=\\'google/tapas-small-finetuned-sqa\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'msr_sqa\\', \\'accuracy\\': 0.6155}, \\'description\\': \\'TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table).\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 133, "text": " A company is running a survey and they want to know how many respondents have given a specific answer for each question of the survey.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Document Question Answering\\', \\'api_name\\': \\'CQI_Visual_Question_Awnser_PT_v0\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=LayoutLMForQuestionAnswering.from_pretrained(\\'microsoft/layoutlm-base-uncased\\'))\", \\'api_arguments\\': [\\'url\\', \\'question\\'], \\'python_environment_requirements\\': [\\'PIL\\', \\'pytesseract\\', \\'PyTorch\\', \\'transformers\\'], \\'example_code\\': [\"nlp(\\'https://templates.invoicehome.com/invoice-template-us-neat-750px.png\\', \\'What is the invoice number?\\')\", \"nlp(\\'https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\\', \\'What is the purchase amount?\\')\", \"nlp(\\'https://www.accountingcoach.com/wp-content/uploads/2013/10/income-statement-example@2x.png\\', \\'What are the 2020 net sales?\\')\"], \\'performance\\': {\\'dataset\\': [{\\'accuracy\\': 0.9943977}, {\\'accuracy\\': 0.9912159}, {\\'accuracy\\': 0.59147286}]}, \\'description\\': \\'A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 134, "text": " Extract information about a non-compete clause from a legal document with a context related to data protection.\n###Input: \\\"The data protection provisions set forth in this agreement shall be in effect for a period of 2 years after the termination of services. The non-compete clause states that the service provider is prohibited from providing similar services to any competitor within a 50-mile radius and during the 1-year period following termination of services.\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Translation\\', \\'framework\\': \\'PyTorch Transformers\\', \\'functionality\\': \\'text2text-generation\\', \\'api_name\\': \\'facebook/nllb-200-distilled-600M\\', \\'api_call\\': \"pipeline(\\'translation_xx_to_yy\\', model=\\'facebook/nllb-200-distilled-600M\\')\", \\'api_arguments\\': [\\'model\\', \\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\', \\'torch\\'], \\'example_code\\': \"from transformers import pipeline; translator = pipeline(\\'translation_xx_to_yy\\', model=\\'facebook/nllb-200-distilled-600M\\'); translator(\\'Hello World\\')\", \\'performance\\': {\\'dataset\\': \\'Flores-200\\', \\'accuracy\\': \\'BLEU, spBLEU, chrF++\\'}, \\'description\\': \\'NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 135, "text": " Tell me the day of the game when it was played given the following context: \\\"The game was played on February 7, 2016 at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\\\"\n###Input: {'context': \\\"The game was played on February 7, 2016 at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\\\", 'question': \\\"What day was the game played on?\\\"}\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Question Answering\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Question Answering\\', \\'api_name\\': \\'csarron/bert-base-uncased-squad-v1\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=\\'csarron/bert-base-uncased-squad-v1\\', tokenizer=\\'csarron/bert-base-uncased-squad-v1\\')\", \\'api_arguments\\': {\\'model\\': \\'csarron/bert-base-uncased-squad-v1\\', \\'tokenizer\\': \\'csarron/bert-base-uncased-squad-v1\\'}, \\'python_environment_requirements\\': \\'Python 3.7.5\\', \\'example_code\\': \"from transformers import pipeline\\\nqa_pipeline = pipeline(\\\n question-answering,\\\n model=csarron/bert-base-uncased-squad-v1,\\\n tokenizer=csarron/bert-base-uncased-squad-v1\\\n)\\\npredictions = qa_pipeline({\\\n \\'context\\': The game was played on February 7, 2016 at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California.,\\\n \\'question\\': What day was the game played on?\\\n})\\\nprint(predictions)\", \\'performance\\': {\\'dataset\\': \\'SQuAD1.1\\', \\'accuracy\\': {\\'EM\\': 80.9, \\'F1\\': 88.2}}, \\'description\\': \\'BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 136, "text": " We need to identify the relationship between two sentences whether they are contradictory, entail each other, or neutral.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Sentence Similarity\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Sentence Embeddings\\', \\'api_name\\': \\'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\\', \\'api_call\\': \"SentenceTransformer(\\'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\\')\", \\'api_arguments\\': [\\'sentences\\'], \\'python_environment_requirements\\': \\'pip install -U sentence-transformers\\', \\'example_code\\': \"from sentence_transformers import SentenceTransformer\\\nsentences = [This is an example sentence, Each sentence is converted]\\\nmodel = SentenceTransformer(\\'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\\')\\\nembeddings = model.encode(sentences)\\\nprint(embeddings)\", \\'performance\\': {\\'dataset\\': \\'https://seb.sbert.net\\', \\'accuracy\\': \\'Automated evaluation\\'}, \\'description\\': \\'This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 137, "text": " I am a climate change agency, looking to have my research summaries translated into Chinese for international audiences.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Summarization\\', \\'api_name\\': \\'Randeng-Pegasus-238M-Summary-Chinese\\', \\'api_call\\': \"PegasusForConditionalGeneration.from_pretrained(\\'IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\\')\", \\'api_arguments\\': {\\'text\\': \\'string\\', \\'max_length\\': \\'integer\\'}, \\'python_environment_requirements\\': [\\'transformers\\', \\'tokenizers_pegasus.py\\', \\'data_utils.py\\'], \\'example_code\\': \"from transformers import PegasusForConditionalGeneration\\\nfrom tokenizers_pegasus import PegasusTokenizer\\\nmodel = PegasusForConditionalGeneration.from_pretrained(\\'IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\\')\\\ntokenizer = PegasusTokenizer.from_pretrained(\\'IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\\')\\\ntext = \\'1\\'\\\ninputs = tokenizer(text, max_length=1024, return_tensors=\\'pt\\')\\\nsummary_ids = model.generate(inputs[\\'input_ids\\'])\\\ntokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\", \\'performance\\': {\\'dataset\\': \\'LCSTS\\', \\'accuracy\\': {\\'rouge-1\\': 43.46, \\'rouge-2\\': 29.59, \\'rouge-L\\': 39.76}}, \\'description\\': \\'Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 138, "text": " We are building an app to summarize long articles for users. We need a solution to create a condensed summary of the given text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Summarization\\', \\'api_name\\': \\'pszemraj/long-t5-tglobal-base-16384-book-summary\\', \\'api_call\\': \"T5ForConditionalGeneration.from_pretrained(\\'pszemraj/long-t5-tglobal-base-16384-book-summary\\')\", \\'api_arguments\\': [\\'long_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\nimport torch\\\nsummarizer = pipeline(\\\n summarization,\\\n pszemraj/long-t5-tglobal-base-16384-book-summary,\\\n device=0 if torch.cuda.is_available() else -1,\\\n)\\\nlong_text = Here is a lot of text I don\\'t want to read. Replace me\\\nresult = summarizer(long_text)\\\nprint(result[0][summary_text])\", \\'performance\\': {\\'dataset\\': \\'kmfoda/booksum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.408, \\'ROUGE-2\\': 6.065, \\'ROUGE-L\\': 16.721, \\'ROUGE-LSUM\\': 33.34}}, \\'description\\': \\'A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 139, "text": " A news agency wants to summaries their international news articles daily.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Summarization\\', \\'api_name\\': \\'it5-base-news-summarization\\', \\'api_call\\': \"pipeline(\\'summarization\\', model=\\'it5/it5-base-news-summarization\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'newsum(Dal 31 maggio è infine partita la piattaforma ITsART, a più di un anno da quando – durante il primo lockdown – il ministro della Cultura Dario Franceschini ne aveva parlato come di «una sorta di Netflix della cultura», pensata per «offrire a tutto il mondo la cultura italiana a pagamento». È presto per dare giudizi definitivi sulla piattaforma, e di certo sarà difficile farlo anche più avanti senza numeri precisi. Al momento, l’unica cosa che si può fare è guardare com’è fatto il sito, contare quanti contenuti ci sono (circa 700 “titoli”, tra film, documentari, spettacoli teatrali e musicali e altri eventi) e provare a dare un giudizio sul loro valore e sulla loro varietà. Intanto, una cosa notata da più parti è che diversi contenuti di ITsART sono a pagamento sulla piattaforma sebbene altrove, per esempio su RaiPlay, siano invece disponibili gratuitamente.)\\', \\'performance\\': {\\'dataset\\': \\'NewsSum-IT\\', \\'accuracy\\': {\\'Rouge1\\': 0.339, \\'Rouge2\\': 0.16, \\'RougeL\\': 0.263}}, \\'description\\': \\'IT5 Base model fine-tuned on news summarization on the Fanpage and Il Post corpora for Italian Language Understanding and Generation.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 140, "text": " Design a smart home system that can have conversations with the user for controlling the home appliances.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'hyunwoongko/blenderbot-9B\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'hyunwoongko/blenderbot-9B\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'Input a message to start chatting with hyunwoongko/blenderbot-9B.\\', \\'performance\\': {\\'dataset\\': \\'blended_skill_talk\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 141, "text": " An educational publishing company is developing a language comprehension program for elementary school students. They want a system that can generate a short story based on a given prompt.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Paraphrase-based utterance augmentation\\', \\'api_name\\': \\'prithivida/parrot_fluency_model\\', \\'api_call\\': \"pipeline(\\'text-classification\\', model=\\'prithivida/parrot_fluency_model\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"parrot(\\'your input text\\')\", \\'performance\\': {\\'dataset\\': \\'N/A\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 142, "text": " Can you initiate a conversation with an AI model that plays the role of a friend who just got back from a conference?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Conversational\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Text Generation\\', \\'api_name\\': \\'mywateriswet/ShuanBot\\', \\'api_call\\': \"pipeline(\\'conversational\\', model=\\'mywateriswet/ShuanBot\\')\", \\'api_arguments\\': \\'message\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"response = chatbot(\\'What is your name?\\')\", \\'performance\\': {\\'dataset\\': \\'N/A\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 143, "text": " As a software developer, I want a program that can automatically generate code snippets for me based on natural language descriptions.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Program Synthesis\\', \\'api_name\\': \\'Salesforce/codegen-350M-multi\\', \\'api_call\\': \"AutoTokenizer.from_pretrained(\\'Salesforce/codegen-350M-multi\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'from transformers import AutoTokenizer, AutoModelForCausalLM\\\ntokenizer = AutoTokenizer.from_pretrained(Salesforce/codegen-350M-multi)\\\nmodel = AutoModelForCausalLM.from_pretrained(Salesforce/codegen-350M-multi)\\\ntext = def hello_world():\\\ninput_ids = tokenizer(text, return_tensors=pt).input_ids\\\ngenerated_ids = model.generate(input_ids, max_length=128)\\\nprint(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\\', \\'performance\\': {\\'dataset\\': \\'HumanEval and MTPB\\', \\'accuracy\\': \\'Refer to the paper for accuracy details\\'}, \\'description\\': \\'CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 144, "text": " Provide a short summary of an article about cryptocurrency investment risks.\n###Input: Cryptocurrencies have become exceedingly popular among investors seeking higher returns and diversification in their portfolios. However, investing in these digital currencies carries several inherent risks. Market volatility is a major factor \\u2013 cryptocurrencies can experience wild price swings, sometimes even within hours or minutes. This high volatility makes it difficult to predict the future value of the investments and can result in significant losses. Furthermore, the lack of regulatory oversight and security concerns may also lead to potential frauds and hacks, exposing investors to additional risk. Lastly, the environmental impact of mining digital currencies like Bitcoin has come under scrutiny, questioning the long-term sustainability of the cryptocurrency market.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Summarization\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Abstractive Russian Summarization\\', \\'api_name\\': \\'cointegrated/rut5-base-absum\\', \\'api_call\\': \"T5ForConditionalGeneration.from_pretrained(\\'cointegrated/rut5-base-absum\\')\", \\'api_arguments\\': {\\'n_words\\': \\'int\\', \\'compression\\': \\'float\\', \\'max_length\\': \\'int\\', \\'num_beams\\': \\'int\\', \\'do_sample\\': \\'bool\\', \\'repetition_penalty\\': \\'float\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'latest\\', \\'torch\\': \\'latest\\'}, \\'example_code\\': \"import torch\\\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\\\nMODEL_NAME = \\'cointegrated/rut5-base-absum\\'\\\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\\\ntokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\\\nmodel.cuda();\\\nmodel.eval();\\\ndef summarize(\\\n text, n_words=None, compression=None,\\\n max_length=1000, num_beams=3, do_sample=False, repetition_penalty=10.0, \\\n <strong>kwargs\\\n):\\\n \\\n Summarize the text\\\n The following parameters are mutually exclusive:\\\n - n_words (int) is an approximate number of words to generate.\\\n - compression (float) is an approximate length ratio of summary and original text.\\\n \\\n if n_words:\\\n text = \\'[{}] \\'.format(n_words) + text\\\n elif compression:\\\n text = \\'[{0:.1g}] \\'.format(compression) + text\\\n x = tokenizer(text, return_tensors=\\'pt\\', padding=True).to(model.device)\\\n with torch.inference_mode():\\\n out = model.generate(\\\n </strong>x, \\\n max_length=max_length, num_beams=num_beams, \\\n do_sample=do_sample, repetition_penalty=repetition_penalty, \\\n **kwargs\\\n )\\\n return tokenizer.decode(out[0], skip_special_tokens=True)\", \\'performance\\': {\\'dataset\\': [\\'csebuetnlp/xlsum\\', \\'IlyaGusev/gazeta\\', \\'mlsum\\'], \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 145, "text": " You have just met a person that speaks French. As a hotel manager, you need to tell them, \\\"Welcome to our hotel, we hope you enjoy your stay.\\\" in French.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Translation\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Translation\\', \\'api_name\\': \\'Helsinki-NLP/opus-mt-en-fr\\', \\'api_call\\': \"translate(\\'input_text\\', model=\\'Helsinki-NLP/opus-mt-en-fr\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'opus\\', \\'accuracy\\': {\\'BLEU\\': {\\'newsdiscussdev2015-enfr.en.fr\\': 33.8, \\'newsdiscusstest2015-enfr.en.fr\\': 40.0, \\'newssyscomb2009.en.fr\\': 29.8, \\'news-test2008.en.fr\\': 27.5, \\'newstest2009.en.fr\\': 29.4, \\'newstest2010.en.fr\\': 32.7, \\'newstest2011.en.fr\\': 34.3, \\'newstest2012.en.fr\\': 31.8, \\'newstest2013.en.fr\\': 33.2, \\'Tatoeba.en.fr\\': 50.5}}}, \\'description\\': \\'Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 146, "text": " They are planning a trip to Germany and want to spend some leisure time in the parks of Munich, find out how to ask a question about the location of parks in Munich in German.\n \n Use this API documentation for reference: [Document(page_content=\"{'domain': 'Natural Language Processing Token Classification', 'framework': 'Transformers', 'functionality': 'punctuation prediction', 'api_name': 'oliverguhr/fullstop-punctuation-multilang-large', 'api_call': 'PunctuationModel()', 'api_arguments': ['text'], 'python_environment_requirements': ['pip install deepmultilingualpunctuation'], 'example_code': 'from deepmultilingualpunctuation import PunctuationModel\\\nmodel = PunctuationModel()\\\ntext = My name is Clara and I live in Berkeley California Ist das eine Frage Frau Müller\\\nresult = model.restore_punctuation(text)\\\nprint(result)', 'performance': {'dataset': 'wmt/europarl', 'EN_accuracy': 0.775, 'DE_accuracy': 0.814, 'FR_accuracy': 0.782, 'IT_accuracy': 0.762}, 'description': 'This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :.'}\", metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 147, "text": " We are a company offering speech to text services. We need to summarize the conversion and make it open-ended question.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Summarization\\', \\'api_name\\': \\'pszemraj/long-t5-tglobal-base-16384-book-summary\\', \\'api_call\\': \"T5ForConditionalGeneration.from_pretrained(\\'pszemraj/long-t5-tglobal-base-16384-book-summary\\')\", \\'api_arguments\\': [\\'long_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\nimport torch\\\nsummarizer = pipeline(\\\n summarization,\\\n pszemraj/long-t5-tglobal-base-16384-book-summary,\\\n device=0 if torch.cuda.is_available() else -1,\\\n)\\\nlong_text = Here is a lot of text I don\\'t want to read. Replace me\\\nresult = summarizer(long_text)\\\nprint(result[0][summary_text])\", \\'performance\\': {\\'dataset\\': \\'kmfoda/booksum\\', \\'accuracy\\': {\\'ROUGE-1\\': 36.408, \\'ROUGE-2\\': 6.065, \\'ROUGE-L\\': 16.721, \\'ROUGE-LSUM\\': 33.34}}, \\'description\\': \\'A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 148, "text": " To help me with my writing, I need an AI tool that can fill in the gaps for me when I get stuck. It should be able to complete phrases or sentences.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Paraphrasing\\', \\'api_name\\': \\'prithivida/parrot_paraphraser_on_T5\\', \\'api_call\\': \"Parrot(model_tag=\\'prithivida/parrot_paraphraser_on_T5\\', use_gpu=False)\", \\'api_arguments\\': [\\'input_phrase\\', \\'diversity_ranker\\', \\'do_diverse\\', \\'max_return_phrases\\', \\'max_length\\', \\'adequacy_threshold\\', \\'fluency_threshold\\'], \\'python_environment_requirements\\': [\\'torch\\', \\'transformers\\'], \\'example_code\\': \\'from parrot import Parrot\\\nimport torch\\\nimport warnings\\\nwarnings.filterwarnings(ignore)\\\n\\\nparrot = Parrot(model_tag=prithivida/parrot_paraphraser_on_T5, use_gpu=False)\\\nphrases = [Can you recommed some upscale restaurants in Newyork?,\\\n What are the famous places we should not miss in Russia?\\\n]\\\nfor phrase in phrases:\\\n print(-*100)\\\n print(Input_phrase: , phrase)\\\n print(-*100)\\\n para_phrases = parrot.augment(input_phrase=phrase)\\\n for para_phrase in para_phrases:\\\n  print(para_phrase)\\', \\'performance\\': {\\'dataset\\': \\'Not mentioned\\', \\'accuracy\\': \\'Not mentioned\\'}, \\'description\\': \\'Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 149, "text": " A writer needs help with generating the next word in the phrase \\\"The dog jumped over the\\\" __.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text2Text Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Paraphrasing\\', \\'api_name\\': \\'prithivida/parrot_paraphraser_on_T5\\', \\'api_call\\': \"Parrot(model_tag=\\'prithivida/parrot_paraphraser_on_T5\\', use_gpu=False)\", \\'api_arguments\\': [\\'input_phrase\\', \\'diversity_ranker\\', \\'do_diverse\\', \\'max_return_phrases\\', \\'max_length\\', \\'adequacy_threshold\\', \\'fluency_threshold\\'], \\'python_environment_requirements\\': [\\'torch\\', \\'transformers\\'], \\'example_code\\': \\'from parrot import Parrot\\\nimport torch\\\nimport warnings\\\nwarnings.filterwarnings(ignore)\\\n\\\nparrot = Parrot(model_tag=prithivida/parrot_paraphraser_on_T5, use_gpu=False)\\\nphrases = [Can you recommed some upscale restaurants in Newyork?,\\\n What are the famous places we should not miss in Russia?\\\n]\\\nfor phrase in phrases:\\\n print(-*100)\\\n print(Input_phrase: , phrase)\\\n print(-*100)\\\n para_phrases = parrot.augment(input_phrase=phrase)\\\n for para_phrase in para_phrases:\\\n  print(para_phrase)\\', \\'performance\\': {\\'dataset\\': \\'Not mentioned\\', \\'accuracy\\': \\'Not mentioned\\'}, \\'description\\': \\'Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 151, "text": " Help me find similarity scores for different restaurant reviews.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Sentence Similarity\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Sentence Transformers\\', \\'api_name\\': \\'nikcheerla/nooks-amd-detection-realtime\\', \\'api_call\\': \"SentenceTransformer(\\'nikcheerla/nooks-amd-detection-realtime\\')\", \\'api_arguments\\': [\\'sentences\\'], \\'python_environment_requirements\\': \\'pip install -U sentence-transformers\\', \\'example_code\\': \"from sentence_transformers import SentenceTransformer\\\nsentences = [This is an example sentence, Each sentence is converted]\\\nmodel = SentenceTransformer(\\'{MODEL_NAME}\\')\\\nembeddings = model.encode(sentences)\\\nprint(embeddings)\", \\'performance\\': {\\'dataset\\': \\'https://seb.sbert.net\\', \\'accuracy\\': \\'Automated evaluation\\'}, \\'description\\': \\'This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 152, "text": " Our company is building an automated assistance system for the visually impaired. We need a tool to convert text into spoken instructions.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Text-to-Speech\\', \\'framework\\': \\'ESPnet\\', \\'functionality\\': \\'Text-to-Speech\\', \\'api_name\\': \\'kan-bayashi_ljspeech_vits\\', \\'api_call\\': \"pipeline(\\'text-to-speech\\', model=\\'espnet/kan-bayashi_ljspeech_vits\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"from transformers import pipeline; tts = pipeline(\\'text-to-speech\\', model=\\'espnet/kan-bayashi_ljspeech_vits\\'); tts(\\'Hello World\\')\", \\'performance\\': {\\'dataset\\': \\'ljspeech\\', \\'accuracy\\': \\'Not mentioned\\'}, \\'description\\': \\'A Text-to-Speech model trained on the ljspeech dataset using the ESPnet toolkit. This model can be used to convert text input into synthesized speech.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 153, "text": " I would like to create an application where users may listen to translations of English sentences. I need a Text-to-Speech model to support this functionality.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Text-to-Speech\\', \\'framework\\': \\'ESPnet\\', \\'functionality\\': \\'Text-to-Speech\\', \\'api_name\\': \\'mio/Artoria\\', \\'api_call\\': \"pipeline(\\'text-to-speech\\', model=\\'mio/Artoria\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline; tts = pipeline(\\'text-to-speech\\', model=\\'mio/Artoria\\'); tts(\\'s\\')\", \\'performance\\': {\\'dataset\\': \\'fate\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 154, "text": " We are a language learning app platform. We need a text-to-speech tool to read a sentence in multiple languages for our users.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Text-to-Speech\\', \\'framework\\': \\'ESPnet\\', \\'functionality\\': \\'Text-to-Speech\\', \\'api_name\\': \\'SYSPIN/Marathi_Male_TTS\\', \\'api_call\\': \"api.load(\\'ESPnet/espnet_model_zoo:SYSPIN/Marathi_Male_TTS\\').\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'huggingface_hub\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A Marathi Male Text-to-Speech model using ESPnet framework.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 155, "text": " I need to create an audio output that translates the given text to speech for a French audiobook assistant.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Audio-to-Audio\\', \\'framework\\': \\'Fairseq\\', \\'functionality\\': \\'speech-to-speech-translation\\', \\'api_name\\': \\'facebook/textless_sm_en_fr\\', \\'api_call\\': \"load_model_ensemble_and_task_from_hf_hub(\\'facebook/textless_sm_en_fr\\')\", \\'api_arguments\\': [\\'input_file\\'], \\'python_environment_requirements\\': [\\'huggingface_hub\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 156, "text": " We are opening a platform where users can record their own podcast and host it on our platform, can you help us to convert the audio into text automatically?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Text-to-Speech\\', \\'framework\\': \\'ESPnet\\', \\'functionality\\': \\'Text-to-Speech\\', \\'api_name\\': \\'lakahaga/novel_reading_tts\\', \\'api_call\\': \"AutoModelForTTS.from_pretrained(\\'lakahaga/novel_reading_tts\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"inputs = processor(text, return_tensors=\\'pt\\'); generated_audio = model.generate(**inputs);\", \\'performance\\': {\\'dataset\\': \\'novelspeech\\', \\'accuracy\\': None}, \\'description\\': \\'This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 157, "text": " We are currently working on the development of a speech-to-text application for transcription purposes. Can you help generate the required transcription code?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'CTranslate2\\', \\'functionality\\': \\'Automatic Speech Recognition\\', \\'api_name\\': \\'guillaumekln/faster-whisper-large-v2\\', \\'api_call\\': \"WhisperModel(\\'large-v2\\')\", \\'api_arguments\\': [\\'audio.mp3\\'], \\'python_environment_requirements\\': [\\'faster_whisper\\'], \\'example_code\\': \\'from faster_whisper import WhisperModel\\\nmodel = WhisperModel(large-v2)\\\nsegments, info = model.transcribe(audio.mp3)\\\nfor segment in segments:\\\n print([%.2fs -&gt; %.2fs] %s % (segment.start, segment.end, segment.text))\\', \\'performance\\': {\\'dataset\\': \\'99 languages\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 158, "text": " We are building an app for tour guides to transcribe what they say during the tour. Then the transcript will be translated into sign language.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'CTranslate2\\', \\'functionality\\': \\'Automatic Speech Recognition\\', \\'api_name\\': \\'guillaumekln/faster-whisper-large-v2\\', \\'api_call\\': \"WhisperModel(\\'large-v2\\')\", \\'api_arguments\\': [\\'audio.mp3\\'], \\'python_environment_requirements\\': [\\'faster_whisper\\'], \\'example_code\\': \\'from faster_whisper import WhisperModel\\\nmodel = WhisperModel(large-v2)\\\nsegments, info = model.transcribe(audio.mp3)\\\nfor segment in segments:\\\n print([%.2fs -&gt; %.2fs] %s % (segment.start, segment.end, segment.text))\\', \\'performance\\': {\\'dataset\\': \\'99 languages\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 159, "text": " I am an English teacher. I have recently met a Hokkien speaker. I am looking to translate a conversational sentence from English to Hokkien to facilitate communication.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Translation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Translation\\', \\'api_name\\': \\'Helsinki-NLP/opus-mt-en-zh\\', \\'api_call\\': \"pipeline(\\'translation_en_to_zh\\', model=\\'Helsinki-NLP/opus-mt-en-zh\\')\", \\'api_arguments\\': [\\'text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"from transformers import pipeline\\\ntranslation = pipeline(\\'translation_en_to_zh\\', model=\\'Helsinki-NLP/opus-mt-en-zh\\')\\\ntranslated_text = translation(\\'Hello, world!\\')\", \\'performance\\': {\\'dataset\\': \\'Tatoeba-test.eng.zho\\', \\'accuracy\\': {\\'BLEU\\': 31.4, \\'chr-F\\': 0.268}}, \\'description\\': \"A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of \\'>>id<<\\' (id = valid target language ID).\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 160, "text": " Determine the keyword spoken in a recorded audio file.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'CTranslate2\\', \\'functionality\\': \\'Automatic Speech Recognition\\', \\'api_name\\': \\'guillaumekln/faster-whisper-large-v2\\', \\'api_call\\': \"WhisperModel(\\'large-v2\\')\", \\'api_arguments\\': [\\'audio.mp3\\'], \\'python_environment_requirements\\': [\\'faster_whisper\\'], \\'example_code\\': \\'from faster_whisper import WhisperModel\\\nmodel = WhisperModel(large-v2)\\\nsegments, info = model.transcribe(audio.mp3)\\\nfor segment in segments:\\\n print([%.2fs -&gt; %.2fs] %s % (segment.start, segment.end, segment.text))\\', \\'performance\\': {\\'dataset\\': \\'99 languages\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 161, "text": " Determine which speaker an audio segment belongs to using the provided audio file.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Voice Activity Detection\\', \\'framework\\': \\'pyannote.audio\\', \\'functionality\\': \\'Speaker diarization\\', \\'api_name\\': \\'johnislarry/cloned-pyannote-speaker-diarization-endpoint\\', \\'api_call\\': \"Pipeline.from_pretrained(\\'pyannote/speaker-diarization@2.1\\',use_auth_token=\\'ACCESS_TOKEN_GOES_HERE\\')\", \\'api_arguments\\': [\\'num_speakers\\', \\'min_speakers\\', \\'max_speakers\\', \\'segmentation_onset\\'], \\'python_environment_requirements\\': \\'pyannote.audio 2.0\\', \\'example_code\\': {\\'load_pipeline\\': \\'from pyannote.audio import Pipeline\\\npipeline = Pipeline.from_pretrained(pyannote/speaker-diarization@2022.07)\\', \\'apply_pipeline\\': \\'diarization = pipeline(audio.wav)\\', \\'save_output\\': \\'with open(audio.rttm, w) as rttm:\\\n  diarization.write_rttm(rttm)\\'}, \\'performance\\': {\\'dataset\\': [{\\'name\\': \\'AISHELL-4\\', \\'accuracy\\': {\\'DER%\\': 14.61, \\'FA%\\': 3.31, \\'Miss%\\': 4.35, \\'Conf%\\': 6.95}}, {\\'name\\': \\'AMI Mix-Headset only_words\\', \\'accuracy\\': {\\'DER%\\': 18.21, \\'FA%\\': 3.28, \\'Miss%\\': 11.07, \\'Conf%\\': 3.87}}, {\\'name\\': \\'AMI Array1-01 only_words\\', \\'accuracy\\': {\\'DER%\\': 29.0, \\'FA%\\': 2.71, \\'Miss%\\': 21.61, \\'Conf%\\': 4.68}}, {\\'name\\': \\'CALLHOME Part2\\', \\'accuracy\\': {\\'DER%\\': 30.24, \\'FA%\\': 3.71, \\'Miss%\\': 16.86, \\'Conf%\\': 9.66}}, {\\'name\\': \\'DIHARD 3 Full\\', \\'accuracy\\': {\\'DER%\\': 20.99, \\'FA%\\': 4.25, \\'Miss%\\': 10.74, \\'Conf%\\': 6.0}}, {\\'name\\': \\'REPERE Phase 2\\', \\'accuracy\\': {\\'DER%\\': 12.62, \\'FA%\\': 1.55, \\'Miss%\\': 3.3, \\'Conf%\\': 7.76}}, {\\'name\\': \\'VoxConverse v0.0.2\\', \\'accuracy\\': {\\'DER%\\': 12.76, \\'FA%\\': 3.45, \\'Miss%\\': 3.85, \\'Conf%\\': 5.46}}]}, \\'description\\': \\'This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 162, "text": " We have a database of customer voices and are trying to build a voice recognition product so we can recognize customer voices when they call. How should we process and classify?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Voice Activity Detection\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Voice Activity Detection\\', \\'api_name\\': \\'d4data/Indian-voice-cloning\\', \\'api_call\\': \"pipeline(\\'voice-activity-detection\\', model=\\'d4data/Indian-voice-cloning\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A model for detecting voice activity in Indian languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 163, "text": " We are developing a voice-controlled drone. Please identify the spoken command in the audio clip provided.\n###Input: \\\"audio_clip.wav\\\"\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Automatic Speech Recognition\\', \\'framework\\': \\'CTranslate2\\', \\'functionality\\': \\'Automatic Speech Recognition\\', \\'api_name\\': \\'guillaumekln/faster-whisper-large-v2\\', \\'api_call\\': \"WhisperModel(\\'large-v2\\')\", \\'api_arguments\\': [\\'audio.mp3\\'], \\'python_environment_requirements\\': [\\'faster_whisper\\'], \\'example_code\\': \\'from faster_whisper import WhisperModel\\\nmodel = WhisperModel(large-v2)\\\nsegments, info = model.transcribe(audio.mp3)\\\nfor segment in segments:\\\n print([%.2fs -&gt; %.2fs] %s % (segment.start, segment.end, segment.text))\\', \\'performance\\': {\\'dataset\\': \\'99 languages\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 164, "text": " Make a summary video for our last team meeting. The audio from the video must identify who is speaking and when.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'chavinlo/TempoFunk\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'chavinlo/TempoFunk\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 165, "text": " I want to estimate the price of a house based on its features using this API. Please provide the code.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Joblib\\', \\'functionality\\': \\'Single Column Regression\\', \\'api_name\\': \\'jwan2021/autotrain-us-housing-prices-1771761512\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\', \\'json\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'jwan2021/autotrain-data-us-housing-prices\\', \\'accuracy\\': {\\'Loss\\': 122809.223, \\'R2\\': 0.884, \\'MSE\\': 15082105200.447, \\'MAE\\': 95586.887, \\'RMSLE\\': 0.13}}, \\'description\\': \\'A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 166, "text": " Our company wants to predict housing prices in the US based on given features. Help us use the trained model to predict the prices.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Joblib\\', \\'functionality\\': \\'Single Column Regression\\', \\'api_name\\': \\'jwan2021/autotrain-us-housing-prices-1771761512\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\', \\'json\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'jwan2021/autotrain-data-us-housing-prices\\', \\'accuracy\\': {\\'Loss\\': 122809.223, \\'R2\\': 0.884, \\'MSE\\': 15082105200.447, \\'MAE\\': 95586.887, \\'RMSLE\\': 0.13}}, \\'description\\': \\'A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 167, "text": " An environmental organization would like to use our Carbon Emissions prediction model to estimate CO2 emissions of different configurations of vehicles.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Carbon Emissions\\', \\'api_name\\': \\'45473113800\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'samvelkoch/autotrain-data-prknsn-2\\', \\'accuracy\\': {\\'Loss\\': 5.079, \\'R2\\': 0.109, \\'MSE\\': 25.795, \\'MAE\\': 3.78, \\'RMSLE\\': 0.849}}, \\'description\\': \\'A tabular regression model trained with AutoTrain for predicting carbon emissions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 168, "text": " I am a data analyst working in pollution detection, find a model and develop a piece of code for me for environment monitoring.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Classification\\', \\'framework\\': \\'Joblib\\', \\'functionality\\': \\'Carbon Emissions\\', \\'api_name\\': \\'tejas23/autotrain-amx2-1702259725\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': {\\'accuracy\\': 0.827}}, \\'description\\': \\'Multi-class Classification Model for Carbon Emissions\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 169, "text": " We want to develop an intelligent prosthetic leg that can improve walking. Use a decision transformer to predict actions to be taken.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Reinforcement Learning\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'edbeeching/decision-transformer-gym-walker2d-expert\\', \\'api_call\\': \"AutoModel.from_pretrained(\\'edbeeching/decision-transformer-gym-walker2d-expert\\')\", \\'api_arguments\\': {\\'mean\\': [1.2384834, 0.19578537, -0.10475016, -0.18579608, 0.23003316, 0.022800924, -0.37383768, 0.337791, 3.925096, -0.0047428459, 0.025267061, -0.0039287535, -0.01736751, -0.48212224, 0.00035432147, -0.0037124525, 0.0026285544], \\'std\\': [0.06664903, 0.16980624, 0.17309439, 0.21843709, 0.74599105, 0.02410989, 0.3729872, 0.6226182, 0.9708009, 0.72936815, 1.504065, 2.495893, 3.511518, 5.3656907, 0.79503316, 4.317483, 6.1784487]}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'See our Blog Post, Colab notebook or Example Script for usage.\\', \\'performance\\': {\\'dataset\\': \\'Gym Walker2d environment\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 170, "text": " You want to create a bot that can play the Pong No Frameskip-v4 game with exceptional skill.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Reinforcement Learning\\', \\'framework\\': \\'Stable-Baselines3\\', \\'functionality\\': \\'deep-reinforcement-learning\\', \\'api_name\\': \\'ppo-PongNoFrameskip-v4\\', \\'api_call\\': \"load_from_hub(repo_id=\\'sb3/ppo-PongNoFrameskip-v4\\',filename=\\'{MODEL FILENAME}.zip\\',)\", \\'api_arguments\\': [\\'algo\\', \\'env\\', \\'f\\'], \\'python_environment_requirements\\': [\\'RL Zoo\\', \\'SB3\\', \\'SB3 Contrib\\'], \\'example_code\\': \\'python -m rl_zoo3.load_from_hub --algo ppo --env PongNoFrameskip-v4 -orga sb3 -f logs/\\', \\'performance\\': {\\'dataset\\': \\'PongNoFrameskip-v4\\', \\'accuracy\\': \\'21.00 +/- 0.00\\'}, \\'description\\': \\'This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 171, "text": " I am a game developer working on a game project involving moving carts. I need to use reinforcement learning to improve the game experience.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Reinforcement Learning\\', \\'framework\\': \\'Stable-Baselines3\\', \\'functionality\\': \\'CartPole-v1\\', \\'api_name\\': \\'dqn-CartPole-v1\\', \\'api_call\\': \"load_from_hub(repo_id=\\'sb3/dqn-CartPole-v1\\',filename=\\'{MODEL FILENAME}.zip\\',)\", \\'api_arguments\\': [\\'algo\\', \\'env\\', \\'logs\\'], \\'python_environment_requirements\\': [\\'rl_zoo3\\', \\'stable-baselines3\\', \\'stable-baselines3-contrib\\'], \\'example_code\\': \\'python train.py --algo dqn --env CartPole-v1 -f logs/\\', \\'performance\\': {\\'dataset\\': \\'CartPole-v1\\', \\'accuracy\\': \\'500.00 +/- 0.00\\'}, \\'description\\': \\'This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 172, "text": " Develop a soccer playing agent that can outperform its opponents in a 2v2 environment.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Reinforcement Learning\\', \\'framework\\': \\'Unity ML-Agents Library\\', \\'functionality\\': \\'Train and play SoccerTwos\\', \\'api_name\\': \\'poca-SoccerTwosv2\\', \\'api_call\\': \"mlagents-load-from-hf --repo-id=\\'Raiden-1001/poca-SoccerTwosv2\\' --local-dir=\\'./downloads\\'\", \\'api_arguments\\': [\\'your_configuration_file_path.yaml\\', \\'run_id\\'], \\'python_environment_requirements\\': [\\'ml-agents\\'], \\'example_code\\': \\'mlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\\', \\'performance\\': {\\'dataset\\': \\'SoccerTwos\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 173, "text": " We are tasked to analyze text for a Russian newspaper to help understand general sentiment and trends in the text.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Natural Language Processing Text Classification\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Sentiment Analysis\\', \\'api_name\\': \\'finiteautomata/beto-sentiment-analysis\\', \\'api_call\\': \"pipeline(\\'sentiment-analysis\\', model=\\'finiteautomata/beto-sentiment-analysis\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'Hugging Face Transformers library\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'TASS 2020 corpus\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Model trained with TASS 2020 corpus (around ~5k tweets) of several dialects of Spanish. Base model is BETO, a BERT model trained in Spanish. Uses POS, NEG, NEU labels.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 174, "text": " We want to generate an image from a textual description for our PowerPoint presentation.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'Linaqruf/anything-v3.0\\', \\'api_call\\': \"Text2ImagePipeline(model=\\'Linaqruf/anything-v3.0\\')\", \\'api_arguments\\': \\'\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A text-to-image model that generates images from text descriptions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 175, "text": " A new manga has been released and we would like to provide a manga reader app with translations. Get the text from the manga image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Image-to-Text\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'kha-white/manga-ocr-base\\', \\'api_call\\': \"pipeline(\\'ocr\\', model=\\'kha-white/manga-ocr-base\\')\", \\'api_arguments\\': \\'image\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'manga109s\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 176, "text": " We are building a social media site which creates automatic captions for users when they post a picture\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Image-to-Text\\', \\'framework\\': \\'Transformers\\', \\'functionality\\': \\'Image Captioning\\', \\'api_name\\': \\'blip-image-captioning-large\\', \\'api_call\\': \\'BlipForConditionalGeneration.from_pretrained(Salesforce/blip-image-captioning-large)\\', \\'api_arguments\\': {\\'raw_image\\': \\'Image\\', \\'text\\': \\'Optional Text\\'}, \\'python_environment_requirements\\': {\\'transformers\\': \\'BlipProcessor, BlipForConditionalGeneration\\', \\'PIL\\': \\'Image\\', \\'requests\\': \\'requests\\'}, \\'example_code\\': {\\'import_requests\\': \\'import requests\\', \\'import_PIL\\': \\'from PIL import Image\\', \\'import_transformers\\': \\'from transformers import BlipProcessor, BlipForConditionalGeneration\\', \\'load_processor\\': \\'processor = BlipProcessor.from_pretrained(Salesforce/blip-image-captioning-large)\\', \\'load_model\\': \\'model = BlipForConditionalGeneration.from_pretrained(Salesforce/blip-image-captioning-large)\\', \\'load_image\\': \"img_url = \\'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg\\'\\\nraw_image = Image.open(requests.get(img_url, stream=True).raw).convert(\\'RGB\\')\", \\'conditional_captioning\\': \\'text = a photography of\\\ninputs = processor(raw_image, text, return_tensors=pt)\\\nout = model.generate(**inputs)\\\nprint(processor.decode(out[0], skip_special_tokens=True))\\', \\'unconditional_captioning\\': \\'inputs = processor(raw_image, return_tensors=pt)\\\nout = model.generate(**inputs)\\\nprint(processor.decode(out[0], skip_special_tokens=True))\\'}, \\'performance\\': {\\'dataset\\': \\'COCO\\', \\'accuracy\\': {\\'image-text retrieval\\': \\'+2.7% recall@1\\', \\'image captioning\\': \\'+2.8% CIDEr\\', \\'VQA\\': \\'+1.6% VQA score\\'}}, \\'description\\': \\'BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 177, "text": " There is robot in our factory which reads the image from the production line and then generate a text output based on the image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'gsdf/Counterfeit-V2.5\\', \\'api_call\\': \"pipeline(\\'text-to-image\\', model=\\'gsdf/Counterfeit-V2.5\\')\", \\'api_arguments\\': \\'text\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'((masterpiece,best quality)),1girl, solo, animal ears, rabbit, barefoot, knees up, dress, sitting, rabbit ears, short sleeves, looking at viewer, grass, short hair, smile, white hair, puffy sleeves, outdoors, puffy short sleeves, bangs, on ground, full body, animal, white dress, sunlight, brown eyes, dappled sunlight, day, depth of field\\', \\'performance\\': {\\'dataset\\': \\'EasyNegative\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 178, "text": " I am a filmmaker, and I need to make a short video based on a scene description from a script.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'chavinlo/TempoFunk\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'chavinlo/TempoFunk\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 179, "text": " I'm an author and want to create a short video based on a brief passage from my book. Can you generate a video based on this text?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'chavinlo/TempoFunk\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'chavinlo/TempoFunk\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 180, "text": " I want to build an AI model that can analyze images and answer questions about the content of the image.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Document Question Answering\\', \\'api_name\\': \\'CQI_Visual_Question_Awnser_PT_v0\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=LayoutLMForQuestionAnswering.from_pretrained(\\'microsoft/layoutlm-base-uncased\\'))\", \\'api_arguments\\': [\\'url\\', \\'question\\'], \\'python_environment_requirements\\': [\\'PIL\\', \\'pytesseract\\', \\'PyTorch\\', \\'transformers\\'], \\'example_code\\': [\"nlp(\\'https://templates.invoicehome.com/invoice-template-us-neat-750px.png\\', \\'What is the invoice number?\\')\", \"nlp(\\'https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\\', \\'What is the purchase amount?\\')\", \"nlp(\\'https://www.accountingcoach.com/wp-content/uploads/2013/10/income-statement-example@2x.png\\', \\'What are the 2020 net sales?\\')\"], \\'performance\\': {\\'dataset\\': [{\\'accuracy\\': 0.9943977}, {\\'accuracy\\': 0.9912159}, {\\'accuracy\\': 0.59147286}]}, \\'description\\': \\'A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 181, "text": " We are trying to develop an application that helps tourists get information about attractions by analyzing images they take and responding to questions.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'prompthero/openjourney-v4\\', \\'api_call\\': \"pipeline(\\'text-to-image\\', model=\\'prompthero/openjourney-v4\\')\", \\'api_arguments\\': {\\'text\\': \\'string\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"generate_image(\\'your text here\\')\", \\'performance\\': {\\'dataset\\': \\'Midjourney v4 images\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 182, "text": " We have the financial documents of a company and we want to extract information about the cash flow. Modify the model so it can answer the questions related to the cash flow.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Document Question Answering\\', \\'api_name\\': \\'CQI_Visual_Question_Awnser_PT_v0\\', \\'api_call\\': \"pipeline(\\'question-answering\\', model=LayoutLMForQuestionAnswering.from_pretrained(\\'microsoft/layoutlm-base-uncased\\'))\", \\'api_arguments\\': [\\'url\\', \\'question\\'], \\'python_environment_requirements\\': [\\'PIL\\', \\'pytesseract\\', \\'PyTorch\\', \\'transformers\\'], \\'example_code\\': [\"nlp(\\'https://templates.invoicehome.com/invoice-template-us-neat-750px.png\\', \\'What is the invoice number?\\')\", \"nlp(\\'https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\\', \\'What is the purchase amount?\\')\", \"nlp(\\'https://www.accountingcoach.com/wp-content/uploads/2013/10/income-statement-example@2x.png\\', \\'What are the 2020 net sales?\\')\"], \\'performance\\': {\\'dataset\\': [{\\'accuracy\\': 0.9943977}, {\\'accuracy\\': 0.9912159}, {\\'accuracy\\': 0.59147286}]}, \\'description\\': \\'A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 183, "text": " Please generate a correct building plan leveraging the data given.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Tabular Tabular Regression\\', \\'framework\\': \\'Joblib\\', \\'functionality\\': \\'Single Column Regression\\', \\'api_name\\': \\'jwan2021/autotrain-us-housing-prices-1771761512\\', \\'api_call\\': \"joblib.load(\\'model.joblib\\')\", \\'api_arguments\\': [\\'data\\'], \\'python_environment_requirements\\': [\\'joblib\\', \\'pandas\\', \\'json\\'], \\'example_code\\': \"import json\\\nimport joblib\\\nimport pandas as pd\\\nmodel = joblib.load(\\'model.joblib\\')\\\nconfig = json.load(open(\\'config.json\\'))\\\nfeatures = config[\\'features\\']\\\ndata = pd.read_csv(\\'data.csv\\')\\\ndata = data[features]\\\ndata.columns = [\\'feat_\\' + str(col) for col in data.columns]\\\npredictions = model.predict(data)\", \\'performance\\': {\\'dataset\\': \\'jwan2021/autotrain-data-us-housing-prices\\', \\'accuracy\\': {\\'Loss\\': 122809.223, \\'R2\\': 0.884, \\'MSE\\': 15082105200.447, \\'MAE\\': 95586.887, \\'RMSLE\\': 0.13}}, \\'description\\': \\'A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 184, "text": " Help our drone video analyzing app estimate the depth in drone footage.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Depth Estimation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Depth Estimation\\', \\'api_name\\': \\'glpn-kitti\\', \\'api_call\\': \"GLPNForDepthEstimation.from_pretrained(\\'vinvino02/glpn-kitti\\')\", \\'api_arguments\\': \\'images, return_tensors\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'from transformers import GLPNFeatureExtractor, GLPNForDepthEstimation\\\nimport torch\\\nimport numpy as np\\\nfrom PIL import Image\\\nimport requests\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\nfeature_extractor = GLPNFeatureExtractor.from_pretrained(vinvino02/glpn-kitti)\\\nmodel = GLPNForDepthEstimation.from_pretrained(vinvino02/glpn-kitti)\\\ninputs = feature_extractor(images=image, return_tensors=pt)\\\nwith torch.no_grad():\\\n outputs = model(**inputs)\\\n predicted_depth = outputs.predicted_depth\\\nprediction = torch.nn.functional.interpolate(\\\n predicted_depth.unsqueeze(1),\\\n size=image.size[::-1],\\\n mode=bicubic,\\\n align_corners=False,\\\n)\\\noutput = prediction.squeeze().cpu().numpy()\\\nformatted = (output * 255 / np.max(output)).astype(uint8)\\\ndepth = Image.fromarray(formatted)\\', \\'performance\\': {\\'dataset\\': \\'KITTI\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 185, "text": " As a salesperson, I need to analyze customer invoices to answer questions about the total amount, tax, and due date from an image file.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Document Question Answer\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Transformers\\', \\'api_name\\': \\'layoutlm-invoices\\', \\'api_call\\': \"AutoModelForDocumentQuestionAnswering.from_pretrained(\\'impira/layoutlm-invoices\\')\", \\'api_arguments\\': \\'question, context\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \"nlp(question=\\'What is the total amount?\\', context=\\'your_invoice_text\\')\", \\'performance\\': {\\'dataset\\': \\'proprietary dataset of invoices, SQuAD2.0, and DocVQA\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 186, "text": " We need to find out the depth information of a room for monitoring purposes.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Depth Estimation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Depth Estimation\\', \\'api_name\\': \\'glpn-nyu-finetuned-diode\\', \\'api_call\\': \"pipeline(\\'depth-estimation\\', model=\\'sayakpaul/glpn-nyu-finetuned-diode\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'diode-subset\\', \\'accuracy\\': {\\'Loss\\': 0.4359, \\'Rmse\\': 0.4276}}, \\'description\\': \\'This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 187, "text": " We are creating an autonomous car and need to estimate the depth of objects in a given scene.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Depth Estimation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Depth Estimation\\', \\'api_name\\': \\'glpn-kitti\\', \\'api_call\\': \"GLPNForDepthEstimation.from_pretrained(\\'vinvino02/glpn-kitti\\')\", \\'api_arguments\\': \\'images, return_tensors\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'from transformers import GLPNFeatureExtractor, GLPNForDepthEstimation\\\nimport torch\\\nimport numpy as np\\\nfrom PIL import Image\\\nimport requests\\\nurl = http://images.cocodataset.org/val2017/000000039769.jpg\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\nfeature_extractor = GLPNFeatureExtractor.from_pretrained(vinvino02/glpn-kitti)\\\nmodel = GLPNForDepthEstimation.from_pretrained(vinvino02/glpn-kitti)\\\ninputs = feature_extractor(images=image, return_tensors=pt)\\\nwith torch.no_grad():\\\n outputs = model(**inputs)\\\n predicted_depth = outputs.predicted_depth\\\nprediction = torch.nn.functional.interpolate(\\\n predicted_depth.unsqueeze(1),\\\n size=image.size[::-1],\\\n mode=bicubic,\\\n align_corners=False,\\\n)\\\noutput = prediction.squeeze().cpu().numpy()\\\nformatted = (output * 255 / np.max(output)).astype(uint8)\\\ndepth = Image.fromarray(formatted)\\', \\'performance\\': {\\'dataset\\': \\'KITTI\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 188, "text": " Help us create an AI solution to automatically label images taken by a security camera.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Classification\\', \\'api_name\\': \\'abhishek/autotrain-dog-vs-food\\', \\'api_call\\': \"pipeline(\\'image-classification\\', model=\\'abhishek/autotrain-dog-vs-food\\')\", \\'api_arguments\\': \\'image_path\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'sasha/dog-food\\', \\'accuracy\\': 0.998}, \\'description\\': \"A pre-trained model for classifying images as either dog or food using Hugging Face\\'s AutoTrain framework.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 189, "text": " Develop a software to classify an image from a URL into a thousand categories.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image-to-Image\\', \\'framework\\': \\'Keras\\', \\'functionality\\': \\'Image Deblurring\\', \\'api_name\\': \\'google/maxim-s3-deblurring-gopro\\', \\'api_call\\': \"from_pretrained_keras(\\'google/maxim-s3-deblurring-gopro\\')\", \\'api_arguments\\': [\\'image\\'], \\'python_environment_requirements\\': [\\'huggingface_hub\\', \\'PIL\\', \\'tensorflow\\', \\'numpy\\', \\'requests\\'], \\'example_code\\': \\'from huggingface_hub import from_pretrained_keras\\\nfrom PIL import Image\\\nimport tensorflow as tf\\\nimport numpy as np\\\nimport requests\\\nurl = https://github.com/sayakpaul/maxim-tf/raw/main/images/Deblurring/input/1fromGOPR0950.png\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\nimage = np.array(image)\\\nimage = tf.convert_to_tensor(image)\\\nimage = tf.image.resize(image, (256, 256))\\\nmodel = from_pretrained_keras(google/maxim-s3-deblurring-gopro)\\\npredictions = model.predict(tf.expand_dims(image, 0))\\', \\'performance\\': {\\'dataset\\': \\'GoPro\\', \\'accuracy\\': {\\'PSNR\\': 32.86, \\'SSIM\\': 0.961}}, \\'description\\': \\'MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 190, "text": " Our delivery drones need to detect and avoid obstacles while flying. Develop a solution for them to detect objects in their path.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Audio Voice Activity Detection\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Voice Activity Detection\\', \\'api_name\\': \\'d4data/Indian-voice-cloning\\', \\'api_call\\': \"pipeline(\\'voice-activity-detection\\', model=\\'d4data/Indian-voice-cloning\\')\", \\'api_arguments\\': [], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A model for detecting voice activity in Indian languages.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 191, "text": " Develop a code to recognize objects in images using deformable-detr model.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Object Detection\\', \\'api_name\\': \\'deformable-detr\\', \\'api_call\\': \"DeformableDetrForObjectDetection.from_pretrained(\\'SenseTime/deformable-detr\\')\", \\'api_arguments\\': [\\'images\\', \\'return_tensors\\'], \\'python_environment_requirements\\': [\\'transformers\\', \\'torch\\', \\'PIL\\', \\'requests\\'], \\'example_code\\': \"from transformers import AutoImageProcessor, DeformableDetrForObjectDetection\\\nimport torch\\\nfrom PIL import Image\\\nimport requests\\\nurl = \\'http://images.cocodataset.org/val2017/000000039769.jpg\\'\\\nimage = Image.open(requests.get(url, stream=True).raw)\\\nprocessor = AutoImageProcessor.from_pretrained(\\'SenseTime/deformable-detr\\')\\\nmodel = DeformableDetrForObjectDetection.from_pretrained(\\'SenseTime/deformable-detr\\')\\\ninputs = processor(images=image, return_tensors=\\'pt\\')\\\noutputs = model(**inputs)\", \\'performance\\': {\\'dataset\\': \\'COCO 2017\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Deformable DETR model with ResNet-50 backbone trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Zhu et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 192, "text": " I need to extract tables from a set of scanned document images to simplify data analysis.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Table Extraction\\', \\'api_name\\': \\'keremberke/yolov8n-table-extraction\\', \\'api_call\\': \"YOLO(\\'keremberke/yolov8n-table-extraction\\')\", \\'api_arguments\\': {\\'conf\\': 0.25, \\'iou\\': 0.45, \\'agnostic_nms\\': False, \\'max_det\\': 1000}, \\'python_environment_requirements\\': [\\'ultralyticsplus==0.0.23\\', \\'ultralytics==8.0.21\\'], \\'example_code\\': [\\'from ultralyticsplus import YOLO, render_result\\', \"model = YOLO(\\'keremberke/yolov8n-table-extraction\\')\", \"model.overrides[\\'conf\\'] = 0.25\", \"model.overrides[\\'iou\\'] = 0.45\", \"model.overrides[\\'agnostic_nms\\'] = False\", \"model.overrides[\\'max_det\\'] = 1000\", \"image = \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'\", \\'results = model.predict(image)\\', \\'print(results[0].boxes)\\', \\'render = render_result(model=model, image=image, result=results[0])\\', \\'render.show()\\'], \\'performance\\': {\\'dataset\\': \\'table-extraction\\', \\'accuracy\\': 0.967}, \\'description\\': \"An object detection model for extracting tables from documents. Supports two label types: \\'bordered\\' and \\'borderless\\'.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 193, "text": " Our customers wish to automatically detect shoplifters in the store using a surveillance camera. Help them to implement object detection and identify potential thieves.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Object Detection\\', \\'api_name\\': \\'keremberke/yolov8m-forklift-detection\\', \\'api_call\\': \"YOLO(\\'keremberke/yolov8m-forklift-detection\\')\", \\'api_arguments\\': {\\'image\\': \\'URL or local path to the image\\'}, \\'python_environment_requirements\\': [\\'ultralyticsplus==0.0.23\\', \\'ultralytics==8.0.21\\'], \\'example_code\\': [\\'from ultralyticsplus import YOLO, render_result\\', \"model = YOLO(\\'keremberke/yolov8m-forklift-detection\\')\", \"model.overrides[\\'conf\\'] = 0.25\", \"model.overrides[\\'iou\\'] = 0.45\", \"model.overrides[\\'agnostic_nms\\'] = False\", \"model.overrides[\\'max_det\\'] = 1000\", \"image = \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'\", \\'results = model.predict(image)\\', \\'print(results[0].boxes)\\', \\'render = render_result(model=model, image=image, result=results[0])\\', \\'render.show()\\'], \\'performance\\': {\\'dataset\\': \\'forklift-object-detection\\', \\'accuracy\\': 0.846}, \\'description\\': \\'A YOLOv8 model for detecting forklifts and persons in images.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 194, "text": " Create an object detector that can detect blood cells in an image, such as platelets, red blood cells, and white blood cells.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Object Detection\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Blood Cell Detection\\', \\'api_name\\': \\'keremberke/yolov8n-blood-cell-detection\\', \\'api_call\\': \"YOLO(\\'keremberke/yolov8n-blood-cell-detection\\')\", \\'api_arguments\\': {\\'conf\\': 0.25, \\'iou\\': 0.45, \\'agnostic_nms\\': False, \\'max_det\\': 1000}, \\'python_environment_requirements\\': \\'ultralyticsplus==0.0.23 ultralytics==8.0.21\\', \\'example_code\\': \"from ultralyticsplus import YOLO, render_result\\\nmodel = YOLO(\\'keremberke/yolov8n-blood-cell-detection\\')\\\nmodel.overrides[\\'conf\\'] = 0.25\\\nmodel.overrides[\\'iou\\'] = 0.45\\\nmodel.overrides[\\'agnostic_nms\\'] = False\\\nmodel.overrides[\\'max_det\\'] = 1000\\\nimage = \\'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\\'\\\nresults = model.predict(image)\\\nprint(results[0].boxes)\\\nrender = render_result(model=model, image=image, result=results[0])\\\nrender.show()\", \\'performance\\': {\\'dataset\\': \\'blood-cell-object-detection\\', \\'accuracy\\': 0.893}, \\'description\\': \\'This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 195, "text": " I am a real-estate agent working on a project where I need to convert images of room plans to a better visual representation.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'Realistic_Vision_V1.4\\', \\'api_call\\': \"pipeline(\\'text-to-image\\', model=SG161222/Realistic_Vision_V1.4)\", \\'api_arguments\\': {\\'prompt\\': \\'string\\', \\'negative_prompt\\': \\'string\\'}, \\'python_environment_requirements\\': [\\'transformers\\', \\'torch\\'], \\'example_code\\': \"from transformers import pipeline\\\n\\\nmodel = pipeline(\\'text-to-image\\', model=\\'SG161222/Realistic_Vision_V1.4\\')\\\n\\\nprompt = \\'a close up portrait photo of 26 y.o woman in wastelander clothes, long haircut, pale skin, slim body, background is city ruins, (high detailed skin:1.2), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3\\'\\\nnegative_prompt = \\'(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\\'\\\n\\\nresult = model(prompt, negative_prompt=negative_prompt)\", \\'performance\\': {\\'dataset\\': \\'N/A\\', \\'accuracy\\': \\'N/A\\'}, \\'description\\': \\'Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 196, "text": " We recently received low resolution images of newly released products and need to upscale them for better quality.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Image Upscaling\\', \\'api_name\\': \\'stabilityai/sd-x2-latent-upscaler\\', \\'api_call\\': \\'StableDiffusionLatentUpscalePipeline.from_pretrained(stabilityai/sd-x2-latent-upscaler, torch_dtype=torch.float16)\\', \\'api_arguments\\': {\\'prompt\\': \\'text prompt\\', \\'image\\': \\'low resolution latents\\', \\'num_inference_steps\\': 20, \\'guidance_scale\\': 0, \\'generator\\': \\'torch generator\\'}, \\'python_environment_requirements\\': [\\'git+https://github.com/huggingface/diffusers.git\\', \\'transformers\\', \\'accelerate\\', \\'scipy\\', \\'safetensors\\'], \\'example_code\\': \\'from diffusers import StableDiffusionLatentUpscalePipeline, StableDiffusionPipeline\\\nimport torch\\\npipeline = StableDiffusionPipeline.from_pretrained(CompVis/stable-diffusion-v1-4, torch_dtype=torch.float16)\\\npipeline.to(cuda)\\\nupscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(stabilityai/sd-x2-latent-upscaler, torch_dtype=torch.float16)\\\nupscaler.to(cuda)\\\nprompt = a photo of an astronaut high resolution, unreal engine, ultra realistic\\\ngenerator = torch.manual_seed(33)\\\nlow_res_latents = pipeline(prompt, generator=generator, output_type=latent).images\\\nupscaled_image = upscaler(prompt=prompt, image=low_res_latents, num_inference_steps=20, guidance_scale=0, generator=generator).images[0]\\\nupscaled_image.save(astronaut_1024.png)\\', \\'performance\\': {\\'dataset\\': \\'LAION-2B\\', \\'accuracy\\': \\'Not specified\\'}, \\'description\\': \"Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion\\'s latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 197, "text": " As a toy company, we are designing a new toy line. We'd like you to create an image of a toy robot using relevant text prompts as control input.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Image\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Image\\', \\'api_name\\': \\'prompthero/openjourney-v4\\', \\'api_call\\': \"pipeline(\\'text-to-image\\', model=\\'prompthero/openjourney-v4\\')\", \\'api_arguments\\': {\\'text\\': \\'string\\'}, \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \"generate_image(\\'your text here\\')\", \\'performance\\': {\\'dataset\\': \\'Midjourney v4 images\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 198, "text": " I'm developing a game that needs more Minecraft skins for some characters. How can I generete them with this model?\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Diffusers\\', \\'api_name\\': \\'Minecraft-Skin-Diffusion\\', \\'api_call\\': \"DDPMPipeline.from_pretrained(\\'WiNE-iNEFF/Minecraft-Skin-Diffusion\\')\", \\'api_arguments\\': {}, \\'python_environment_requirements\\': [\\'diffusers\\'], \\'example_code\\': \"from diffusers import DDPMPipeline\\\npipeline = DDPMPipeline.from_pretrained(\\'WiNE-iNEFF/Minecraft-Skin-Diffusion\\')\\\nimage = pipeline().images[0].convert(\\'RGBA\\')\\\nimage\", \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 199, "text": " Find me a generative model to create cat images in 256x256 resolution.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Unconditional Image Generation\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Unconditional Image Generation\\', \\'api_name\\': \\'google/ddpm-cat-256\\', \\'api_call\\': \"DDPMPipeline.from_pretrained(\\'google/ddpm-cat-256\\')\", \\'api_arguments\\': [\\'model_id\\'], \\'python_environment_requirements\\': [\\'diffusers\\'], \\'example_code\\': \\'!pip install diffusers\\\nfrom diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline\\\nmodel_id = google/ddpm-cat-256\\\nddpm = DDPMPipeline.from_pretrained(model_id)\\\nimage = ddpm().images[0]\\\nimage.save(ddpm_generated_image.png)\\', \\'performance\\': {\\'dataset\\': \\'CIFAR10\\', \\'accuracy\\': {\\'Inception_score\\': 9.46, \\'FID_score\\': 3.17}}, \\'description\\': \\'Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 200, "text": " Our organization works with video surveillance. We need a system to analyze the videos and classify various events happening inside the video.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Video Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Video Classification\\', \\'api_name\\': \\'facebook/timesformer-base-finetuned-ssv2\\', \\'api_call\\': \"TimesformerForVideoClassification.from_pretrained(\\'facebook/timesformer-base-finetuned-ssv2\\')\", \\'api_arguments\\': [\\'images\\', \\'return_tensors\\'], \\'python_environment_requirements\\': [\\'transformers\\', \\'numpy\\', \\'torch\\'], \\'example_code\\': \\'from transformers import AutoImageProcessor, TimesformerForVideoClassification\\\nimport numpy as np\\\nimport torch\\\nvideo = list(np.random.randn(8, 3, 224, 224))\\\nprocessor = AutoImageProcessor.from_pretrained(facebook/timesformer-base-finetuned-ssv2)\\\nmodel = TimesformerForVideoClassification.from_pretrained(facebook/timesformer-base-finetuned-ssv2)\\\ninputs = processor(images=video, return_tensors=pt)\\\nwith torch.no_grad():\\\n outputs = model(**inputs)\\\n logits = outputs.logits\\\npredicted_class_idx = logits.argmax(-1).item()\\\nprint(Predicted class:, model.config.id2label[predicted_class_idx])\\', \\'performance\\': {\\'dataset\\': \\'Something Something v2\\', \\'accuracy\\': \\'Not provided\\'}, \\'description\\': \\'TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 201, "text": " People in my company need an automatic solution to categorize videos based on their content. The system should be able to recognize the main theme of a video with high accuracy.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Multimodal Text-to-Video\\', \\'framework\\': \\'Hugging Face\\', \\'functionality\\': \\'Text-to-Video\\', \\'api_name\\': \\'chavinlo/TempoFunk\\', \\'api_call\\': \"pipeline(\\'text-to-video\\', model=\\'chavinlo/TempoFunk\\')\", \\'api_arguments\\': [\\'input_text\\'], \\'python_environment_requirements\\': [\\'transformers\\'], \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'\\', \\'accuracy\\': \\'\\'}, \\'description\\': \\'A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text.\\'}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
{"question_id": 202, "text": " We want to build a product to classify images of pets into different categories.\n \n Use this API documentation for reference: [Document(page_content='{\\'domain\\': \\'Computer Vision Image Classification\\', \\'framework\\': \\'Hugging Face Transformers\\', \\'functionality\\': \\'Image Classification\\', \\'api_name\\': \\'abhishek/autotrain-dog-vs-food\\', \\'api_call\\': \"pipeline(\\'image-classification\\', model=\\'abhishek/autotrain-dog-vs-food\\')\", \\'api_arguments\\': \\'image_path\\', \\'python_environment_requirements\\': \\'transformers\\', \\'example_code\\': \\'\\', \\'performance\\': {\\'dataset\\': \\'sasha/dog-food\\', \\'accuracy\\': 0.998}, \\'description\\': \"A pre-trained model for classifying images as either dog or food using Hugging Face\\'s AutoTrain framework.\"}', metadata={})]\nWrite a python program in 1 to 2 lines to call API in huggingface.\n\nThe answer should follow the format: {<<<domain>>> $DOMAIN, <<<api_call>>>: $API_CALL, <<<api_provider>>>: $API_PROVIDER, <<<explanation>>>: $EXPLANATION, <<<code>>>: $CODE}. Here are the requirements:\n1. The $API_CALL should have only 1 line of code that calls api.\n2. The $API_PROVIDER should be the programming framework used.\n3. $EXPLANATION should be a step-by-step explanation.\n4. The $CODE is the python code.\n5. Do not repeat the format in your answer.", "category": "generic"}
